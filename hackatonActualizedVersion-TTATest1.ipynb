{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.collections\n",
    "\n",
    "from matplotlib.transforms import Affine2D\n",
    "import mpl_toolkits.axisartist.floating_axes as floating_axes\n",
    "import matplotlib.collections\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from tqdm import *\n",
    "# nice progress bars otherwise\n",
    "# def tqdm(x):\n",
    "#     yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO, improvement ideas\n",
    "\n",
    "# use log(flux) as input\n",
    "# investigate highest errors (argmax(xi²))\n",
    "\n",
    "# kfold integration in place of CV\n",
    "# TTA\n",
    "# CNN segmentation cleanup \n",
    "# resnet v2 ( https://github.com/myutwo150/keras-inception-resnet-v2/blob/master/inception_resnet_v2.py )\n",
    "# custom CNN features\n",
    "# CV2 resize cubic interpolation \n",
    "\n",
    "# Serge:\n",
    "# essayer de remplacer lgb par un Deep NN keras (vu la quantité de donnée)\n",
    "\n",
    "\n",
    "#done\n",
    "# lgbm eval rmsle instead of rmse\n",
    "# add image size as feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# memory debug function\n",
    "\n",
    "import sys\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "mm = sorted([(x, sys.getsizeof(globals().get(x)),\"{:,}\".format(sys.getsizeof(globals().get(x)))) \n",
    "        for x in dir() \n",
    "           if not x.startswith('_') \n",
    "#         and x not in sys.modules\n",
    "        and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data folder set up and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFolder = 'data/mainData/'\n",
    "plt.ion()\n",
    "\n",
    "runNameParams = []\n",
    "runNameParams.append('newSource')\n",
    "# print(runNameParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(id):\n",
    "    if id[-4:] == '.npy':\n",
    "        X = np.load(dataFolder+id)\n",
    "    elif os.path.isfile(dataFolder+id+'.npy'):\n",
    "        X = np.load(dataFolder+id + '.npy')\n",
    "    elif os.path.isfile(dataFolder+id+'-g.csv'):\n",
    "        X = np.genfromtxt(dataFolder+id+'-g.csv', delimiter=\",\")\n",
    "    else:\n",
    "        X = None\n",
    "\n",
    "    X = np.float32(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80306\n"
     ]
    }
   ],
   "source": [
    "dataFileList = []\n",
    "\n",
    "directory = os.fsencode(dataFolder)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".npy\") or filename.endswith(\".py\"): \n",
    "        dataFileList.append(filename)\n",
    "        \n",
    "print(len(dataFileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check a few random images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drawOneGalaxy(galaxyID):\n",
    "    oneImageData = read_image(galaxyID)\n",
    "    print(galaxyID)\n",
    "\n",
    "    # new image\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    #set grid spec for the 4 graphs\n",
    "    gs = gridspec.GridSpec(2, 2, width_ratios=[5, 1], height_ratios=[1,5]) \n",
    "\n",
    "    #draw image\n",
    "    plt.title(\"raw\")\n",
    "    plt.subplot(gs[2])\n",
    "    plt.imshow(oneImageData)\n",
    "    \n",
    "    # horizontal (top) sum\n",
    "    plt.subplot(gs[0])\n",
    "    plt.title(galaxyID)\n",
    "    plt.plot(oneImageData.sum(axis=0))\n",
    "\n",
    "    # vertical (bottom-right) sum\n",
    "    ax = plt.subplot(gs[3])\n",
    "    ss = np.flip(oneImageData.sum(axis=1),axis=0)\n",
    "    plt.scatter(x=ss, y=list(range(oneImageData.shape[1])), s=1)\n",
    "    lines = [[(ss[i-1],i-1),(ss[i],i)] for i in range(1,len(ss))]\n",
    "    lc = matplotlib.collections.LineCollection(lines)\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    #value histogram\n",
    "    plt.subplot(gs[1])\n",
    "    plt.hist(oneImageData.reshape(-1), bins=100)\n",
    "    plt.yscale('log')    \n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #add small log of image\n",
    "    ax = fig.add_axes([0.02,0.6,.2,.2])\n",
    "    plt.imshow(np.log(oneImageData-oneImageData.min()+0.00001))\n",
    "\n",
    "for _ in range(5):\n",
    "    i = random.randint(0,len(dataFileList))\n",
    "#     oneImageData = np.load(dataFolder+'1237648704067273096.npy')\n",
    "#     drawOneGalaxy(dataFileList[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "issuesImages = ['1237658298983055529.npy','1237660634917634181.npy','1237654879654772871.npy','1237654953205170487.npy','1237651249884627014.npy','1237651754022207627.npy',\n",
    " '1237654669736018114.npy','1237655471824568727.npy','1237665530643808416.npy','1237658611444088911.npy','1237667255070490937.npy',\n",
    " '1237665531177795774.npy','1237645943975837722.npy','1237658425161220139.npy', '1237665129087435003.npy','1237657873792172224.npy',\n",
    " '1237660240313778264.npy','1237668298201432152.npy', '1237662264316264518.npy','1237657630042227294.npy','1237651754550624376.npy',\n",
    " '1237667211059986578.npy','1237655470208582145.npy']\n",
    "\n",
    "# for image in issuesImages:\n",
    "#     drawOneGalaxy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# ML part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import xgboost as xgb\n",
    "from keras.applications import *\n",
    "import lightgbm as lgbm\n",
    "import scipy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xi2(true,pred,error):\n",
    "    s=np.mean((true-pred)**2/error**2)\n",
    "    return s\n",
    "\n",
    "def normalize_image(Xg):\n",
    "    Xg -= np.mean(Xg)\n",
    "    Xg /= np.std(Xg)\n",
    "    \n",
    "    return Xg\n",
    "\n",
    "def crop_image(Xg):\n",
    "    h,w = Xg.shape\n",
    "    cy, cx = h//2, w//2\n",
    "    dy, dx = int(cy*0.75), int(cx*0.75) # crop a bit around center\n",
    "    Xg = Xg[cy-dy:cy+dy,cx-dx:cx+dx]\n",
    "    \n",
    "    return Xg\n",
    "\n",
    "def img_preprocnoread(Xg, preProcNum = 0):\n",
    "#    Xg = cleanupImage(id)\n",
    "\n",
    "    if ( preProcNum != 0):\n",
    "        if preProcNum & 4: # rotate\n",
    "            Xg = np.rot90(Xg)\n",
    "            \n",
    "        if preProcNum %4 == 1: # vflip\n",
    "            Xg = np.flip(Xg,0)\n",
    "        elif preProcNum %4 == 2: # hflip\n",
    "            Xg = np.flip(Xg,1)\n",
    "        elif preProcNum %4 == 3: # hflip+vflip\n",
    "            Xg = np.flip(np.flip(Xg,1),0)\n",
    "\n",
    "    Xg = np.log1p(Xg - Xg.min())\n",
    "    Xg = normalize_image(Xg)\n",
    "    Xg = crop_image(Xg)\n",
    "\n",
    "    \n",
    "    if Xg.shape[0] >= 224:\n",
    "        Xgr = cv2.resize(Xg,(224,224), cv2.INTER_AREA)\n",
    "    else:\n",
    "        Xgr = cv2.resize(Xg,(224,224), cv2.INTER_CUBIC)\n",
    "    \n",
    "    return Xgr\n",
    "    \n",
    "def img_preproc(id, preProcNum = 0):\n",
    "    Xg = read_image(id)\n",
    "    return img_preprocnoread(Xg,preProcNum)\n",
    "\n",
    "runNameParams.append('ReadLog1pNormCrop.75')\n",
    "# preprocName = \"ReadNormCrop.5\"\n",
    "# x = img_preproc('1237662637444694216')\n",
    "x = img_preproc(dataFileList[random.randint(0,len(dataFileList))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.imshow(img_preproc('1237662637444694216',0))\n",
    "# plt.figure()\n",
    "# plt.imshow(img_preproc('1237662637444694216',1))\n",
    "# plt.figure()\n",
    "# plt.imshow(img_preproc('1237662637444694216',2))\n",
    "# plt.figure()\n",
    "# plt.imshow(img_preproc('1237662637444694216',5))\n",
    "# plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.44069 10.3932\n",
      "[[-0.49960858 -0.6258232  -0.97922403 -1.29604864 -1.13738108]\n",
      " [-0.56061667 -0.66088331 -0.94162977 -1.18798494 -0.987252  ]\n",
      " [-0.73143941 -0.75905168 -0.83636582 -0.88540649 -0.56689048]\n",
      " [-0.87579638 -0.83753932 -0.73041952 -0.60053766 -0.17474809]\n",
      " [-0.67609829 -0.6601783  -0.61560243 -0.54589349 -0.149454  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEICAYAAACgbaaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4ee585128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x.min(), x.max())\n",
    "print(x[0:5,0:5])\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('histogram of values after image preprocessing')\n",
    "plt.hist(x.reshape(-1), bins=100)\n",
    "\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet',include_top=True,input_shape=(224,224,3))\n",
    "r50 = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDSS_ID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>logMst</th>\n",
       "      <th>err_l</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>D_Mpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1237662635825954925</td>\n",
       "      <td>210.95489999999998</td>\n",
       "      <td>12.64455</td>\n",
       "      <td>0.33113110693986714</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>42.47806067869379</td>\n",
       "      <td>440.99999325616017</td>\n",
       "      <td>0.8552113203991983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1237652947452297303</td>\n",
       "      <td>0.84015</td>\n",
       "      <td>-9.98328</td>\n",
       "      <td>0.5248074948227709</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>11.312</td>\n",
       "      <td>0.016</td>\n",
       "      <td>50.181626715917524</td>\n",
       "      <td>328.7142940929958</td>\n",
       "      <td>0.6374607478101917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1237652899137912944</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>-11.17802</td>\n",
       "      <td>0.6165950323262803</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>9.708</td>\n",
       "      <td>0.071</td>\n",
       "      <td>29.440699795795908</td>\n",
       "      <td>164.1428577048438</td>\n",
       "      <td>0.3183148122868964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1237661433779716229</td>\n",
       "      <td>211.48905000000002</td>\n",
       "      <td>43.88251</td>\n",
       "      <td>0.7585775667003197</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.062</td>\n",
       "      <td>31.869792393005813</td>\n",
       "      <td>144.4285735487938</td>\n",
       "      <td>0.28008379359836033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1237652944786555077</td>\n",
       "      <td>1.48395</td>\n",
       "      <td>16.13445</td>\n",
       "      <td>0.3388441338170015</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>38.39840364463448</td>\n",
       "      <td>389.571413397789</td>\n",
       "      <td>0.7554782039377076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SDSS_ID                  RA        DEC                  D25  \\\n",
       "10  1237662635825954925  210.95489999999998   12.64455  0.33113110693986714   \n",
       "11  1237652947452297303             0.84015   -9.98328   0.5248074948227709   \n",
       "12  1237652899137912944              1.0026  -11.17802   0.6165950323262803   \n",
       "13  1237661433779716229  211.48905000000002   43.88251   0.7585775667003197   \n",
       "14  1237652944786555077             1.48395   16.13445   0.3388441338170015   \n",
       "\n",
       "    redshi  logMst  err_l         GalSize_kpc               D_Mpc  \\\n",
       "10  0.1029   -99.0  -99.0   42.47806067869379  440.99999325616017   \n",
       "11  0.0767  11.312  0.016  50.181626715917524   328.7142940929958   \n",
       "12  0.0383   9.708  0.071  29.440699795795908   164.1428577048438   \n",
       "13  0.0337    9.26  0.062  31.869792393005813   144.4285735487938   \n",
       "14  0.0909    10.7   0.04   38.39840364463448    389.571413397789   \n",
       "\n",
       "              d_pix_kpc  \n",
       "10   0.8552113203991983  \n",
       "11   0.6374607478101917  \n",
       "12   0.3183148122868964  \n",
       "13  0.28008379359836033  \n",
       "14   0.7554782039377076  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_fwf('metaData.dat', comment = '#')\n",
    "df.columns = df.iloc[9,:].values\n",
    "df = df[10:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "      <th>logMstar</th>\n",
       "      <th>err_logMstar</th>\n",
       "      <th>Distance</th>\n",
       "      <th>lin_mass</th>\n",
       "      <th>lin_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>1.877420e+05</td>\n",
       "      <td>1.877420e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>184.527190</td>\n",
       "      <td>24.898677</td>\n",
       "      <td>0.445798</td>\n",
       "      <td>0.074652</td>\n",
       "      <td>38.318105</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>9.081941</td>\n",
       "      <td>-1.313631</td>\n",
       "      <td>319.936358</td>\n",
       "      <td>7.877701e+10</td>\n",
       "      <td>4.648110e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.620064</td>\n",
       "      <td>19.374103</td>\n",
       "      <td>0.168006</td>\n",
       "      <td>0.040143</td>\n",
       "      <td>18.942158</td>\n",
       "      <td>0.333632</td>\n",
       "      <td>12.706553</td>\n",
       "      <td>11.469736</td>\n",
       "      <td>172.041273</td>\n",
       "      <td>9.461819e+10</td>\n",
       "      <td>5.529011e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.008250</td>\n",
       "      <td>-11.252830</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>4.034125</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>42.857142</td>\n",
       "      <td>1.000000e-99</td>\n",
       "      <td>-2.279559e-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>152.349938</td>\n",
       "      <td>8.662358</td>\n",
       "      <td>0.346737</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>25.157782</td>\n",
       "      <td>0.366519</td>\n",
       "      <td>10.191000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>189.000006</td>\n",
       "      <td>1.552387e+10</td>\n",
       "      <td>1.144774e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.824575</td>\n",
       "      <td>23.197910</td>\n",
       "      <td>0.389045</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>35.525868</td>\n",
       "      <td>0.573465</td>\n",
       "      <td>10.693000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>295.714278</td>\n",
       "      <td>4.931738e+10</td>\n",
       "      <td>2.906879e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>222.151537</td>\n",
       "      <td>39.835143</td>\n",
       "      <td>0.478630</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>48.283920</td>\n",
       "      <td>0.801189</td>\n",
       "      <td>11.032000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>413.142858</td>\n",
       "      <td>1.076465e+11</td>\n",
       "      <td>6.027530e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.994900</td>\n",
       "      <td>70.133250</td>\n",
       "      <td>10.964781</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>1373.931687</td>\n",
       "      <td>2.490003</td>\n",
       "      <td>12.326000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1284.000022</td>\n",
       "      <td>2.118361e+12</td>\n",
       "      <td>1.727792e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RA            DEC            D25         redshi  \\\n",
       "count  187742.000000  187742.000000  187742.000000  187742.000000   \n",
       "mean      184.527190      24.898677       0.445798       0.074652   \n",
       "std        61.620064      19.374103       0.168006       0.040143   \n",
       "min         0.008250     -11.252830       0.316228       0.010000   \n",
       "25%       152.349938       8.662358       0.346737       0.044100   \n",
       "50%       185.824575      23.197910       0.389045       0.069000   \n",
       "75%       222.151537      39.835143       0.478630       0.096400   \n",
       "max       359.994900      70.133250      10.964781       0.299600   \n",
       "\n",
       "         GalSize_kpc      d_pix_kpc       logMstar   err_logMstar  \\\n",
       "count  187742.000000  187742.000000  187742.000000  187742.000000   \n",
       "mean       38.318105       0.620438       9.081941      -1.313631   \n",
       "std        18.942158       0.333632      12.706553      11.469736   \n",
       "min         4.034125       0.083111     -99.000000     -99.000000   \n",
       "25%        25.157782       0.366519      10.191000       0.021000   \n",
       "50%        35.525868       0.573465      10.693000       0.029000   \n",
       "75%        48.283920       0.801189      11.032000       0.041000   \n",
       "max      1373.931687       2.490003      12.326000       0.800000   \n",
       "\n",
       "            Distance      lin_mass       lin_err  \n",
       "count  187742.000000  1.877420e+05  1.877420e+05  \n",
       "mean      319.936358  7.877701e+10  4.648110e+09  \n",
       "std       172.041273  9.461819e+10  5.529011e+09  \n",
       "min        42.857142  1.000000e-99 -2.279559e-97  \n",
       "25%       189.000006  1.552387e+10  1.144774e+09  \n",
       "50%       295.714278  4.931738e+10  2.906879e+09  \n",
       "75%       413.142858  1.076465e+11  6.027530e+09  \n",
       "max      1284.000022  2.118361e+12  1.727792e+11  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RA'] = df['RA'].apply(np.float64)\n",
    "df['DEC'] = df['DEC'].apply(np.float64)\n",
    "df['D25'] = df['D25'].apply(np.float64)\n",
    "df['redshi'] = df['redshi'].apply(np.float64)\n",
    "df['logMstar'] = df['logMst'].apply(np.float64) #renamed\n",
    "df['err_logMstar'] = df['err_l'].apply(np.float64) #renamed\n",
    "df['GalSize_kpc'] = df['GalSize_kpc'].apply(np.float64)\n",
    "df['Distance'] = df['D_Mpc'].apply(np.float64) #renamed\n",
    "df['d_pix_kpc'] = df['d_pix_kpc'].apply(np.float64)\n",
    "\n",
    "df['lin_mass'] = np.power(10, df.logMstar)\n",
    "df['lin_err'] = df['lin_mass'] * np.log(10) * df.err_logMstar\n",
    "\n",
    "df = df.drop(['logMst','err_l'], axis=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file present: 80306\n",
      "data file missing: 107436\n"
     ]
    }
   ],
   "source": [
    "# df.SDSS_ID[:20].apply(lambda x: x)\n",
    "df['hasFile'] = df.SDSS_ID.apply(lambda x: os.path.isfile(dataFolder+x+'.npy'))\n",
    "\n",
    "print(\"data file present:\", len(df[df['hasFile']==True]))\n",
    "print(\"data file missing:\", len(df[df['hasFile']==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter images that have no known mass, no actual image, or with an unknown error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "      <th>logMstar</th>\n",
       "      <th>err_logMstar</th>\n",
       "      <th>Distance</th>\n",
       "      <th>lin_mass</th>\n",
       "      <th>lin_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>7.885100e+04</td>\n",
       "      <td>7.885100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>185.303775</td>\n",
       "      <td>25.672447</td>\n",
       "      <td>0.557644</td>\n",
       "      <td>0.058701</td>\n",
       "      <td>38.101843</td>\n",
       "      <td>0.487867</td>\n",
       "      <td>10.558197</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>251.574576</td>\n",
       "      <td>7.898269e+10</td>\n",
       "      <td>4.398954e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.111612</td>\n",
       "      <td>18.944782</td>\n",
       "      <td>0.194465</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>19.838329</td>\n",
       "      <td>0.270663</td>\n",
       "      <td>0.654456</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>139.570856</td>\n",
       "      <td>9.624108e+10</td>\n",
       "      <td>5.552716e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009450</td>\n",
       "      <td>-11.238420</td>\n",
       "      <td>0.407380</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>5.248929</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>7.376000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>42.857142</td>\n",
       "      <td>2.376840e+07</td>\n",
       "      <td>4.756699e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>154.486425</td>\n",
       "      <td>9.795145</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>24.390653</td>\n",
       "      <td>0.280915</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>144.857136</td>\n",
       "      <td>1.584893e+10</td>\n",
       "      <td>1.023221e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>186.753000</td>\n",
       "      <td>24.400580</td>\n",
       "      <td>0.489779</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>35.043089</td>\n",
       "      <td>0.434670</td>\n",
       "      <td>10.692000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>224.142852</td>\n",
       "      <td>4.920395e+10</td>\n",
       "      <td>2.693666e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>221.979375</td>\n",
       "      <td>40.093400</td>\n",
       "      <td>0.602560</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>47.500516</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>323.999992</td>\n",
       "      <td>1.071519e+11</td>\n",
       "      <td>5.603185e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.994900</td>\n",
       "      <td>70.133250</td>\n",
       "      <td>10.964781</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>1373.931687</td>\n",
       "      <td>2.450110</td>\n",
       "      <td>12.326000</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>1263.428628</td>\n",
       "      <td>2.118361e+12</td>\n",
       "      <td>1.414535e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RA           DEC           D25        redshi   GalSize_kpc  \\\n",
       "count  78851.000000  78851.000000  78851.000000  78851.000000  78851.000000   \n",
       "mean     185.303775     25.672447      0.557644      0.058701     38.101843   \n",
       "std       57.111612     18.944782      0.194465      0.032567     19.838329   \n",
       "min        0.009450    -11.238420      0.407380      0.010000      5.248929   \n",
       "25%      154.486425      9.795145      0.436516      0.033800     24.390653   \n",
       "50%      186.753000     24.400580      0.489779      0.052300     35.043089   \n",
       "75%      221.979375     40.093400      0.602560      0.075600     47.500516   \n",
       "max      359.994900     70.133250     10.964781      0.294800   1373.931687   \n",
       "\n",
       "          d_pix_kpc      logMstar  err_logMstar      Distance      lin_mass  \\\n",
       "count  78851.000000  78851.000000  78851.000000  78851.000000  7.885100e+04   \n",
       "mean       0.487867     10.558197      0.031070    251.574576  7.898269e+10   \n",
       "std        0.270663      0.654456      0.016953    139.570856  9.624108e+10   \n",
       "min        0.083111      7.376000      0.001000     42.857142  2.376840e+07   \n",
       "25%        0.280915     10.200000      0.019000    144.857136  1.584893e+10   \n",
       "50%        0.434670     10.692000      0.028000    224.142852  4.920395e+10   \n",
       "75%        0.628319     11.030000      0.039000    323.999992  1.071519e+11   \n",
       "max        2.450110     12.326000      0.778000   1263.428628  2.118361e+12   \n",
       "\n",
       "            lin_err  \n",
       "count  7.885100e+04  \n",
       "mean   4.398954e+09  \n",
       "std    5.552716e+09  \n",
       "min    4.756699e+05  \n",
       "25%    1.023221e+09  \n",
       "50%    2.693666e+09  \n",
       "75%    5.603185e+09  \n",
       "max    1.414535e+11  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.logMstar != -99]\n",
    "df = df[df.hasFile == True]\n",
    "df = df[df['lin_err']!=0]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDSS_ID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>D_Mpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "      <th>logMstar</th>\n",
       "      <th>err_logMstar</th>\n",
       "      <th>Distance</th>\n",
       "      <th>lin_mass</th>\n",
       "      <th>lin_err</th>\n",
       "      <th>hasFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237648721253957885</td>\n",
       "      <td>232.98435</td>\n",
       "      <td>-0.04219</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>73.628694</td>\n",
       "      <td>579.8571237495968</td>\n",
       "      <td>1.124491</td>\n",
       "      <td>11.186</td>\n",
       "      <td>0.022</td>\n",
       "      <td>579.857124</td>\n",
       "      <td>1.534617e+11</td>\n",
       "      <td>7.773890e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237658801497899152</td>\n",
       "      <td>172.27530</td>\n",
       "      <td>54.09419</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>38.365286</td>\n",
       "      <td>302.14286276272367</td>\n",
       "      <td>0.585932</td>\n",
       "      <td>11.044</td>\n",
       "      <td>0.022</td>\n",
       "      <td>302.142863</td>\n",
       "      <td>1.106624e+11</td>\n",
       "      <td>5.605810e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237678602386014376</td>\n",
       "      <td>16.90380</td>\n",
       "      <td>17.96906</td>\n",
       "      <td>0.407380</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>38.394687</td>\n",
       "      <td>323.9999924387251</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>10.796</td>\n",
       "      <td>0.034</td>\n",
       "      <td>323.999992</td>\n",
       "      <td>6.251727e+10</td>\n",
       "      <td>4.894345e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1237671261739942137</td>\n",
       "      <td>143.39220</td>\n",
       "      <td>13.57625</td>\n",
       "      <td>0.467735</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>50.322261</td>\n",
       "      <td>369.85714520726884</td>\n",
       "      <td>0.717247</td>\n",
       "      <td>11.065</td>\n",
       "      <td>0.019</td>\n",
       "      <td>369.857145</td>\n",
       "      <td>1.161449e+11</td>\n",
       "      <td>5.081235e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237661387617141036</td>\n",
       "      <td>246.39915</td>\n",
       "      <td>37.24876</td>\n",
       "      <td>0.512861</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>49.039348</td>\n",
       "      <td>328.7142940929958</td>\n",
       "      <td>0.637461</td>\n",
       "      <td>10.820</td>\n",
       "      <td>0.038</td>\n",
       "      <td>328.714294</td>\n",
       "      <td>6.606934e+10</td>\n",
       "      <td>5.780951e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SDSS_ID         RA       DEC       D25  redshi  GalSize_kpc  \\\n",
       "0  1237648721253957885  232.98435  -0.04219  0.436516  0.1353    73.628694   \n",
       "1  1237658801497899152  172.27530  54.09419  0.436516  0.0705    38.365286   \n",
       "2  1237678602386014376   16.90380  17.96906  0.407380  0.0756    38.394687   \n",
       "3  1237671261739942137  143.39220  13.57625  0.467735  0.0863    50.322261   \n",
       "4  1237661387617141036  246.39915  37.24876  0.512861  0.0767    49.039348   \n",
       "\n",
       "                D_Mpc  d_pix_kpc  logMstar  err_logMstar    Distance  \\\n",
       "0   579.8571237495968   1.124491    11.186         0.022  579.857124   \n",
       "1  302.14286276272367   0.585932    11.044         0.022  302.142863   \n",
       "2   323.9999924387251   0.628319    10.796         0.034  323.999992   \n",
       "3  369.85714520726884   0.717247    11.065         0.019  369.857145   \n",
       "4   328.7142940929958   0.637461    10.820         0.038  328.714294   \n",
       "\n",
       "       lin_mass       lin_err  hasFile  \n",
       "0  1.534617e+11  7.773890e+09     True  \n",
       "1  1.106624e+11  5.605810e+09     True  \n",
       "2  6.251727e+10  4.894345e+09     True  \n",
       "3  1.161449e+11  5.081235e+09     True  \n",
       "4  6.606934e+10  5.780951e+09     True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe4e66c8160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4e66c8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.logMstar.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78851\n"
     ]
    }
   ],
   "source": [
    "print(len(df.SDSS_ID.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration parameters defined here:\n",
    "\n",
    "- N is the number of galaxies to use for this run\n",
    "- M is the number of galaxies to train set (rest is holdout)\n",
    "- chunkSize is the number of galaxies to evaluate at once\n",
    "- prefixThisRound is the model name, for serialization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = int(len(df.SDSS_ID.values))\n",
    "M = int(N*.9)\n",
    "prefixThisRound = 'sp'\n",
    "for i in runNameParams:\n",
    "    prefixThisRound = prefixThisRound + '-' + i\n",
    "\n",
    "chunkSize = 200\n",
    "nSplits = 3\n",
    "\n",
    "# N = 3000 # number of galaxies to take into consideration\n",
    "# M = 2000 # train vs holdout\n",
    "\n",
    "\n",
    "# N = int(N*0.01)\n",
    "# M = int(M*0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = df.SDSS_ID.values[:N]\n",
    "Y = df.logMstar.values[:N]\n",
    "err = df.err_logMstar.values[:N]\n",
    "Y_lin = df.lin_mass.values[:N]\n",
    "err_lin = df.lin_err.values[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78851\n",
      "70965\n",
      "200\n",
      "sp-newSource-ReadLog1pNormCrop.75\n"
     ]
    }
   ],
   "source": [
    "print(N)\n",
    "print(M)\n",
    "print(chunkSize)\n",
    "print(prefixThisRound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crap instruction to make the auto execution stop here :p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call img_preproc on all images, per batches of \"chunkSize\"\n",
    "### Generate features based on the preprocessed images, pretrained networks and flux densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunkFileName(chunkSize, prefix, chunkNumber):\n",
    "    fileName = 'Xg3-'+str(chunkSize)+'-'+prefix+'-chunk-' + str(chunkNumber) + '.npy'\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefixThisRound = prefixThisRound + '-model6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'nthread': 4,\n",
    "    #'silent': True,\n",
    "    'num_leaves': 2**4,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 10,\n",
    "    'max_bin': 255,\n",
    "    #'subsample_for_bin': 50000,\n",
    "    #'subsample': 0.8,\n",
    "    #'subsample_freq': 1,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    #'reg_alpha': 1,\n",
    "    #'reg_lambda': 0,\n",
    "    #'min_split_gain': 0.5,\n",
    "    #'min_child_weight': 1,\n",
    "    #'min_child_samples': 60,\n",
    "    #'scale_pos_weight': 1,\n",
    "    'device' : 'gpu',\n",
    "    'metric' : 'rmse',\n",
    "    #'metric' : 'multi_error',\n",
    "    'verbose':0,          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatures(preProcessingNum):\n",
    "    Xg3r50 = []\n",
    "    Xg3vgg16 = []\n",
    "    postImgFeatures = []\n",
    "    csize=2\n",
    "    preImgFeatures = []\n",
    "\n",
    "    maxChunkNumber = math.ceil(len(ids)/chunkSize)\n",
    "    chunkStart = 0\n",
    "    # for chunkStart in tqdm(range(0, 3)):\n",
    "    for chunkStart in tqdm(range(0, len(ids), chunkSize)):\n",
    "        curChunk = int((chunkStart//chunkSize))\n",
    "        valuesInThisChunk = min(chunkStart+chunkSize,len(ids))-chunkStart\n",
    "\n",
    "        Xg_ = []\n",
    "        pre_ex_ = []\n",
    "\n",
    "        # preprocess the image and collect some raw image stats\n",
    "        for i in range(chunkStart, chunkStart+valuesInThisChunk):\n",
    "            X = read_image(ids[i])\n",
    "            Xg_.append(img_preprocnoread(X, preProcessingNum))\n",
    "            pre_ex_.append([\n",
    "                X.sum(),\n",
    "                X.min(),\n",
    "                X.max(),\n",
    "                X.mean(),\n",
    "                X.std(),\n",
    "                X[X.shape[0]//2,X.shape[1]//2],\n",
    "                np.mean(X[X.shape[0]//2-csize:X.shape[0]//2+csize,X.shape[1]//2-csize:X.shape[1]//2+csize]), # mean center\n",
    "                X.shape[0], \n",
    "            ])\n",
    "\n",
    "        # reformat the postprocessing\n",
    "        pre_ex = np.stack(pre_ex_)\n",
    "        Xg = np.stack(Xg_)\n",
    "\n",
    "        # collect some post processing stats\n",
    "        post_ex = np.hstack([\n",
    "            np.sum(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.min(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.max(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.mean(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.std(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            Xg[:,112,112].reshape(valuesInThisChunk,1),       # center\n",
    "            np.mean(Xg[:,112-csize:112+csize,112-csize:112+csize].reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,-1) # mean center\n",
    "            ])\n",
    "\n",
    "        Xg3 = np.zeros((valuesInThisChunk,224,224,3))\n",
    "        Xg3[:,:,:,:] = Xg.reshape(valuesInThisChunk,224,224,1)\n",
    "\n",
    "        # do r50 prediction\n",
    "        Xg3r50_ = r50.predict(Xg3).reshape(valuesInThisChunk, 2048)\n",
    "        Xg3vgg16_ = vgg16.predict(Xg3)\n",
    "\n",
    "\n",
    "        if chunkStart == 0:\n",
    "            Xg3r50 = Xg3r50_\n",
    "            Xg3vgg16 = Xg3vgg16_\n",
    "            preImgFeatures = pre_ex\n",
    "            postImgFeatures = post_ex\n",
    "        else:\n",
    "            Xg3r50 = np.concatenate([Xg3r50,Xg3r50_], axis=0)\n",
    "            Xg3vgg16 = np.concatenate([Xg3vgg16,Xg3vgg16_], axis=0)\n",
    "            preImgFeatures = np.concatenate([preImgFeatures,pre_ex], axis=0)\n",
    "            postImgFeatures = np.concatenate([postImgFeatures,post_ex], axis=0)\n",
    "\n",
    "    postImgFeatureNames = ['norm.flux.sum', 'norm.flux.min',\n",
    "                           'norm.flux.max', 'norm.flux.mean', \n",
    "                           'norm.flux.std', 'center.flux', \n",
    "                           'aroundCenter.flux']\n",
    "    preImgFeatureNames = ['pre.flux.sum', 'pre.flux.min', \n",
    "                          'pre.flux.max', 'pre.flux.mean',\n",
    "                          'pre.flux.std', 'pre.center.flux',\n",
    "                          'pre.aroundCenter.flux', 'width']\n",
    "\n",
    "\n",
    "    Xg3 = None\n",
    "    Xg = None\n",
    "    X = None\n",
    "\n",
    "    Distance = df.Distance.values[:N].reshape(N,1)\n",
    "\n",
    "    Xg3f = np.hstack ( ( \n",
    "            Xg3r50, \n",
    "            Xg3vgg16, \n",
    "            Distance,\n",
    "            1/Distance,\n",
    "            Distance**2,\n",
    "            1/(Distance**2),\n",
    "            Distance**3,\n",
    "            1/(Distance**3),\n",
    "            np.log(Distance),\n",
    "            1/np.log(Distance),\n",
    "            np.log(Distance**2),\n",
    "            1/np.log(Distance**2),\n",
    "            np.log(Distance)**2,\n",
    "            1/np.log(Distance)**2,\n",
    "            preImgFeatures,\n",
    "            postImgFeatures\n",
    "            ) )\n",
    "\n",
    "    distanceNames = ['D', '1/D', 'D**2', '1/D**2', 'D**3', '1/D**3', 'log(D)', '1/log(D)', 'log(D**2)', 'log(1/D**2)', 'log(D)**2', '1/log(D)**2' ]\n",
    "\n",
    "    # extraImgFeatureNames = ['norm.flux.sum', 'norm.flux.min', 'norm.flux.max', 'norm.flux.mean', 'norm.flux.std', 'center.flux', 'aroundCenter.flux']\n",
    "\n",
    "    Xg3fNames = ( [prefixThisRound+'.r50.' + str(i) for i in range(Xg3r50.shape[1])]\n",
    "                + [prefixThisRound+'.vgg16.' + str(i) for i in range(Xg3vgg16.shape[1])] \n",
    "                + [prefixThisRound+'.'+ n for n in distanceNames]\n",
    "                + [prefixThisRound+'.'+ n for n in preImgFeatureNames]\n",
    "                + [prefixThisRound+'.'+ n for n in postImgFeatureNames])\n",
    "\n",
    "    print(len(Xg3fNames), Xg3f.shape)\n",
    "    \n",
    "    return Xg3f, Xg3fNames\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getModels(trainSet, YSet):\n",
    "    kf = KFold(n_splits=nSplits,shuffle=True, random_state=220673)\n",
    "\n",
    "    cvtrainpreds = np.zeros([len(Xg3f),nSplits])\n",
    "    models = []\n",
    "    xis, linxis = [],[]\n",
    "    counter = 0\n",
    "    for tix, vix in kf.split(trainSet):\n",
    "        X_train, X_test = trainSet[tix], trainSet[vix]\n",
    "        Y_train, Y_test = YSet[tix], YSet[vix]\n",
    "\n",
    "        lgb_train = lgbm.Dataset(X_train, Y_train)\n",
    "        lgb_eval = lgbm.Dataset(X_test, Y_test)\n",
    "\n",
    "        gbm = lgbm.train(lgbm_params,\n",
    "                           lgb_train,\n",
    "                           num_boost_round=20000,\n",
    "                           valid_sets=[lgb_train,lgb_eval],  # eval training data\n",
    "                           verbose_eval=100,\n",
    "                           early_stopping_rounds=100\n",
    "                        )\n",
    "        models.append(gbm)\n",
    "\n",
    "        p = gbm.predict(X_test)\n",
    "        chiSq = xi2(Y_test,p,err[vix])\n",
    "        linChiSq = xi2(10**Y_test,10**p,err_lin[vix])\n",
    "        xis.append(chiSq)\n",
    "        linxis.append(linChiSq)\n",
    "        print(counter,chiSq,linChiSq)    \n",
    "\n",
    "        cvtrainpreds[vix,counter] = p\n",
    "        counter = counter+1\n",
    "        \n",
    "    return models, cvtrainpreds, xis, linxis\n",
    "\n",
    "# models, cvtrainpreds, xis, linxis = getModels(Xg3f[:M], Y[:M])\n",
    "\n",
    "# print(models, cvtrainpreds)\n",
    "\n",
    "# print(xis, linxis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:09<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356514\tvalid_1's rmse: 0.354764\n",
      "[200]\ttraining's rmse: 0.258598\tvalid_1's rmse: 0.259958\n",
      "[300]\ttraining's rmse: 0.225951\tvalid_1's rmse: 0.229552\n",
      "[400]\ttraining's rmse: 0.211316\tvalid_1's rmse: 0.216831\n",
      "[500]\ttraining's rmse: 0.20238\tvalid_1's rmse: 0.209603\n",
      "[600]\ttraining's rmse: 0.195793\tvalid_1's rmse: 0.20471\n",
      "[700]\ttraining's rmse: 0.190659\tvalid_1's rmse: 0.201161\n",
      "[800]\ttraining's rmse: 0.186503\tvalid_1's rmse: 0.198398\n",
      "[900]\ttraining's rmse: 0.182913\tvalid_1's rmse: 0.196235\n",
      "[1000]\ttraining's rmse: 0.179845\tvalid_1's rmse: 0.194494\n",
      "[1100]\ttraining's rmse: 0.177149\tvalid_1's rmse: 0.193127\n",
      "[1200]\ttraining's rmse: 0.174717\tvalid_1's rmse: 0.19195\n",
      "[1300]\ttraining's rmse: 0.172526\tvalid_1's rmse: 0.190967\n",
      "[1400]\ttraining's rmse: 0.170548\tvalid_1's rmse: 0.190263\n",
      "[1500]\ttraining's rmse: 0.168729\tvalid_1's rmse: 0.189656\n",
      "[1600]\ttraining's rmse: 0.166998\tvalid_1's rmse: 0.189097\n",
      "[1700]\ttraining's rmse: 0.165362\tvalid_1's rmse: 0.188606\n",
      "[1800]\ttraining's rmse: 0.163841\tvalid_1's rmse: 0.188193\n",
      "[1900]\ttraining's rmse: 0.162356\tvalid_1's rmse: 0.18782\n",
      "[2000]\ttraining's rmse: 0.160932\tvalid_1's rmse: 0.187453\n",
      "[2100]\ttraining's rmse: 0.15957\tvalid_1's rmse: 0.187099\n",
      "[2200]\ttraining's rmse: 0.158265\tvalid_1's rmse: 0.186782\n",
      "[2300]\ttraining's rmse: 0.157007\tvalid_1's rmse: 0.186508\n",
      "[2400]\ttraining's rmse: 0.155771\tvalid_1's rmse: 0.186262\n",
      "[2500]\ttraining's rmse: 0.154607\tvalid_1's rmse: 0.186052\n",
      "[2600]\ttraining's rmse: 0.153464\tvalid_1's rmse: 0.18585\n",
      "[2700]\ttraining's rmse: 0.152318\tvalid_1's rmse: 0.185649\n",
      "[2800]\ttraining's rmse: 0.151236\tvalid_1's rmse: 0.185474\n",
      "[2900]\ttraining's rmse: 0.150176\tvalid_1's rmse: 0.185303\n",
      "[3000]\ttraining's rmse: 0.14915\tvalid_1's rmse: 0.185158\n",
      "[3100]\ttraining's rmse: 0.148115\tvalid_1's rmse: 0.184981\n",
      "[3200]\ttraining's rmse: 0.147149\tvalid_1's rmse: 0.184852\n",
      "[3300]\ttraining's rmse: 0.146162\tvalid_1's rmse: 0.184703\n",
      "[3400]\ttraining's rmse: 0.145213\tvalid_1's rmse: 0.184583\n",
      "[3500]\ttraining's rmse: 0.144257\tvalid_1's rmse: 0.184426\n",
      "[3600]\ttraining's rmse: 0.143351\tvalid_1's rmse: 0.184314\n",
      "[3700]\ttraining's rmse: 0.142452\tvalid_1's rmse: 0.184202\n",
      "[3800]\ttraining's rmse: 0.14157\tvalid_1's rmse: 0.184107\n",
      "[3900]\ttraining's rmse: 0.140708\tvalid_1's rmse: 0.183986\n",
      "[4000]\ttraining's rmse: 0.13985\tvalid_1's rmse: 0.183878\n",
      "[4100]\ttraining's rmse: 0.139013\tvalid_1's rmse: 0.183786\n",
      "[4200]\ttraining's rmse: 0.138181\tvalid_1's rmse: 0.183703\n",
      "[4300]\ttraining's rmse: 0.137345\tvalid_1's rmse: 0.183596\n",
      "[4400]\ttraining's rmse: 0.136531\tvalid_1's rmse: 0.183511\n",
      "[4500]\ttraining's rmse: 0.135734\tvalid_1's rmse: 0.183423\n",
      "[4600]\ttraining's rmse: 0.134934\tvalid_1's rmse: 0.183339\n",
      "[4700]\ttraining's rmse: 0.134153\tvalid_1's rmse: 0.183264\n",
      "[4800]\ttraining's rmse: 0.133381\tvalid_1's rmse: 0.183195\n",
      "[4900]\ttraining's rmse: 0.132616\tvalid_1's rmse: 0.183127\n",
      "[5000]\ttraining's rmse: 0.131846\tvalid_1's rmse: 0.183072\n",
      "[5100]\ttraining's rmse: 0.131117\tvalid_1's rmse: 0.182993\n",
      "[5200]\ttraining's rmse: 0.130371\tvalid_1's rmse: 0.182933\n",
      "[5300]\ttraining's rmse: 0.129639\tvalid_1's rmse: 0.182876\n",
      "[5400]\ttraining's rmse: 0.128914\tvalid_1's rmse: 0.182835\n",
      "[5500]\ttraining's rmse: 0.1282\tvalid_1's rmse: 0.182784\n",
      "[5600]\ttraining's rmse: 0.127487\tvalid_1's rmse: 0.182741\n",
      "[5700]\ttraining's rmse: 0.126797\tvalid_1's rmse: 0.182694\n",
      "[5800]\ttraining's rmse: 0.126107\tvalid_1's rmse: 0.182645\n",
      "[5900]\ttraining's rmse: 0.125436\tvalid_1's rmse: 0.182598\n",
      "[6000]\ttraining's rmse: 0.124758\tvalid_1's rmse: 0.182549\n",
      "[6100]\ttraining's rmse: 0.124081\tvalid_1's rmse: 0.182514\n",
      "[6200]\ttraining's rmse: 0.123429\tvalid_1's rmse: 0.18248\n",
      "[6300]\ttraining's rmse: 0.122782\tvalid_1's rmse: 0.18244\n",
      "[6400]\ttraining's rmse: 0.122131\tvalid_1's rmse: 0.182401\n",
      "[6500]\ttraining's rmse: 0.121506\tvalid_1's rmse: 0.182354\n",
      "[6600]\ttraining's rmse: 0.120869\tvalid_1's rmse: 0.182322\n",
      "[6700]\ttraining's rmse: 0.12025\tvalid_1's rmse: 0.18229\n",
      "[6800]\ttraining's rmse: 0.119647\tvalid_1's rmse: 0.182254\n",
      "[6900]\ttraining's rmse: 0.119024\tvalid_1's rmse: 0.182219\n",
      "[7000]\ttraining's rmse: 0.118433\tvalid_1's rmse: 0.182186\n",
      "[7100]\ttraining's rmse: 0.117832\tvalid_1's rmse: 0.182149\n",
      "[7200]\ttraining's rmse: 0.117239\tvalid_1's rmse: 0.182112\n",
      "[7300]\ttraining's rmse: 0.116649\tvalid_1's rmse: 0.182079\n",
      "[7400]\ttraining's rmse: 0.116056\tvalid_1's rmse: 0.182044\n",
      "[7500]\ttraining's rmse: 0.115477\tvalid_1's rmse: 0.182004\n",
      "[7600]\ttraining's rmse: 0.114897\tvalid_1's rmse: 0.181966\n",
      "[7700]\ttraining's rmse: 0.114315\tvalid_1's rmse: 0.181948\n",
      "[7800]\ttraining's rmse: 0.113743\tvalid_1's rmse: 0.181917\n",
      "[7900]\ttraining's rmse: 0.113175\tvalid_1's rmse: 0.181878\n",
      "[8000]\ttraining's rmse: 0.112618\tvalid_1's rmse: 0.181851\n",
      "[8100]\ttraining's rmse: 0.112069\tvalid_1's rmse: 0.181834\n",
      "[8200]\ttraining's rmse: 0.111509\tvalid_1's rmse: 0.181798\n",
      "[8300]\ttraining's rmse: 0.110964\tvalid_1's rmse: 0.18177\n",
      "[8400]\ttraining's rmse: 0.110428\tvalid_1's rmse: 0.181736\n",
      "[8500]\ttraining's rmse: 0.109891\tvalid_1's rmse: 0.181708\n",
      "[8600]\ttraining's rmse: 0.109365\tvalid_1's rmse: 0.181676\n",
      "[8700]\ttraining's rmse: 0.108846\tvalid_1's rmse: 0.181669\n",
      "[8800]\ttraining's rmse: 0.108322\tvalid_1's rmse: 0.18164\n",
      "[8900]\ttraining's rmse: 0.107786\tvalid_1's rmse: 0.181599\n",
      "[9000]\ttraining's rmse: 0.107281\tvalid_1's rmse: 0.181582\n",
      "[9100]\ttraining's rmse: 0.106763\tvalid_1's rmse: 0.181561\n",
      "[9200]\ttraining's rmse: 0.106255\tvalid_1's rmse: 0.181542\n",
      "[9300]\ttraining's rmse: 0.10575\tvalid_1's rmse: 0.18152\n",
      "[9400]\ttraining's rmse: 0.105241\tvalid_1's rmse: 0.181498\n",
      "[9500]\ttraining's rmse: 0.10474\tvalid_1's rmse: 0.181478\n",
      "[9600]\ttraining's rmse: 0.104258\tvalid_1's rmse: 0.181455\n",
      "[9700]\ttraining's rmse: 0.10377\tvalid_1's rmse: 0.181443\n",
      "[9800]\ttraining's rmse: 0.103287\tvalid_1's rmse: 0.181413\n",
      "[9900]\ttraining's rmse: 0.102798\tvalid_1's rmse: 0.181385\n",
      "[10000]\ttraining's rmse: 0.10234\tvalid_1's rmse: 0.181364\n",
      "[10100]\ttraining's rmse: 0.101853\tvalid_1's rmse: 0.181338\n",
      "[10200]\ttraining's rmse: 0.101383\tvalid_1's rmse: 0.181304\n",
      "[10300]\ttraining's rmse: 0.100911\tvalid_1's rmse: 0.18129\n",
      "[10400]\ttraining's rmse: 0.10042\tvalid_1's rmse: 0.181267\n",
      "[10500]\ttraining's rmse: 0.0999442\tvalid_1's rmse: 0.181262\n",
      "[10600]\ttraining's rmse: 0.0994922\tvalid_1's rmse: 0.181248\n",
      "[10700]\ttraining's rmse: 0.0990446\tvalid_1's rmse: 0.181236\n",
      "[10800]\ttraining's rmse: 0.0985689\tvalid_1's rmse: 0.18122\n",
      "[10900]\ttraining's rmse: 0.0981158\tvalid_1's rmse: 0.181207\n",
      "[11000]\ttraining's rmse: 0.0976588\tvalid_1's rmse: 0.181191\n",
      "[11100]\ttraining's rmse: 0.0972225\tvalid_1's rmse: 0.18117\n",
      "[11200]\ttraining's rmse: 0.0967833\tvalid_1's rmse: 0.181147\n",
      "[11300]\ttraining's rmse: 0.096333\tvalid_1's rmse: 0.181132\n",
      "[11400]\ttraining's rmse: 0.0958844\tvalid_1's rmse: 0.18112\n",
      "[11500]\ttraining's rmse: 0.095446\tvalid_1's rmse: 0.181103\n",
      "[11600]\ttraining's rmse: 0.0950304\tvalid_1's rmse: 0.181095\n",
      "[11700]\ttraining's rmse: 0.094595\tvalid_1's rmse: 0.18107\n",
      "[11800]\ttraining's rmse: 0.0941622\tvalid_1's rmse: 0.181052\n",
      "[11900]\ttraining's rmse: 0.0937274\tvalid_1's rmse: 0.181026\n",
      "[12000]\ttraining's rmse: 0.0933012\tvalid_1's rmse: 0.181007\n",
      "[12100]\ttraining's rmse: 0.092882\tvalid_1's rmse: 0.180992\n",
      "[12200]\ttraining's rmse: 0.0924601\tvalid_1's rmse: 0.180982\n",
      "[12300]\ttraining's rmse: 0.0920503\tvalid_1's rmse: 0.180965\n",
      "[12400]\ttraining's rmse: 0.0916532\tvalid_1's rmse: 0.180947\n",
      "[12500]\ttraining's rmse: 0.0912459\tvalid_1's rmse: 0.180943\n",
      "[12600]\ttraining's rmse: 0.0908371\tvalid_1's rmse: 0.180924\n",
      "[12700]\ttraining's rmse: 0.0904273\tvalid_1's rmse: 0.180914\n",
      "[12800]\ttraining's rmse: 0.0900324\tvalid_1's rmse: 0.180902\n",
      "[12900]\ttraining's rmse: 0.0896471\tvalid_1's rmse: 0.180889\n",
      "[13000]\ttraining's rmse: 0.0892514\tvalid_1's rmse: 0.180873\n",
      "[13100]\ttraining's rmse: 0.0888466\tvalid_1's rmse: 0.180864\n",
      "[13200]\ttraining's rmse: 0.088469\tvalid_1's rmse: 0.180856\n",
      "[13300]\ttraining's rmse: 0.0880748\tvalid_1's rmse: 0.180843\n",
      "[13400]\ttraining's rmse: 0.0876966\tvalid_1's rmse: 0.180825\n",
      "[13500]\ttraining's rmse: 0.087307\tvalid_1's rmse: 0.180815\n",
      "[13600]\ttraining's rmse: 0.0869332\tvalid_1's rmse: 0.180806\n",
      "Early stopping, best iteration is:\n",
      "[13577]\ttraining's rmse: 0.0870165\tvalid_1's rmse: 0.180803\n",
      "0 78.4684834286 112.691843817\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355378\tvalid_1's rmse: 0.360873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 0.258087\tvalid_1's rmse: 0.26427\n",
      "[300]\ttraining's rmse: 0.225429\tvalid_1's rmse: 0.232395\n",
      "[400]\ttraining's rmse: 0.210858\tvalid_1's rmse: 0.218794\n",
      "[500]\ttraining's rmse: 0.201983\tvalid_1's rmse: 0.211099\n",
      "[600]\ttraining's rmse: 0.195481\tvalid_1's rmse: 0.206035\n",
      "[700]\ttraining's rmse: 0.190462\tvalid_1's rmse: 0.202397\n",
      "[800]\ttraining's rmse: 0.186328\tvalid_1's rmse: 0.199561\n",
      "[900]\ttraining's rmse: 0.182783\tvalid_1's rmse: 0.197373\n",
      "[1000]\ttraining's rmse: 0.179744\tvalid_1's rmse: 0.195641\n",
      "[1100]\ttraining's rmse: 0.177004\tvalid_1's rmse: 0.194229\n",
      "[1200]\ttraining's rmse: 0.174587\tvalid_1's rmse: 0.193149\n",
      "[1300]\ttraining's rmse: 0.172392\tvalid_1's rmse: 0.192244\n",
      "[1400]\ttraining's rmse: 0.170399\tvalid_1's rmse: 0.191454\n",
      "[1500]\ttraining's rmse: 0.168551\tvalid_1's rmse: 0.190789\n",
      "[1600]\ttraining's rmse: 0.166832\tvalid_1's rmse: 0.19025\n",
      "[1700]\ttraining's rmse: 0.1652\tvalid_1's rmse: 0.189825\n",
      "[1800]\ttraining's rmse: 0.163652\tvalid_1's rmse: 0.18942\n",
      "[1900]\ttraining's rmse: 0.162187\tvalid_1's rmse: 0.189077\n",
      "[2000]\ttraining's rmse: 0.160805\tvalid_1's rmse: 0.188763\n",
      "[2100]\ttraining's rmse: 0.159475\tvalid_1's rmse: 0.188477\n",
      "[2200]\ttraining's rmse: 0.158192\tvalid_1's rmse: 0.188212\n",
      "[2300]\ttraining's rmse: 0.156937\tvalid_1's rmse: 0.187931\n",
      "[2400]\ttraining's rmse: 0.155717\tvalid_1's rmse: 0.187693\n",
      "[2500]\ttraining's rmse: 0.154549\tvalid_1's rmse: 0.18748\n",
      "[2600]\ttraining's rmse: 0.153427\tvalid_1's rmse: 0.187269\n",
      "[2700]\ttraining's rmse: 0.152337\tvalid_1's rmse: 0.187068\n",
      "[2800]\ttraining's rmse: 0.151255\tvalid_1's rmse: 0.186884\n",
      "[2900]\ttraining's rmse: 0.150211\tvalid_1's rmse: 0.186714\n",
      "[3000]\ttraining's rmse: 0.149161\tvalid_1's rmse: 0.186562\n",
      "[3100]\ttraining's rmse: 0.148138\tvalid_1's rmse: 0.186413\n",
      "[3200]\ttraining's rmse: 0.147115\tvalid_1's rmse: 0.186257\n",
      "[3300]\ttraining's rmse: 0.146113\tvalid_1's rmse: 0.186131\n",
      "[3400]\ttraining's rmse: 0.145137\tvalid_1's rmse: 0.186005\n",
      "[3500]\ttraining's rmse: 0.14419\tvalid_1's rmse: 0.185884\n",
      "[3600]\ttraining's rmse: 0.143225\tvalid_1's rmse: 0.185766\n",
      "[3700]\ttraining's rmse: 0.142303\tvalid_1's rmse: 0.185661\n",
      "[3800]\ttraining's rmse: 0.141412\tvalid_1's rmse: 0.185549\n",
      "[3900]\ttraining's rmse: 0.140548\tvalid_1's rmse: 0.185455\n",
      "[4000]\ttraining's rmse: 0.139667\tvalid_1's rmse: 0.185362\n",
      "[4100]\ttraining's rmse: 0.138814\tvalid_1's rmse: 0.185277\n",
      "[4200]\ttraining's rmse: 0.13799\tvalid_1's rmse: 0.185178\n",
      "[4300]\ttraining's rmse: 0.137145\tvalid_1's rmse: 0.185098\n",
      "[4400]\ttraining's rmse: 0.136337\tvalid_1's rmse: 0.185028\n",
      "[4500]\ttraining's rmse: 0.135538\tvalid_1's rmse: 0.184949\n",
      "[4600]\ttraining's rmse: 0.134747\tvalid_1's rmse: 0.18487\n",
      "[4700]\ttraining's rmse: 0.133976\tvalid_1's rmse: 0.184796\n",
      "[4800]\ttraining's rmse: 0.133211\tvalid_1's rmse: 0.184725\n",
      "[4900]\ttraining's rmse: 0.132446\tvalid_1's rmse: 0.184651\n",
      "[5000]\ttraining's rmse: 0.131689\tvalid_1's rmse: 0.18459\n",
      "[5100]\ttraining's rmse: 0.130942\tvalid_1's rmse: 0.184533\n",
      "[5200]\ttraining's rmse: 0.130204\tvalid_1's rmse: 0.184466\n",
      "[5300]\ttraining's rmse: 0.129495\tvalid_1's rmse: 0.184413\n",
      "[5400]\ttraining's rmse: 0.128789\tvalid_1's rmse: 0.18436\n",
      "[5500]\ttraining's rmse: 0.128076\tvalid_1's rmse: 0.184309\n",
      "[5600]\ttraining's rmse: 0.127391\tvalid_1's rmse: 0.184261\n",
      "[5700]\ttraining's rmse: 0.126697\tvalid_1's rmse: 0.184204\n",
      "[5800]\ttraining's rmse: 0.126016\tvalid_1's rmse: 0.18416\n",
      "[5900]\ttraining's rmse: 0.125339\tvalid_1's rmse: 0.184102\n",
      "[6000]\ttraining's rmse: 0.124656\tvalid_1's rmse: 0.184068\n",
      "[6100]\ttraining's rmse: 0.124009\tvalid_1's rmse: 0.184014\n",
      "[6200]\ttraining's rmse: 0.123342\tvalid_1's rmse: 0.183964\n",
      "[6300]\ttraining's rmse: 0.122699\tvalid_1's rmse: 0.183933\n",
      "[6400]\ttraining's rmse: 0.122078\tvalid_1's rmse: 0.183899\n",
      "[6500]\ttraining's rmse: 0.121462\tvalid_1's rmse: 0.183867\n",
      "[6600]\ttraining's rmse: 0.120823\tvalid_1's rmse: 0.183814\n",
      "[6700]\ttraining's rmse: 0.120189\tvalid_1's rmse: 0.18377\n",
      "[6800]\ttraining's rmse: 0.11956\tvalid_1's rmse: 0.183728\n",
      "[6900]\ttraining's rmse: 0.118943\tvalid_1's rmse: 0.183671\n",
      "[7000]\ttraining's rmse: 0.118341\tvalid_1's rmse: 0.183616\n",
      "[7100]\ttraining's rmse: 0.11773\tvalid_1's rmse: 0.183574\n",
      "[7200]\ttraining's rmse: 0.117147\tvalid_1's rmse: 0.183546\n",
      "[7300]\ttraining's rmse: 0.116533\tvalid_1's rmse: 0.18349\n",
      "[7400]\ttraining's rmse: 0.115961\tvalid_1's rmse: 0.183467\n",
      "[7500]\ttraining's rmse: 0.115358\tvalid_1's rmse: 0.183427\n",
      "[7600]\ttraining's rmse: 0.114786\tvalid_1's rmse: 0.183381\n",
      "[7700]\ttraining's rmse: 0.114213\tvalid_1's rmse: 0.183354\n",
      "[7800]\ttraining's rmse: 0.113646\tvalid_1's rmse: 0.183328\n",
      "[7900]\ttraining's rmse: 0.113082\tvalid_1's rmse: 0.183293\n",
      "[8000]\ttraining's rmse: 0.11251\tvalid_1's rmse: 0.18327\n",
      "[8100]\ttraining's rmse: 0.111943\tvalid_1's rmse: 0.183246\n",
      "[8200]\ttraining's rmse: 0.111413\tvalid_1's rmse: 0.183238\n",
      "[8300]\ttraining's rmse: 0.11086\tvalid_1's rmse: 0.183197\n",
      "[8400]\ttraining's rmse: 0.110311\tvalid_1's rmse: 0.183153\n",
      "[8500]\ttraining's rmse: 0.10977\tvalid_1's rmse: 0.183118\n",
      "[8600]\ttraining's rmse: 0.109246\tvalid_1's rmse: 0.183089\n",
      "[8700]\ttraining's rmse: 0.108708\tvalid_1's rmse: 0.183064\n",
      "[8800]\ttraining's rmse: 0.108184\tvalid_1's rmse: 0.183044\n",
      "[8900]\ttraining's rmse: 0.107682\tvalid_1's rmse: 0.183016\n",
      "[9000]\ttraining's rmse: 0.107162\tvalid_1's rmse: 0.182996\n",
      "[9100]\ttraining's rmse: 0.106643\tvalid_1's rmse: 0.182961\n",
      "[9200]\ttraining's rmse: 0.106144\tvalid_1's rmse: 0.182931\n",
      "[9300]\ttraining's rmse: 0.105654\tvalid_1's rmse: 0.182904\n",
      "[9400]\ttraining's rmse: 0.105162\tvalid_1's rmse: 0.182877\n",
      "[9500]\ttraining's rmse: 0.104656\tvalid_1's rmse: 0.182844\n",
      "[9600]\ttraining's rmse: 0.104154\tvalid_1's rmse: 0.182824\n",
      "[9700]\ttraining's rmse: 0.103678\tvalid_1's rmse: 0.1828\n",
      "[9800]\ttraining's rmse: 0.103184\tvalid_1's rmse: 0.182763\n",
      "[9900]\ttraining's rmse: 0.102698\tvalid_1's rmse: 0.182738\n",
      "[10000]\ttraining's rmse: 0.102206\tvalid_1's rmse: 0.182712\n",
      "[10100]\ttraining's rmse: 0.101715\tvalid_1's rmse: 0.182681\n",
      "[10200]\ttraining's rmse: 0.101244\tvalid_1's rmse: 0.182645\n",
      "[10300]\ttraining's rmse: 0.100773\tvalid_1's rmse: 0.182625\n",
      "[10400]\ttraining's rmse: 0.100303\tvalid_1's rmse: 0.182597\n",
      "[10500]\ttraining's rmse: 0.0998263\tvalid_1's rmse: 0.182566\n",
      "[10600]\ttraining's rmse: 0.0993573\tvalid_1's rmse: 0.182547\n",
      "[10700]\ttraining's rmse: 0.0989015\tvalid_1's rmse: 0.182521\n",
      "[10800]\ttraining's rmse: 0.0984483\tvalid_1's rmse: 0.182494\n",
      "[10900]\ttraining's rmse: 0.0980037\tvalid_1's rmse: 0.182483\n",
      "[11000]\ttraining's rmse: 0.0975519\tvalid_1's rmse: 0.182464\n",
      "[11100]\ttraining's rmse: 0.0971123\tvalid_1's rmse: 0.182443\n",
      "[11200]\ttraining's rmse: 0.0966694\tvalid_1's rmse: 0.182417\n",
      "[11300]\ttraining's rmse: 0.0962351\tvalid_1's rmse: 0.182393\n",
      "[11400]\ttraining's rmse: 0.0958052\tvalid_1's rmse: 0.182378\n",
      "[11500]\ttraining's rmse: 0.0953848\tvalid_1's rmse: 0.182354\n",
      "[11600]\ttraining's rmse: 0.0949419\tvalid_1's rmse: 0.182328\n",
      "[11700]\ttraining's rmse: 0.0945236\tvalid_1's rmse: 0.182308\n",
      "[11800]\ttraining's rmse: 0.0940978\tvalid_1's rmse: 0.182288\n",
      "[11900]\ttraining's rmse: 0.0936845\tvalid_1's rmse: 0.182278\n",
      "[12000]\ttraining's rmse: 0.093254\tvalid_1's rmse: 0.182255\n",
      "[12100]\ttraining's rmse: 0.092834\tvalid_1's rmse: 0.182229\n",
      "[12200]\ttraining's rmse: 0.0924095\tvalid_1's rmse: 0.182209\n",
      "[12300]\ttraining's rmse: 0.092006\tvalid_1's rmse: 0.182194\n",
      "[12400]\ttraining's rmse: 0.0915823\tvalid_1's rmse: 0.182189\n",
      "[12500]\ttraining's rmse: 0.091183\tvalid_1's rmse: 0.18218\n",
      "[12600]\ttraining's rmse: 0.090778\tvalid_1's rmse: 0.182164\n",
      "[12700]\ttraining's rmse: 0.0903748\tvalid_1's rmse: 0.18215\n",
      "[12800]\ttraining's rmse: 0.0899831\tvalid_1's rmse: 0.182141\n",
      "[12900]\ttraining's rmse: 0.0895786\tvalid_1's rmse: 0.182129\n",
      "[13000]\ttraining's rmse: 0.089201\tvalid_1's rmse: 0.182115\n",
      "[13100]\ttraining's rmse: 0.088796\tvalid_1's rmse: 0.1821\n",
      "[13200]\ttraining's rmse: 0.0884023\tvalid_1's rmse: 0.182093\n",
      "[13300]\ttraining's rmse: 0.0879996\tvalid_1's rmse: 0.182083\n",
      "[13400]\ttraining's rmse: 0.0876031\tvalid_1's rmse: 0.182072\n",
      "[13500]\ttraining's rmse: 0.0872208\tvalid_1's rmse: 0.182063\n",
      "[13600]\ttraining's rmse: 0.0868399\tvalid_1's rmse: 0.182055\n",
      "[13700]\ttraining's rmse: 0.086463\tvalid_1's rmse: 0.182042\n",
      "[13800]\ttraining's rmse: 0.0860845\tvalid_1's rmse: 0.182028\n",
      "[13900]\ttraining's rmse: 0.0857037\tvalid_1's rmse: 0.182012\n",
      "[14000]\ttraining's rmse: 0.0853451\tvalid_1's rmse: 0.182013\n",
      "[14100]\ttraining's rmse: 0.0849774\tvalid_1's rmse: 0.181998\n",
      "[14200]\ttraining's rmse: 0.0846096\tvalid_1's rmse: 0.181987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14300]\ttraining's rmse: 0.0842411\tvalid_1's rmse: 0.181972\n",
      "[14400]\ttraining's rmse: 0.0838744\tvalid_1's rmse: 0.181963\n",
      "[14500]\ttraining's rmse: 0.0835018\tvalid_1's rmse: 0.181946\n",
      "[14600]\ttraining's rmse: 0.0831339\tvalid_1's rmse: 0.181934\n",
      "[14700]\ttraining's rmse: 0.0827706\tvalid_1's rmse: 0.181931\n",
      "[14800]\ttraining's rmse: 0.0824132\tvalid_1's rmse: 0.181929\n",
      "[14900]\ttraining's rmse: 0.0820728\tvalid_1's rmse: 0.181918\n",
      "[15000]\ttraining's rmse: 0.0817249\tvalid_1's rmse: 0.181908\n",
      "[15100]\ttraining's rmse: 0.081377\tvalid_1's rmse: 0.181897\n",
      "[15200]\ttraining's rmse: 0.081024\tvalid_1's rmse: 0.181884\n",
      "[15300]\ttraining's rmse: 0.080686\tvalid_1's rmse: 0.181883\n",
      "[15400]\ttraining's rmse: 0.0803629\tvalid_1's rmse: 0.181877\n",
      "[15500]\ttraining's rmse: 0.080017\tvalid_1's rmse: 0.18187\n",
      "[15600]\ttraining's rmse: 0.0796953\tvalid_1's rmse: 0.18186\n",
      "[15700]\ttraining's rmse: 0.0793579\tvalid_1's rmse: 0.181852\n",
      "[15800]\ttraining's rmse: 0.0790124\tvalid_1's rmse: 0.181839\n",
      "[15900]\ttraining's rmse: 0.0786779\tvalid_1's rmse: 0.181829\n",
      "[16000]\ttraining's rmse: 0.0783436\tvalid_1's rmse: 0.181825\n",
      "[16100]\ttraining's rmse: 0.0780289\tvalid_1's rmse: 0.181811\n",
      "[16200]\ttraining's rmse: 0.0776977\tvalid_1's rmse: 0.181798\n",
      "[16300]\ttraining's rmse: 0.0773667\tvalid_1's rmse: 0.181794\n",
      "[16400]\ttraining's rmse: 0.0770458\tvalid_1's rmse: 0.181794\n",
      "[16500]\ttraining's rmse: 0.076723\tvalid_1's rmse: 0.181785\n",
      "[16600]\ttraining's rmse: 0.0764095\tvalid_1's rmse: 0.18178\n",
      "[16700]\ttraining's rmse: 0.0760981\tvalid_1's rmse: 0.181773\n",
      "[16800]\ttraining's rmse: 0.0757804\tvalid_1's rmse: 0.181765\n",
      "[16900]\ttraining's rmse: 0.0754583\tvalid_1's rmse: 0.181761\n",
      "[17000]\ttraining's rmse: 0.0751457\tvalid_1's rmse: 0.181755\n",
      "[17100]\ttraining's rmse: 0.074839\tvalid_1's rmse: 0.181746\n",
      "[17200]\ttraining's rmse: 0.0745354\tvalid_1's rmse: 0.181733\n",
      "[17300]\ttraining's rmse: 0.0742329\tvalid_1's rmse: 0.181728\n",
      "[17400]\ttraining's rmse: 0.0739315\tvalid_1's rmse: 0.181723\n",
      "[17500]\ttraining's rmse: 0.0736331\tvalid_1's rmse: 0.181714\n",
      "[17600]\ttraining's rmse: 0.0733213\tvalid_1's rmse: 0.181712\n",
      "[17700]\ttraining's rmse: 0.0730223\tvalid_1's rmse: 0.181706\n",
      "[17800]\ttraining's rmse: 0.0727203\tvalid_1's rmse: 0.1817\n",
      "Early stopping, best iteration is:\n",
      "[17793]\ttraining's rmse: 0.0727418\tvalid_1's rmse: 0.181699\n",
      "1 77.5949791596 3216.9670334\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356363\tvalid_1's rmse: 0.359557\n",
      "[200]\ttraining's rmse: 0.259244\tvalid_1's rmse: 0.264012\n",
      "[300]\ttraining's rmse: 0.226755\tvalid_1's rmse: 0.23268\n",
      "[400]\ttraining's rmse: 0.21223\tvalid_1's rmse: 0.219312\n",
      "[500]\ttraining's rmse: 0.203199\tvalid_1's rmse: 0.211597\n",
      "[600]\ttraining's rmse: 0.196579\tvalid_1's rmse: 0.206214\n",
      "[700]\ttraining's rmse: 0.191428\tvalid_1's rmse: 0.202306\n",
      "[800]\ttraining's rmse: 0.187237\tvalid_1's rmse: 0.19938\n",
      "[900]\ttraining's rmse: 0.183714\tvalid_1's rmse: 0.197133\n",
      "[1000]\ttraining's rmse: 0.180602\tvalid_1's rmse: 0.195297\n",
      "[1100]\ttraining's rmse: 0.1779\tvalid_1's rmse: 0.193858\n",
      "[1200]\ttraining's rmse: 0.175469\tvalid_1's rmse: 0.192742\n",
      "[1300]\ttraining's rmse: 0.173285\tvalid_1's rmse: 0.191867\n",
      "[1400]\ttraining's rmse: 0.171279\tvalid_1's rmse: 0.191103\n",
      "[1500]\ttraining's rmse: 0.169405\tvalid_1's rmse: 0.190436\n",
      "[1600]\ttraining's rmse: 0.167677\tvalid_1's rmse: 0.189869\n",
      "[1700]\ttraining's rmse: 0.166064\tvalid_1's rmse: 0.189369\n",
      "[1800]\ttraining's rmse: 0.164527\tvalid_1's rmse: 0.188918\n",
      "[1900]\ttraining's rmse: 0.163067\tvalid_1's rmse: 0.188525\n",
      "[2000]\ttraining's rmse: 0.161661\tvalid_1's rmse: 0.188179\n",
      "[2100]\ttraining's rmse: 0.160309\tvalid_1's rmse: 0.187868\n",
      "[2200]\ttraining's rmse: 0.159025\tvalid_1's rmse: 0.187618\n",
      "[2300]\ttraining's rmse: 0.157746\tvalid_1's rmse: 0.187352\n",
      "[2400]\ttraining's rmse: 0.156522\tvalid_1's rmse: 0.187164\n",
      "[2500]\ttraining's rmse: 0.155347\tvalid_1's rmse: 0.186955\n",
      "[2600]\ttraining's rmse: 0.154208\tvalid_1's rmse: 0.186757\n",
      "[2700]\ttraining's rmse: 0.15308\tvalid_1's rmse: 0.186549\n",
      "[2800]\ttraining's rmse: 0.151971\tvalid_1's rmse: 0.186351\n",
      "[2900]\ttraining's rmse: 0.150908\tvalid_1's rmse: 0.186207\n",
      "[3000]\ttraining's rmse: 0.149858\tvalid_1's rmse: 0.186055\n",
      "[3100]\ttraining's rmse: 0.148819\tvalid_1's rmse: 0.185911\n",
      "[3200]\ttraining's rmse: 0.147806\tvalid_1's rmse: 0.185775\n",
      "[3300]\ttraining's rmse: 0.146784\tvalid_1's rmse: 0.185609\n",
      "[3400]\ttraining's rmse: 0.145825\tvalid_1's rmse: 0.185472\n",
      "[3500]\ttraining's rmse: 0.144856\tvalid_1's rmse: 0.185341\n",
      "[3600]\ttraining's rmse: 0.143904\tvalid_1's rmse: 0.185231\n",
      "[3700]\ttraining's rmse: 0.142989\tvalid_1's rmse: 0.185103\n",
      "[3800]\ttraining's rmse: 0.142076\tvalid_1's rmse: 0.184989\n",
      "[3900]\ttraining's rmse: 0.141177\tvalid_1's rmse: 0.184874\n",
      "[4000]\ttraining's rmse: 0.140297\tvalid_1's rmse: 0.184757\n",
      "[4100]\ttraining's rmse: 0.139427\tvalid_1's rmse: 0.184657\n",
      "[4200]\ttraining's rmse: 0.138578\tvalid_1's rmse: 0.184567\n",
      "[4300]\ttraining's rmse: 0.137726\tvalid_1's rmse: 0.184476\n",
      "[4400]\ttraining's rmse: 0.136886\tvalid_1's rmse: 0.184377\n",
      "[4500]\ttraining's rmse: 0.136069\tvalid_1's rmse: 0.18428\n",
      "[4600]\ttraining's rmse: 0.135251\tvalid_1's rmse: 0.184184\n",
      "[4700]\ttraining's rmse: 0.13445\tvalid_1's rmse: 0.184107\n",
      "[4800]\ttraining's rmse: 0.133663\tvalid_1's rmse: 0.184019\n",
      "[4900]\ttraining's rmse: 0.132876\tvalid_1's rmse: 0.183918\n",
      "[5000]\ttraining's rmse: 0.132107\tvalid_1's rmse: 0.183843\n",
      "[5100]\ttraining's rmse: 0.131344\tvalid_1's rmse: 0.183754\n",
      "[5200]\ttraining's rmse: 0.130611\tvalid_1's rmse: 0.183682\n",
      "[5300]\ttraining's rmse: 0.129854\tvalid_1's rmse: 0.183579\n",
      "[5400]\ttraining's rmse: 0.129117\tvalid_1's rmse: 0.183509\n",
      "[5500]\ttraining's rmse: 0.128367\tvalid_1's rmse: 0.183415\n",
      "[5600]\ttraining's rmse: 0.127664\tvalid_1's rmse: 0.183325\n",
      "[5700]\ttraining's rmse: 0.126944\tvalid_1's rmse: 0.18325\n",
      "[5800]\ttraining's rmse: 0.126269\tvalid_1's rmse: 0.183185\n",
      "[5900]\ttraining's rmse: 0.125566\tvalid_1's rmse: 0.183113\n",
      "[6000]\ttraining's rmse: 0.124887\tvalid_1's rmse: 0.183049\n",
      "[6100]\ttraining's rmse: 0.124212\tvalid_1's rmse: 0.182983\n",
      "[6200]\ttraining's rmse: 0.123534\tvalid_1's rmse: 0.182919\n",
      "[6300]\ttraining's rmse: 0.122852\tvalid_1's rmse: 0.182856\n",
      "[6400]\ttraining's rmse: 0.122199\tvalid_1's rmse: 0.182803\n",
      "[6500]\ttraining's rmse: 0.121556\tvalid_1's rmse: 0.182749\n",
      "[6600]\ttraining's rmse: 0.120911\tvalid_1's rmse: 0.182702\n",
      "[6700]\ttraining's rmse: 0.120257\tvalid_1's rmse: 0.182637\n",
      "[6800]\ttraining's rmse: 0.119634\tvalid_1's rmse: 0.182582\n",
      "[6900]\ttraining's rmse: 0.119009\tvalid_1's rmse: 0.182534\n",
      "[7000]\ttraining's rmse: 0.118395\tvalid_1's rmse: 0.182477\n",
      "[7100]\ttraining's rmse: 0.117768\tvalid_1's rmse: 0.182425\n",
      "[7200]\ttraining's rmse: 0.117141\tvalid_1's rmse: 0.18238\n",
      "[7300]\ttraining's rmse: 0.116538\tvalid_1's rmse: 0.182334\n",
      "[7400]\ttraining's rmse: 0.115942\tvalid_1's rmse: 0.182291\n",
      "[7500]\ttraining's rmse: 0.115352\tvalid_1's rmse: 0.182255\n",
      "[7600]\ttraining's rmse: 0.114772\tvalid_1's rmse: 0.182224\n",
      "[7700]\ttraining's rmse: 0.114213\tvalid_1's rmse: 0.182192\n",
      "[7800]\ttraining's rmse: 0.113622\tvalid_1's rmse: 0.182139\n",
      "[7900]\ttraining's rmse: 0.113041\tvalid_1's rmse: 0.182102\n",
      "[8000]\ttraining's rmse: 0.112469\tvalid_1's rmse: 0.182065\n",
      "[8100]\ttraining's rmse: 0.111909\tvalid_1's rmse: 0.182027\n",
      "[8200]\ttraining's rmse: 0.111349\tvalid_1's rmse: 0.181987\n",
      "[8300]\ttraining's rmse: 0.110796\tvalid_1's rmse: 0.181959\n",
      "[8400]\ttraining's rmse: 0.110254\tvalid_1's rmse: 0.181925\n",
      "[8500]\ttraining's rmse: 0.10972\tvalid_1's rmse: 0.181907\n",
      "[8600]\ttraining's rmse: 0.109193\tvalid_1's rmse: 0.18187\n",
      "[8700]\ttraining's rmse: 0.108673\tvalid_1's rmse: 0.181835\n",
      "[8800]\ttraining's rmse: 0.108135\tvalid_1's rmse: 0.181809\n",
      "[8900]\ttraining's rmse: 0.107612\tvalid_1's rmse: 0.181778\n",
      "[9000]\ttraining's rmse: 0.107104\tvalid_1's rmse: 0.181758\n",
      "[9100]\ttraining's rmse: 0.106573\tvalid_1's rmse: 0.181724\n",
      "[9200]\ttraining's rmse: 0.106068\tvalid_1's rmse: 0.181701\n",
      "[9300]\ttraining's rmse: 0.105554\tvalid_1's rmse: 0.181681\n",
      "[9400]\ttraining's rmse: 0.105046\tvalid_1's rmse: 0.181661\n",
      "[9500]\ttraining's rmse: 0.104541\tvalid_1's rmse: 0.181632\n",
      "[9600]\ttraining's rmse: 0.104037\tvalid_1's rmse: 0.181603\n",
      "[9700]\ttraining's rmse: 0.103555\tvalid_1's rmse: 0.181587\n",
      "[9800]\ttraining's rmse: 0.103064\tvalid_1's rmse: 0.181565\n",
      "[9900]\ttraining's rmse: 0.10259\tvalid_1's rmse: 0.181534\n",
      "[10000]\ttraining's rmse: 0.102121\tvalid_1's rmse: 0.181518\n",
      "[10100]\ttraining's rmse: 0.101653\tvalid_1's rmse: 0.181493\n",
      "[10200]\ttraining's rmse: 0.101175\tvalid_1's rmse: 0.181474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10300]\ttraining's rmse: 0.100715\tvalid_1's rmse: 0.181452\n",
      "[10400]\ttraining's rmse: 0.100254\tvalid_1's rmse: 0.181443\n",
      "[10500]\ttraining's rmse: 0.0997771\tvalid_1's rmse: 0.181431\n",
      "[10600]\ttraining's rmse: 0.0993175\tvalid_1's rmse: 0.181413\n",
      "[10700]\ttraining's rmse: 0.0988418\tvalid_1's rmse: 0.181391\n",
      "[10800]\ttraining's rmse: 0.0983809\tvalid_1's rmse: 0.18137\n",
      "[10900]\ttraining's rmse: 0.0979339\tvalid_1's rmse: 0.181354\n",
      "[11000]\ttraining's rmse: 0.0974814\tvalid_1's rmse: 0.181335\n",
      "[11100]\ttraining's rmse: 0.0970396\tvalid_1's rmse: 0.181307\n",
      "[11200]\ttraining's rmse: 0.0965916\tvalid_1's rmse: 0.181293\n",
      "[11300]\ttraining's rmse: 0.096145\tvalid_1's rmse: 0.18127\n",
      "[11400]\ttraining's rmse: 0.095712\tvalid_1's rmse: 0.181251\n",
      "[11500]\ttraining's rmse: 0.0952757\tvalid_1's rmse: 0.181225\n",
      "[11600]\ttraining's rmse: 0.094846\tvalid_1's rmse: 0.181209\n",
      "[11700]\ttraining's rmse: 0.094408\tvalid_1's rmse: 0.181203\n",
      "[11800]\ttraining's rmse: 0.0939826\tvalid_1's rmse: 0.181189\n",
      "[11900]\ttraining's rmse: 0.0935681\tvalid_1's rmse: 0.181179\n",
      "[12000]\ttraining's rmse: 0.0931684\tvalid_1's rmse: 0.181166\n",
      "[12100]\ttraining's rmse: 0.0927396\tvalid_1's rmse: 0.181156\n",
      "[12200]\ttraining's rmse: 0.0923158\tvalid_1's rmse: 0.181145\n",
      "[12300]\ttraining's rmse: 0.0918927\tvalid_1's rmse: 0.181125\n",
      "[12400]\ttraining's rmse: 0.0914837\tvalid_1's rmse: 0.181116\n",
      "[12500]\ttraining's rmse: 0.0910807\tvalid_1's rmse: 0.181094\n",
      "[12600]\ttraining's rmse: 0.0906677\tvalid_1's rmse: 0.181078\n",
      "[12700]\ttraining's rmse: 0.0902684\tvalid_1's rmse: 0.18106\n",
      "[12800]\ttraining's rmse: 0.0898732\tvalid_1's rmse: 0.181049\n",
      "[12900]\ttraining's rmse: 0.0894852\tvalid_1's rmse: 0.181023\n",
      "[13000]\ttraining's rmse: 0.0890957\tvalid_1's rmse: 0.181006\n",
      "[13100]\ttraining's rmse: 0.0887027\tvalid_1's rmse: 0.180987\n",
      "[13200]\ttraining's rmse: 0.0883085\tvalid_1's rmse: 0.180974\n",
      "[13300]\ttraining's rmse: 0.0879286\tvalid_1's rmse: 0.180958\n",
      "[13400]\ttraining's rmse: 0.0875324\tvalid_1's rmse: 0.180946\n",
      "[13500]\ttraining's rmse: 0.0871392\tvalid_1's rmse: 0.180931\n",
      "[13600]\ttraining's rmse: 0.0867652\tvalid_1's rmse: 0.180924\n",
      "[13700]\ttraining's rmse: 0.0864026\tvalid_1's rmse: 0.180917\n",
      "[13800]\ttraining's rmse: 0.0860183\tvalid_1's rmse: 0.180903\n",
      "[13900]\ttraining's rmse: 0.0856503\tvalid_1's rmse: 0.180894\n",
      "[14000]\ttraining's rmse: 0.0852803\tvalid_1's rmse: 0.180889\n",
      "[14100]\ttraining's rmse: 0.0848994\tvalid_1's rmse: 0.180882\n",
      "[14200]\ttraining's rmse: 0.0845296\tvalid_1's rmse: 0.180874\n",
      "[14300]\ttraining's rmse: 0.0841678\tvalid_1's rmse: 0.180872\n",
      "[14400]\ttraining's rmse: 0.0837987\tvalid_1's rmse: 0.180865\n",
      "[14500]\ttraining's rmse: 0.0834344\tvalid_1's rmse: 0.180856\n",
      "[14600]\ttraining's rmse: 0.0830697\tvalid_1's rmse: 0.180845\n",
      "[14700]\ttraining's rmse: 0.0827088\tvalid_1's rmse: 0.180839\n",
      "[14800]\ttraining's rmse: 0.0823449\tvalid_1's rmse: 0.18083\n",
      "[14900]\ttraining's rmse: 0.0819921\tvalid_1's rmse: 0.180825\n",
      "[15000]\ttraining's rmse: 0.0816454\tvalid_1's rmse: 0.180827\n",
      "[15100]\ttraining's rmse: 0.0812945\tvalid_1's rmse: 0.180815\n",
      "[15200]\ttraining's rmse: 0.0809402\tvalid_1's rmse: 0.180803\n",
      "[15300]\ttraining's rmse: 0.0805917\tvalid_1's rmse: 0.18079\n",
      "Early stopping, best iteration is:\n",
      "[15291]\ttraining's rmse: 0.0806219\tvalid_1's rmse: 0.180788\n",
      "2 76.8955313848 192.760237135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0\n",
      "60.588125427\n",
      "137.62959524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:09<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356289\tvalid_1's rmse: 0.354392\n",
      "[200]\ttraining's rmse: 0.258328\tvalid_1's rmse: 0.2597\n",
      "[300]\ttraining's rmse: 0.226158\tvalid_1's rmse: 0.22985\n",
      "[400]\ttraining's rmse: 0.211459\tvalid_1's rmse: 0.217088\n",
      "[500]\ttraining's rmse: 0.202451\tvalid_1's rmse: 0.209729\n",
      "[600]\ttraining's rmse: 0.195868\tvalid_1's rmse: 0.20483\n",
      "[700]\ttraining's rmse: 0.190808\tvalid_1's rmse: 0.201292\n",
      "[800]\ttraining's rmse: 0.186667\tvalid_1's rmse: 0.198586\n",
      "[900]\ttraining's rmse: 0.183201\tvalid_1's rmse: 0.196436\n",
      "[1000]\ttraining's rmse: 0.180264\tvalid_1's rmse: 0.194766\n",
      "[1100]\ttraining's rmse: 0.177602\tvalid_1's rmse: 0.193413\n",
      "[1200]\ttraining's rmse: 0.175264\tvalid_1's rmse: 0.192375\n",
      "[1300]\ttraining's rmse: 0.173106\tvalid_1's rmse: 0.191526\n",
      "[1400]\ttraining's rmse: 0.171093\tvalid_1's rmse: 0.190726\n",
      "[1500]\ttraining's rmse: 0.169243\tvalid_1's rmse: 0.190081\n",
      "[1600]\ttraining's rmse: 0.167501\tvalid_1's rmse: 0.189523\n",
      "[1700]\ttraining's rmse: 0.165845\tvalid_1's rmse: 0.18905\n",
      "[1800]\ttraining's rmse: 0.164262\tvalid_1's rmse: 0.188611\n",
      "[1900]\ttraining's rmse: 0.162765\tvalid_1's rmse: 0.188235\n",
      "[2000]\ttraining's rmse: 0.161341\tvalid_1's rmse: 0.187875\n",
      "[2100]\ttraining's rmse: 0.159987\tvalid_1's rmse: 0.187542\n",
      "[2200]\ttraining's rmse: 0.158627\tvalid_1's rmse: 0.187227\n",
      "[2300]\ttraining's rmse: 0.15736\tvalid_1's rmse: 0.186969\n",
      "[2400]\ttraining's rmse: 0.156125\tvalid_1's rmse: 0.18674\n",
      "[2500]\ttraining's rmse: 0.154912\tvalid_1's rmse: 0.186479\n",
      "[2600]\ttraining's rmse: 0.153749\tvalid_1's rmse: 0.186258\n",
      "[2700]\ttraining's rmse: 0.152619\tvalid_1's rmse: 0.186065\n",
      "[2800]\ttraining's rmse: 0.151519\tvalid_1's rmse: 0.18587\n",
      "[2900]\ttraining's rmse: 0.150452\tvalid_1's rmse: 0.185676\n",
      "[3000]\ttraining's rmse: 0.149411\tvalid_1's rmse: 0.185516\n",
      "[3100]\ttraining's rmse: 0.148395\tvalid_1's rmse: 0.185354\n",
      "[3200]\ttraining's rmse: 0.147394\tvalid_1's rmse: 0.185171\n",
      "[3300]\ttraining's rmse: 0.146423\tvalid_1's rmse: 0.185031\n",
      "[3400]\ttraining's rmse: 0.145454\tvalid_1's rmse: 0.184892\n",
      "[3500]\ttraining's rmse: 0.144503\tvalid_1's rmse: 0.18477\n",
      "[3600]\ttraining's rmse: 0.143575\tvalid_1's rmse: 0.184633\n",
      "[3700]\ttraining's rmse: 0.142682\tvalid_1's rmse: 0.184515\n",
      "[3800]\ttraining's rmse: 0.141783\tvalid_1's rmse: 0.184417\n",
      "[3900]\ttraining's rmse: 0.140913\tvalid_1's rmse: 0.184313\n",
      "[4000]\ttraining's rmse: 0.140046\tvalid_1's rmse: 0.184211\n",
      "[4100]\ttraining's rmse: 0.139208\tvalid_1's rmse: 0.184133\n",
      "[4200]\ttraining's rmse: 0.13834\tvalid_1's rmse: 0.184066\n",
      "[4300]\ttraining's rmse: 0.137496\tvalid_1's rmse: 0.183977\n",
      "[4400]\ttraining's rmse: 0.136661\tvalid_1's rmse: 0.183899\n",
      "[4500]\ttraining's rmse: 0.135844\tvalid_1's rmse: 0.183822\n",
      "[4600]\ttraining's rmse: 0.135035\tvalid_1's rmse: 0.183738\n",
      "[4700]\ttraining's rmse: 0.134239\tvalid_1's rmse: 0.183653\n",
      "[4800]\ttraining's rmse: 0.133451\tvalid_1's rmse: 0.183565\n",
      "[4900]\ttraining's rmse: 0.13267\tvalid_1's rmse: 0.183469\n",
      "[5000]\ttraining's rmse: 0.131926\tvalid_1's rmse: 0.183425\n",
      "[5100]\ttraining's rmse: 0.131149\tvalid_1's rmse: 0.18335\n",
      "[5200]\ttraining's rmse: 0.130405\tvalid_1's rmse: 0.183295\n",
      "[5300]\ttraining's rmse: 0.129663\tvalid_1's rmse: 0.183238\n",
      "[5400]\ttraining's rmse: 0.128932\tvalid_1's rmse: 0.183184\n",
      "[5500]\ttraining's rmse: 0.128226\tvalid_1's rmse: 0.183136\n",
      "[5600]\ttraining's rmse: 0.127496\tvalid_1's rmse: 0.183101\n",
      "[5700]\ttraining's rmse: 0.126786\tvalid_1's rmse: 0.183047\n",
      "[5800]\ttraining's rmse: 0.126086\tvalid_1's rmse: 0.182996\n",
      "[5900]\ttraining's rmse: 0.125391\tvalid_1's rmse: 0.18295\n",
      "[6000]\ttraining's rmse: 0.1247\tvalid_1's rmse: 0.182889\n",
      "[6100]\ttraining's rmse: 0.124025\tvalid_1's rmse: 0.182834\n",
      "[6200]\ttraining's rmse: 0.123347\tvalid_1's rmse: 0.182772\n",
      "[6300]\ttraining's rmse: 0.122684\tvalid_1's rmse: 0.18272\n",
      "[6400]\ttraining's rmse: 0.122027\tvalid_1's rmse: 0.182674\n",
      "[6500]\ttraining's rmse: 0.12137\tvalid_1's rmse: 0.182622\n",
      "[6600]\ttraining's rmse: 0.120719\tvalid_1's rmse: 0.182584\n",
      "[6700]\ttraining's rmse: 0.120088\tvalid_1's rmse: 0.182541\n",
      "[6800]\ttraining's rmse: 0.119457\tvalid_1's rmse: 0.182502\n",
      "[6900]\ttraining's rmse: 0.118841\tvalid_1's rmse: 0.182471\n",
      "[7000]\ttraining's rmse: 0.118198\tvalid_1's rmse: 0.182429\n",
      "[7100]\ttraining's rmse: 0.117589\tvalid_1's rmse: 0.182395\n",
      "[7200]\ttraining's rmse: 0.117004\tvalid_1's rmse: 0.182358\n",
      "[7300]\ttraining's rmse: 0.116403\tvalid_1's rmse: 0.182321\n",
      "[7400]\ttraining's rmse: 0.115808\tvalid_1's rmse: 0.182286\n",
      "[7500]\ttraining's rmse: 0.115236\tvalid_1's rmse: 0.182253\n",
      "[7600]\ttraining's rmse: 0.114652\tvalid_1's rmse: 0.182218\n",
      "[7700]\ttraining's rmse: 0.114082\tvalid_1's rmse: 0.182184\n",
      "[7800]\ttraining's rmse: 0.113509\tvalid_1's rmse: 0.182152\n",
      "[7900]\ttraining's rmse: 0.112926\tvalid_1's rmse: 0.182117\n",
      "[8000]\ttraining's rmse: 0.11236\tvalid_1's rmse: 0.182098\n",
      "[8100]\ttraining's rmse: 0.111798\tvalid_1's rmse: 0.182062\n",
      "[8200]\ttraining's rmse: 0.111255\tvalid_1's rmse: 0.18203\n",
      "[8300]\ttraining's rmse: 0.110703\tvalid_1's rmse: 0.181998\n",
      "[8400]\ttraining's rmse: 0.110153\tvalid_1's rmse: 0.181976\n",
      "[8500]\ttraining's rmse: 0.109606\tvalid_1's rmse: 0.181952\n",
      "[8600]\ttraining's rmse: 0.109075\tvalid_1's rmse: 0.181938\n",
      "[8700]\ttraining's rmse: 0.10854\tvalid_1's rmse: 0.181902\n",
      "[8800]\ttraining's rmse: 0.10799\tvalid_1's rmse: 0.181879\n",
      "[8900]\ttraining's rmse: 0.107488\tvalid_1's rmse: 0.181857\n",
      "[9000]\ttraining's rmse: 0.106964\tvalid_1's rmse: 0.181831\n",
      "[9100]\ttraining's rmse: 0.106444\tvalid_1's rmse: 0.181812\n",
      "[9200]\ttraining's rmse: 0.105928\tvalid_1's rmse: 0.181774\n",
      "[9300]\ttraining's rmse: 0.105426\tvalid_1's rmse: 0.181749\n",
      "[9400]\ttraining's rmse: 0.104923\tvalid_1's rmse: 0.181721\n",
      "[9500]\ttraining's rmse: 0.104423\tvalid_1's rmse: 0.181697\n",
      "[9600]\ttraining's rmse: 0.103912\tvalid_1's rmse: 0.181683\n",
      "[9700]\ttraining's rmse: 0.103417\tvalid_1's rmse: 0.181666\n",
      "[9800]\ttraining's rmse: 0.102919\tvalid_1's rmse: 0.181635\n",
      "[9900]\ttraining's rmse: 0.102437\tvalid_1's rmse: 0.181617\n",
      "[10000]\ttraining's rmse: 0.101965\tvalid_1's rmse: 0.181599\n",
      "[10100]\ttraining's rmse: 0.101491\tvalid_1's rmse: 0.181583\n",
      "[10200]\ttraining's rmse: 0.101012\tvalid_1's rmse: 0.181565\n",
      "[10300]\ttraining's rmse: 0.100538\tvalid_1's rmse: 0.181554\n",
      "[10400]\ttraining's rmse: 0.100061\tvalid_1's rmse: 0.181535\n",
      "[10500]\ttraining's rmse: 0.0995947\tvalid_1's rmse: 0.181519\n",
      "[10600]\ttraining's rmse: 0.0991323\tvalid_1's rmse: 0.1815\n",
      "[10700]\ttraining's rmse: 0.0986864\tvalid_1's rmse: 0.181496\n",
      "[10800]\ttraining's rmse: 0.0982404\tvalid_1's rmse: 0.181475\n",
      "[10900]\ttraining's rmse: 0.0977979\tvalid_1's rmse: 0.18146\n",
      "[11000]\ttraining's rmse: 0.0973411\tvalid_1's rmse: 0.18145\n",
      "[11100]\ttraining's rmse: 0.0968977\tvalid_1's rmse: 0.181439\n",
      "[11200]\ttraining's rmse: 0.0964443\tvalid_1's rmse: 0.181429\n",
      "[11300]\ttraining's rmse: 0.0959904\tvalid_1's rmse: 0.181408\n",
      "[11400]\ttraining's rmse: 0.0955388\tvalid_1's rmse: 0.181399\n",
      "[11500]\ttraining's rmse: 0.0951092\tvalid_1's rmse: 0.18139\n",
      "[11600]\ttraining's rmse: 0.0946733\tvalid_1's rmse: 0.181372\n",
      "[11700]\ttraining's rmse: 0.0942389\tvalid_1's rmse: 0.181349\n",
      "[11800]\ttraining's rmse: 0.0938095\tvalid_1's rmse: 0.18134\n",
      "[11900]\ttraining's rmse: 0.0933977\tvalid_1's rmse: 0.181335\n",
      "[12000]\ttraining's rmse: 0.0929668\tvalid_1's rmse: 0.181339\n",
      "Early stopping, best iteration is:\n",
      "[11965]\ttraining's rmse: 0.0931164\tvalid_1's rmse: 0.181329\n",
      "0 82.6752419983 131.550288588\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355394\tvalid_1's rmse: 0.360376\n",
      "[200]\ttraining's rmse: 0.257822\tvalid_1's rmse: 0.263332\n",
      "[300]\ttraining's rmse: 0.225852\tvalid_1's rmse: 0.232092\n",
      "[400]\ttraining's rmse: 0.211189\tvalid_1's rmse: 0.218399\n",
      "[500]\ttraining's rmse: 0.202315\tvalid_1's rmse: 0.210634\n",
      "[600]\ttraining's rmse: 0.195814\tvalid_1's rmse: 0.205382\n",
      "[700]\ttraining's rmse: 0.1907\tvalid_1's rmse: 0.201592\n",
      "[800]\ttraining's rmse: 0.186515\tvalid_1's rmse: 0.198628\n",
      "[900]\ttraining's rmse: 0.183032\tvalid_1's rmse: 0.196488\n",
      "[1000]\ttraining's rmse: 0.180036\tvalid_1's rmse: 0.194775\n",
      "[1100]\ttraining's rmse: 0.177374\tvalid_1's rmse: 0.193431\n",
      "[1200]\ttraining's rmse: 0.17503\tvalid_1's rmse: 0.192412\n",
      "[1300]\ttraining's rmse: 0.172899\tvalid_1's rmse: 0.191544\n",
      "[1400]\ttraining's rmse: 0.170959\tvalid_1's rmse: 0.190886\n",
      "[1500]\ttraining's rmse: 0.169151\tvalid_1's rmse: 0.19028\n",
      "[1600]\ttraining's rmse: 0.167472\tvalid_1's rmse: 0.189749\n",
      "[1700]\ttraining's rmse: 0.165874\tvalid_1's rmse: 0.189242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800]\ttraining's rmse: 0.164362\tvalid_1's rmse: 0.188842\n",
      "[1900]\ttraining's rmse: 0.162906\tvalid_1's rmse: 0.188461\n",
      "[2000]\ttraining's rmse: 0.161524\tvalid_1's rmse: 0.18813\n",
      "[2100]\ttraining's rmse: 0.1602\tvalid_1's rmse: 0.187831\n",
      "[2200]\ttraining's rmse: 0.158923\tvalid_1's rmse: 0.187569\n",
      "[2300]\ttraining's rmse: 0.157679\tvalid_1's rmse: 0.187297\n",
      "[2400]\ttraining's rmse: 0.156479\tvalid_1's rmse: 0.187087\n",
      "[2500]\ttraining's rmse: 0.155325\tvalid_1's rmse: 0.186861\n",
      "[2600]\ttraining's rmse: 0.154189\tvalid_1's rmse: 0.186644\n",
      "[2700]\ttraining's rmse: 0.153109\tvalid_1's rmse: 0.186438\n",
      "[2800]\ttraining's rmse: 0.152023\tvalid_1's rmse: 0.186275\n",
      "[2900]\ttraining's rmse: 0.150966\tvalid_1's rmse: 0.186119\n",
      "[3000]\ttraining's rmse: 0.149956\tvalid_1's rmse: 0.185974\n",
      "[3100]\ttraining's rmse: 0.148949\tvalid_1's rmse: 0.185829\n",
      "[3200]\ttraining's rmse: 0.14795\tvalid_1's rmse: 0.185679\n",
      "[3300]\ttraining's rmse: 0.146964\tvalid_1's rmse: 0.185535\n",
      "[3400]\ttraining's rmse: 0.145992\tvalid_1's rmse: 0.185377\n",
      "[3500]\ttraining's rmse: 0.145034\tvalid_1's rmse: 0.185252\n",
      "[3600]\ttraining's rmse: 0.144092\tvalid_1's rmse: 0.185115\n",
      "[3700]\ttraining's rmse: 0.143181\tvalid_1's rmse: 0.184974\n",
      "[3800]\ttraining's rmse: 0.142276\tvalid_1's rmse: 0.184846\n",
      "[3900]\ttraining's rmse: 0.141398\tvalid_1's rmse: 0.184745\n",
      "[4000]\ttraining's rmse: 0.140521\tvalid_1's rmse: 0.184635\n",
      "[4100]\ttraining's rmse: 0.139657\tvalid_1's rmse: 0.18455\n",
      "[4200]\ttraining's rmse: 0.138795\tvalid_1's rmse: 0.184472\n",
      "[4300]\ttraining's rmse: 0.137987\tvalid_1's rmse: 0.184379\n",
      "[4400]\ttraining's rmse: 0.137163\tvalid_1's rmse: 0.184293\n",
      "[4500]\ttraining's rmse: 0.136358\tvalid_1's rmse: 0.184213\n",
      "[4600]\ttraining's rmse: 0.13555\tvalid_1's rmse: 0.184122\n",
      "[4700]\ttraining's rmse: 0.134754\tvalid_1's rmse: 0.184059\n",
      "[4800]\ttraining's rmse: 0.133971\tvalid_1's rmse: 0.183989\n",
      "[4900]\ttraining's rmse: 0.133202\tvalid_1's rmse: 0.183902\n",
      "[5000]\ttraining's rmse: 0.132447\tvalid_1's rmse: 0.183821\n",
      "[5100]\ttraining's rmse: 0.131672\tvalid_1's rmse: 0.183732\n",
      "[5200]\ttraining's rmse: 0.130924\tvalid_1's rmse: 0.183665\n",
      "[5300]\ttraining's rmse: 0.130192\tvalid_1's rmse: 0.183589\n",
      "[5400]\ttraining's rmse: 0.129437\tvalid_1's rmse: 0.183525\n",
      "[5500]\ttraining's rmse: 0.128725\tvalid_1's rmse: 0.18346\n",
      "[5600]\ttraining's rmse: 0.127995\tvalid_1's rmse: 0.183383\n",
      "[5700]\ttraining's rmse: 0.127301\tvalid_1's rmse: 0.183324\n",
      "[5800]\ttraining's rmse: 0.126603\tvalid_1's rmse: 0.183264\n",
      "[5900]\ttraining's rmse: 0.125901\tvalid_1's rmse: 0.183217\n",
      "[6000]\ttraining's rmse: 0.125242\tvalid_1's rmse: 0.183165\n",
      "[6100]\ttraining's rmse: 0.124538\tvalid_1's rmse: 0.1831\n",
      "[6200]\ttraining's rmse: 0.123862\tvalid_1's rmse: 0.183045\n",
      "[6300]\ttraining's rmse: 0.123203\tvalid_1's rmse: 0.183001\n",
      "[6400]\ttraining's rmse: 0.122534\tvalid_1's rmse: 0.182939\n",
      "[6500]\ttraining's rmse: 0.121878\tvalid_1's rmse: 0.182883\n",
      "[6600]\ttraining's rmse: 0.121221\tvalid_1's rmse: 0.182826\n",
      "[6700]\ttraining's rmse: 0.120559\tvalid_1's rmse: 0.182777\n",
      "[6800]\ttraining's rmse: 0.119941\tvalid_1's rmse: 0.182725\n",
      "[6900]\ttraining's rmse: 0.119307\tvalid_1's rmse: 0.182691\n",
      "[7000]\ttraining's rmse: 0.118675\tvalid_1's rmse: 0.182649\n",
      "[7100]\ttraining's rmse: 0.118057\tvalid_1's rmse: 0.182612\n",
      "[7200]\ttraining's rmse: 0.117443\tvalid_1's rmse: 0.182568\n",
      "[7300]\ttraining's rmse: 0.116851\tvalid_1's rmse: 0.182528\n",
      "[7400]\ttraining's rmse: 0.116233\tvalid_1's rmse: 0.182481\n",
      "[7500]\ttraining's rmse: 0.115632\tvalid_1's rmse: 0.182441\n",
      "[7600]\ttraining's rmse: 0.115034\tvalid_1's rmse: 0.182397\n",
      "[7700]\ttraining's rmse: 0.114432\tvalid_1's rmse: 0.182351\n",
      "[7800]\ttraining's rmse: 0.113867\tvalid_1's rmse: 0.182323\n",
      "[7900]\ttraining's rmse: 0.113284\tvalid_1's rmse: 0.18229\n",
      "[8000]\ttraining's rmse: 0.11271\tvalid_1's rmse: 0.182249\n",
      "[8100]\ttraining's rmse: 0.112146\tvalid_1's rmse: 0.182212\n",
      "[8200]\ttraining's rmse: 0.111574\tvalid_1's rmse: 0.182187\n",
      "[8300]\ttraining's rmse: 0.111024\tvalid_1's rmse: 0.182156\n",
      "[8400]\ttraining's rmse: 0.110477\tvalid_1's rmse: 0.182126\n",
      "[8500]\ttraining's rmse: 0.109941\tvalid_1's rmse: 0.182103\n",
      "[8600]\ttraining's rmse: 0.109399\tvalid_1's rmse: 0.182069\n",
      "[8700]\ttraining's rmse: 0.108863\tvalid_1's rmse: 0.182043\n",
      "[8800]\ttraining's rmse: 0.108349\tvalid_1's rmse: 0.182015\n",
      "[8900]\ttraining's rmse: 0.107821\tvalid_1's rmse: 0.181985\n",
      "[9000]\ttraining's rmse: 0.107278\tvalid_1's rmse: 0.18195\n",
      "[9100]\ttraining's rmse: 0.106768\tvalid_1's rmse: 0.181922\n",
      "[9200]\ttraining's rmse: 0.106243\tvalid_1's rmse: 0.181901\n",
      "[9300]\ttraining's rmse: 0.105731\tvalid_1's rmse: 0.181878\n",
      "[9400]\ttraining's rmse: 0.105232\tvalid_1's rmse: 0.181842\n",
      "[9500]\ttraining's rmse: 0.104727\tvalid_1's rmse: 0.181815\n",
      "[9600]\ttraining's rmse: 0.104221\tvalid_1's rmse: 0.181795\n",
      "[9700]\ttraining's rmse: 0.103714\tvalid_1's rmse: 0.181777\n",
      "[9800]\ttraining's rmse: 0.103225\tvalid_1's rmse: 0.181751\n",
      "[9900]\ttraining's rmse: 0.102723\tvalid_1's rmse: 0.181724\n",
      "[10000]\ttraining's rmse: 0.102229\tvalid_1's rmse: 0.181709\n",
      "[10100]\ttraining's rmse: 0.101749\tvalid_1's rmse: 0.181682\n",
      "[10200]\ttraining's rmse: 0.101271\tvalid_1's rmse: 0.181657\n",
      "[10300]\ttraining's rmse: 0.100794\tvalid_1's rmse: 0.18164\n",
      "[10400]\ttraining's rmse: 0.100308\tvalid_1's rmse: 0.181609\n",
      "[10500]\ttraining's rmse: 0.0998256\tvalid_1's rmse: 0.181579\n",
      "[10600]\ttraining's rmse: 0.0993511\tvalid_1's rmse: 0.181557\n",
      "[10700]\ttraining's rmse: 0.0988833\tvalid_1's rmse: 0.181537\n",
      "[10800]\ttraining's rmse: 0.0984255\tvalid_1's rmse: 0.18153\n",
      "[10900]\ttraining's rmse: 0.0979771\tvalid_1's rmse: 0.181505\n",
      "[11000]\ttraining's rmse: 0.0975305\tvalid_1's rmse: 0.181487\n",
      "[11100]\ttraining's rmse: 0.0970944\tvalid_1's rmse: 0.181467\n",
      "[11200]\ttraining's rmse: 0.0966402\tvalid_1's rmse: 0.181454\n",
      "[11300]\ttraining's rmse: 0.0961993\tvalid_1's rmse: 0.181443\n",
      "[11400]\ttraining's rmse: 0.0957727\tvalid_1's rmse: 0.181426\n",
      "[11500]\ttraining's rmse: 0.0953376\tvalid_1's rmse: 0.181412\n",
      "[11600]\ttraining's rmse: 0.0949048\tvalid_1's rmse: 0.181384\n",
      "[11700]\ttraining's rmse: 0.0944788\tvalid_1's rmse: 0.181374\n",
      "[11800]\ttraining's rmse: 0.0940545\tvalid_1's rmse: 0.181355\n",
      "[11900]\ttraining's rmse: 0.0936265\tvalid_1's rmse: 0.181343\n",
      "[12000]\ttraining's rmse: 0.0932084\tvalid_1's rmse: 0.181322\n",
      "[12100]\ttraining's rmse: 0.0927795\tvalid_1's rmse: 0.181303\n",
      "[12200]\ttraining's rmse: 0.0923661\tvalid_1's rmse: 0.181293\n",
      "[12300]\ttraining's rmse: 0.0919409\tvalid_1's rmse: 0.181276\n",
      "[12400]\ttraining's rmse: 0.0915269\tvalid_1's rmse: 0.181254\n",
      "[12500]\ttraining's rmse: 0.0911184\tvalid_1's rmse: 0.181236\n",
      "[12600]\ttraining's rmse: 0.0907135\tvalid_1's rmse: 0.181218\n",
      "[12700]\ttraining's rmse: 0.0903002\tvalid_1's rmse: 0.181198\n",
      "[12800]\ttraining's rmse: 0.0898905\tvalid_1's rmse: 0.181177\n",
      "[12900]\ttraining's rmse: 0.0894963\tvalid_1's rmse: 0.18116\n",
      "[13000]\ttraining's rmse: 0.0891035\tvalid_1's rmse: 0.181145\n",
      "[13100]\ttraining's rmse: 0.0887129\tvalid_1's rmse: 0.181125\n",
      "[13200]\ttraining's rmse: 0.0883285\tvalid_1's rmse: 0.181105\n",
      "[13300]\ttraining's rmse: 0.0879379\tvalid_1's rmse: 0.181083\n",
      "[13400]\ttraining's rmse: 0.087551\tvalid_1's rmse: 0.181068\n",
      "[13500]\ttraining's rmse: 0.0871749\tvalid_1's rmse: 0.181055\n",
      "[13600]\ttraining's rmse: 0.0867917\tvalid_1's rmse: 0.18104\n",
      "[13700]\ttraining's rmse: 0.0864045\tvalid_1's rmse: 0.181026\n",
      "[13800]\ttraining's rmse: 0.0860183\tvalid_1's rmse: 0.181006\n",
      "[13900]\ttraining's rmse: 0.0856362\tvalid_1's rmse: 0.180988\n",
      "[14000]\ttraining's rmse: 0.0852714\tvalid_1's rmse: 0.180975\n",
      "[14100]\ttraining's rmse: 0.0849008\tvalid_1's rmse: 0.180959\n",
      "[14200]\ttraining's rmse: 0.084535\tvalid_1's rmse: 0.180942\n",
      "[14300]\ttraining's rmse: 0.0841676\tvalid_1's rmse: 0.180932\n",
      "[14400]\ttraining's rmse: 0.0838051\tvalid_1's rmse: 0.180919\n",
      "[14500]\ttraining's rmse: 0.0834449\tvalid_1's rmse: 0.180905\n",
      "[14600]\ttraining's rmse: 0.083087\tvalid_1's rmse: 0.180896\n",
      "[14700]\ttraining's rmse: 0.0827296\tvalid_1's rmse: 0.180879\n",
      "[14800]\ttraining's rmse: 0.0823794\tvalid_1's rmse: 0.180874\n",
      "[14900]\ttraining's rmse: 0.0820277\tvalid_1's rmse: 0.18087\n",
      "[15000]\ttraining's rmse: 0.0816723\tvalid_1's rmse: 0.180859\n",
      "[15100]\ttraining's rmse: 0.0813185\tvalid_1's rmse: 0.180854\n",
      "[15200]\ttraining's rmse: 0.0809745\tvalid_1's rmse: 0.180843\n",
      "[15300]\ttraining's rmse: 0.0806293\tvalid_1's rmse: 0.180836\n",
      "[15400]\ttraining's rmse: 0.0802815\tvalid_1's rmse: 0.180821\n",
      "[15500]\ttraining's rmse: 0.0799487\tvalid_1's rmse: 0.180816\n",
      "[15600]\ttraining's rmse: 0.0796148\tvalid_1's rmse: 0.180805\n",
      "[15700]\ttraining's rmse: 0.0792841\tvalid_1's rmse: 0.180799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15800]\ttraining's rmse: 0.0789403\tvalid_1's rmse: 0.180781\n",
      "[15900]\ttraining's rmse: 0.0785982\tvalid_1's rmse: 0.180774\n",
      "[16000]\ttraining's rmse: 0.0782595\tvalid_1's rmse: 0.180769\n",
      "Early stopping, best iteration is:\n",
      "[15984]\ttraining's rmse: 0.0783147\tvalid_1's rmse: 0.180766\n",
      "1 77.1114948086 1640.95511343\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355988\tvalid_1's rmse: 0.359512\n",
      "[200]\ttraining's rmse: 0.258523\tvalid_1's rmse: 0.263722\n",
      "[300]\ttraining's rmse: 0.226248\tvalid_1's rmse: 0.232593\n",
      "[400]\ttraining's rmse: 0.211704\tvalid_1's rmse: 0.219331\n",
      "[500]\ttraining's rmse: 0.202867\tvalid_1's rmse: 0.211699\n",
      "[600]\ttraining's rmse: 0.196252\tvalid_1's rmse: 0.206262\n",
      "[700]\ttraining's rmse: 0.191075\tvalid_1's rmse: 0.20233\n",
      "[800]\ttraining's rmse: 0.186871\tvalid_1's rmse: 0.199427\n",
      "[900]\ttraining's rmse: 0.183327\tvalid_1's rmse: 0.197273\n",
      "[1000]\ttraining's rmse: 0.180271\tvalid_1's rmse: 0.195594\n",
      "[1100]\ttraining's rmse: 0.177598\tvalid_1's rmse: 0.194279\n",
      "[1200]\ttraining's rmse: 0.175204\tvalid_1's rmse: 0.193173\n",
      "[1300]\ttraining's rmse: 0.173016\tvalid_1's rmse: 0.192244\n",
      "[1400]\ttraining's rmse: 0.171069\tvalid_1's rmse: 0.19152\n",
      "[1500]\ttraining's rmse: 0.169227\tvalid_1's rmse: 0.190838\n",
      "[1600]\ttraining's rmse: 0.16752\tvalid_1's rmse: 0.190368\n",
      "[1700]\ttraining's rmse: 0.165897\tvalid_1's rmse: 0.189891\n",
      "[1800]\ttraining's rmse: 0.164344\tvalid_1's rmse: 0.18945\n",
      "[1900]\ttraining's rmse: 0.162854\tvalid_1's rmse: 0.189029\n",
      "[2000]\ttraining's rmse: 0.16146\tvalid_1's rmse: 0.188688\n",
      "[2100]\ttraining's rmse: 0.160102\tvalid_1's rmse: 0.188399\n",
      "[2200]\ttraining's rmse: 0.15881\tvalid_1's rmse: 0.188117\n",
      "[2300]\ttraining's rmse: 0.157542\tvalid_1's rmse: 0.187858\n",
      "[2400]\ttraining's rmse: 0.156322\tvalid_1's rmse: 0.187629\n",
      "[2500]\ttraining's rmse: 0.155178\tvalid_1's rmse: 0.187436\n",
      "[2600]\ttraining's rmse: 0.154052\tvalid_1's rmse: 0.187275\n",
      "[2700]\ttraining's rmse: 0.152925\tvalid_1's rmse: 0.187075\n",
      "[2800]\ttraining's rmse: 0.151841\tvalid_1's rmse: 0.186919\n",
      "[2900]\ttraining's rmse: 0.150788\tvalid_1's rmse: 0.18677\n",
      "[3000]\ttraining's rmse: 0.149758\tvalid_1's rmse: 0.186633\n",
      "[3100]\ttraining's rmse: 0.148725\tvalid_1's rmse: 0.186495\n",
      "[3200]\ttraining's rmse: 0.147717\tvalid_1's rmse: 0.186345\n",
      "[3300]\ttraining's rmse: 0.146744\tvalid_1's rmse: 0.186222\n",
      "[3400]\ttraining's rmse: 0.145765\tvalid_1's rmse: 0.186084\n",
      "[3500]\ttraining's rmse: 0.144789\tvalid_1's rmse: 0.185932\n",
      "[3600]\ttraining's rmse: 0.143833\tvalid_1's rmse: 0.185806\n",
      "[3700]\ttraining's rmse: 0.142929\tvalid_1's rmse: 0.185679\n",
      "[3800]\ttraining's rmse: 0.142021\tvalid_1's rmse: 0.185551\n",
      "[3900]\ttraining's rmse: 0.141102\tvalid_1's rmse: 0.185423\n",
      "[4000]\ttraining's rmse: 0.140253\tvalid_1's rmse: 0.185332\n",
      "[4100]\ttraining's rmse: 0.139369\tvalid_1's rmse: 0.185223\n",
      "[4200]\ttraining's rmse: 0.138521\tvalid_1's rmse: 0.185125\n",
      "[4300]\ttraining's rmse: 0.137681\tvalid_1's rmse: 0.185047\n",
      "[4400]\ttraining's rmse: 0.136863\tvalid_1's rmse: 0.184949\n",
      "[4500]\ttraining's rmse: 0.136034\tvalid_1's rmse: 0.184853\n",
      "[4600]\ttraining's rmse: 0.135229\tvalid_1's rmse: 0.184774\n",
      "[4700]\ttraining's rmse: 0.134424\tvalid_1's rmse: 0.184674\n",
      "[4800]\ttraining's rmse: 0.133637\tvalid_1's rmse: 0.184583\n",
      "[4900]\ttraining's rmse: 0.132859\tvalid_1's rmse: 0.184508\n",
      "[5000]\ttraining's rmse: 0.132083\tvalid_1's rmse: 0.184429\n",
      "[5100]\ttraining's rmse: 0.131327\tvalid_1's rmse: 0.184361\n",
      "[5200]\ttraining's rmse: 0.130583\tvalid_1's rmse: 0.184296\n",
      "[5300]\ttraining's rmse: 0.129816\tvalid_1's rmse: 0.184216\n",
      "[5400]\ttraining's rmse: 0.129083\tvalid_1's rmse: 0.184167\n",
      "[5500]\ttraining's rmse: 0.128355\tvalid_1's rmse: 0.184101\n",
      "[5600]\ttraining's rmse: 0.127627\tvalid_1's rmse: 0.184036\n",
      "[5700]\ttraining's rmse: 0.126937\tvalid_1's rmse: 0.183995\n",
      "[5800]\ttraining's rmse: 0.126247\tvalid_1's rmse: 0.183942\n",
      "[5900]\ttraining's rmse: 0.125566\tvalid_1's rmse: 0.183888\n",
      "[6000]\ttraining's rmse: 0.124879\tvalid_1's rmse: 0.183824\n",
      "[6100]\ttraining's rmse: 0.124209\tvalid_1's rmse: 0.183774\n",
      "[6200]\ttraining's rmse: 0.123536\tvalid_1's rmse: 0.183712\n",
      "[6300]\ttraining's rmse: 0.122861\tvalid_1's rmse: 0.183653\n",
      "[6400]\ttraining's rmse: 0.122214\tvalid_1's rmse: 0.183598\n",
      "[6500]\ttraining's rmse: 0.121577\tvalid_1's rmse: 0.183544\n",
      "[6600]\ttraining's rmse: 0.120922\tvalid_1's rmse: 0.183493\n",
      "[6700]\ttraining's rmse: 0.120275\tvalid_1's rmse: 0.183432\n",
      "[6800]\ttraining's rmse: 0.119656\tvalid_1's rmse: 0.183379\n",
      "[6900]\ttraining's rmse: 0.119024\tvalid_1's rmse: 0.183327\n",
      "[7000]\ttraining's rmse: 0.118398\tvalid_1's rmse: 0.183282\n",
      "[7100]\ttraining's rmse: 0.117776\tvalid_1's rmse: 0.18325\n",
      "[7200]\ttraining's rmse: 0.117175\tvalid_1's rmse: 0.183207\n",
      "[7300]\ttraining's rmse: 0.116569\tvalid_1's rmse: 0.183159\n",
      "[7400]\ttraining's rmse: 0.115974\tvalid_1's rmse: 0.183116\n",
      "[7500]\ttraining's rmse: 0.115376\tvalid_1's rmse: 0.183074\n",
      "[7600]\ttraining's rmse: 0.114793\tvalid_1's rmse: 0.183037\n",
      "[7700]\ttraining's rmse: 0.114211\tvalid_1's rmse: 0.182999\n",
      "[7800]\ttraining's rmse: 0.113632\tvalid_1's rmse: 0.182966\n",
      "[7900]\ttraining's rmse: 0.113041\tvalid_1's rmse: 0.18293\n",
      "[8000]\ttraining's rmse: 0.112491\tvalid_1's rmse: 0.182913\n",
      "[8100]\ttraining's rmse: 0.111927\tvalid_1's rmse: 0.182874\n",
      "[8200]\ttraining's rmse: 0.111361\tvalid_1's rmse: 0.182855\n",
      "[8300]\ttraining's rmse: 0.110817\tvalid_1's rmse: 0.182816\n",
      "[8400]\ttraining's rmse: 0.110247\tvalid_1's rmse: 0.182781\n",
      "[8500]\ttraining's rmse: 0.109701\tvalid_1's rmse: 0.182756\n",
      "[8600]\ttraining's rmse: 0.109147\tvalid_1's rmse: 0.182716\n",
      "[8700]\ttraining's rmse: 0.108624\tvalid_1's rmse: 0.182689\n",
      "[8800]\ttraining's rmse: 0.108087\tvalid_1's rmse: 0.182649\n",
      "[8900]\ttraining's rmse: 0.107573\tvalid_1's rmse: 0.182617\n",
      "[9000]\ttraining's rmse: 0.107062\tvalid_1's rmse: 0.182594\n",
      "[9100]\ttraining's rmse: 0.106546\tvalid_1's rmse: 0.182565\n",
      "[9200]\ttraining's rmse: 0.106037\tvalid_1's rmse: 0.182549\n",
      "[9300]\ttraining's rmse: 0.105514\tvalid_1's rmse: 0.18252\n",
      "[9400]\ttraining's rmse: 0.10501\tvalid_1's rmse: 0.182483\n",
      "[9500]\ttraining's rmse: 0.104501\tvalid_1's rmse: 0.182456\n",
      "[9600]\ttraining's rmse: 0.104006\tvalid_1's rmse: 0.182428\n",
      "[9700]\ttraining's rmse: 0.103521\tvalid_1's rmse: 0.1824\n",
      "[9800]\ttraining's rmse: 0.10302\tvalid_1's rmse: 0.182366\n",
      "[9900]\ttraining's rmse: 0.102525\tvalid_1's rmse: 0.182341\n",
      "[10000]\ttraining's rmse: 0.102038\tvalid_1's rmse: 0.182318\n",
      "[10100]\ttraining's rmse: 0.101566\tvalid_1's rmse: 0.182297\n",
      "[10200]\ttraining's rmse: 0.101096\tvalid_1's rmse: 0.182263\n",
      "[10300]\ttraining's rmse: 0.100631\tvalid_1's rmse: 0.182239\n",
      "[10400]\ttraining's rmse: 0.100152\tvalid_1's rmse: 0.182212\n",
      "[10500]\ttraining's rmse: 0.0996915\tvalid_1's rmse: 0.182187\n",
      "[10600]\ttraining's rmse: 0.0992055\tvalid_1's rmse: 0.182153\n",
      "[10700]\ttraining's rmse: 0.098744\tvalid_1's rmse: 0.182121\n",
      "[10800]\ttraining's rmse: 0.0982946\tvalid_1's rmse: 0.182103\n",
      "[10900]\ttraining's rmse: 0.0978393\tvalid_1's rmse: 0.182081\n",
      "[11000]\ttraining's rmse: 0.0973841\tvalid_1's rmse: 0.182057\n",
      "[11100]\ttraining's rmse: 0.0969355\tvalid_1's rmse: 0.182038\n",
      "[11200]\ttraining's rmse: 0.0964851\tvalid_1's rmse: 0.182019\n",
      "[11300]\ttraining's rmse: 0.0960464\tvalid_1's rmse: 0.182005\n",
      "[11400]\ttraining's rmse: 0.0956251\tvalid_1's rmse: 0.181987\n",
      "[11500]\ttraining's rmse: 0.0951868\tvalid_1's rmse: 0.18196\n",
      "[11600]\ttraining's rmse: 0.0947513\tvalid_1's rmse: 0.18195\n",
      "[11700]\ttraining's rmse: 0.094324\tvalid_1's rmse: 0.181933\n",
      "[11800]\ttraining's rmse: 0.0938981\tvalid_1's rmse: 0.181917\n",
      "[11900]\ttraining's rmse: 0.093481\tvalid_1's rmse: 0.181907\n",
      "[12000]\ttraining's rmse: 0.0930567\tvalid_1's rmse: 0.181886\n",
      "[12100]\ttraining's rmse: 0.0926524\tvalid_1's rmse: 0.181872\n",
      "[12200]\ttraining's rmse: 0.0922495\tvalid_1's rmse: 0.181866\n",
      "[12300]\ttraining's rmse: 0.0918495\tvalid_1's rmse: 0.181847\n",
      "[12400]\ttraining's rmse: 0.0914419\tvalid_1's rmse: 0.181827\n",
      "[12500]\ttraining's rmse: 0.0910432\tvalid_1's rmse: 0.181816\n",
      "[12600]\ttraining's rmse: 0.0906404\tvalid_1's rmse: 0.181794\n",
      "[12700]\ttraining's rmse: 0.090232\tvalid_1's rmse: 0.181781\n",
      "[12800]\ttraining's rmse: 0.0898474\tvalid_1's rmse: 0.181781\n",
      "Early stopping, best iteration is:\n",
      "[12764]\ttraining's rmse: 0.0899865\tvalid_1's rmse: 0.181774\n",
      "2 76.3109789725 190.278453087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "61.5157227771\n",
      "191.692552598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:10<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356359\tvalid_1's rmse: 0.354684\n",
      "[200]\ttraining's rmse: 0.25802\tvalid_1's rmse: 0.259518\n",
      "[300]\ttraining's rmse: 0.225718\tvalid_1's rmse: 0.229582\n",
      "[400]\ttraining's rmse: 0.211047\tvalid_1's rmse: 0.216968\n",
      "[500]\ttraining's rmse: 0.202075\tvalid_1's rmse: 0.209825\n",
      "[600]\ttraining's rmse: 0.195474\tvalid_1's rmse: 0.204962\n",
      "[700]\ttraining's rmse: 0.190323\tvalid_1's rmse: 0.201443\n",
      "[800]\ttraining's rmse: 0.186158\tvalid_1's rmse: 0.198737\n",
      "[900]\ttraining's rmse: 0.182658\tvalid_1's rmse: 0.196621\n",
      "[1000]\ttraining's rmse: 0.179608\tvalid_1's rmse: 0.194965\n",
      "[1100]\ttraining's rmse: 0.176922\tvalid_1's rmse: 0.19355\n",
      "[1200]\ttraining's rmse: 0.174548\tvalid_1's rmse: 0.192462\n",
      "[1300]\ttraining's rmse: 0.172389\tvalid_1's rmse: 0.191596\n",
      "[1400]\ttraining's rmse: 0.170374\tvalid_1's rmse: 0.190795\n",
      "[1500]\ttraining's rmse: 0.168522\tvalid_1's rmse: 0.190136\n",
      "[1600]\ttraining's rmse: 0.166788\tvalid_1's rmse: 0.189524\n",
      "[1700]\ttraining's rmse: 0.165142\tvalid_1's rmse: 0.189014\n",
      "[1800]\ttraining's rmse: 0.163591\tvalid_1's rmse: 0.188589\n",
      "[1900]\ttraining's rmse: 0.162126\tvalid_1's rmse: 0.188204\n",
      "[2000]\ttraining's rmse: 0.160712\tvalid_1's rmse: 0.187846\n",
      "[2100]\ttraining's rmse: 0.159371\tvalid_1's rmse: 0.187547\n",
      "[2200]\ttraining's rmse: 0.158073\tvalid_1's rmse: 0.187256\n",
      "[2300]\ttraining's rmse: 0.156829\tvalid_1's rmse: 0.186998\n",
      "[2400]\ttraining's rmse: 0.155595\tvalid_1's rmse: 0.186761\n",
      "[2500]\ttraining's rmse: 0.154429\tvalid_1's rmse: 0.186529\n",
      "[2600]\ttraining's rmse: 0.153264\tvalid_1's rmse: 0.186324\n",
      "[2700]\ttraining's rmse: 0.152135\tvalid_1's rmse: 0.186133\n",
      "[2800]\ttraining's rmse: 0.151059\tvalid_1's rmse: 0.185948\n",
      "[2900]\ttraining's rmse: 0.150003\tvalid_1's rmse: 0.185798\n",
      "[3000]\ttraining's rmse: 0.148945\tvalid_1's rmse: 0.185646\n",
      "[3100]\ttraining's rmse: 0.147929\tvalid_1's rmse: 0.185508\n",
      "[3200]\ttraining's rmse: 0.146952\tvalid_1's rmse: 0.185404\n",
      "[3300]\ttraining's rmse: 0.145975\tvalid_1's rmse: 0.185287\n",
      "[3400]\ttraining's rmse: 0.145036\tvalid_1's rmse: 0.185147\n",
      "[3500]\ttraining's rmse: 0.144093\tvalid_1's rmse: 0.185047\n",
      "[3600]\ttraining's rmse: 0.143167\tvalid_1's rmse: 0.184922\n",
      "[3700]\ttraining's rmse: 0.142252\tvalid_1's rmse: 0.18481\n",
      "[3800]\ttraining's rmse: 0.141364\tvalid_1's rmse: 0.184708\n",
      "[3900]\ttraining's rmse: 0.140489\tvalid_1's rmse: 0.184595\n",
      "[4000]\ttraining's rmse: 0.139604\tvalid_1's rmse: 0.184494\n",
      "[4100]\ttraining's rmse: 0.138763\tvalid_1's rmse: 0.184395\n",
      "[4200]\ttraining's rmse: 0.137921\tvalid_1's rmse: 0.18428\n",
      "[4300]\ttraining's rmse: 0.137085\tvalid_1's rmse: 0.184166\n",
      "[4400]\ttraining's rmse: 0.136266\tvalid_1's rmse: 0.18409\n",
      "[4500]\ttraining's rmse: 0.135467\tvalid_1's rmse: 0.184015\n",
      "[4600]\ttraining's rmse: 0.134671\tvalid_1's rmse: 0.183932\n",
      "[4700]\ttraining's rmse: 0.133874\tvalid_1's rmse: 0.183847\n",
      "[4800]\ttraining's rmse: 0.1331\tvalid_1's rmse: 0.183761\n",
      "[4900]\ttraining's rmse: 0.132333\tvalid_1's rmse: 0.183688\n",
      "[5000]\ttraining's rmse: 0.131586\tvalid_1's rmse: 0.183623\n",
      "[5100]\ttraining's rmse: 0.130824\tvalid_1's rmse: 0.183542\n",
      "[5200]\ttraining's rmse: 0.130076\tvalid_1's rmse: 0.183462\n",
      "[5300]\ttraining's rmse: 0.129345\tvalid_1's rmse: 0.183378\n",
      "[5400]\ttraining's rmse: 0.12864\tvalid_1's rmse: 0.183336\n",
      "[5500]\ttraining's rmse: 0.127908\tvalid_1's rmse: 0.183265\n",
      "[5600]\ttraining's rmse: 0.127201\tvalid_1's rmse: 0.18321\n",
      "[5700]\ttraining's rmse: 0.126485\tvalid_1's rmse: 0.183151\n",
      "[5800]\ttraining's rmse: 0.125802\tvalid_1's rmse: 0.183114\n",
      "[5900]\ttraining's rmse: 0.125112\tvalid_1's rmse: 0.183055\n",
      "[6000]\ttraining's rmse: 0.12445\tvalid_1's rmse: 0.183008\n",
      "[6100]\ttraining's rmse: 0.123767\tvalid_1's rmse: 0.182961\n",
      "[6200]\ttraining's rmse: 0.123114\tvalid_1's rmse: 0.182928\n",
      "[6300]\ttraining's rmse: 0.122458\tvalid_1's rmse: 0.182887\n",
      "[6400]\ttraining's rmse: 0.121801\tvalid_1's rmse: 0.182856\n",
      "[6500]\ttraining's rmse: 0.121163\tvalid_1's rmse: 0.182813\n",
      "[6600]\ttraining's rmse: 0.120515\tvalid_1's rmse: 0.18276\n",
      "[6700]\ttraining's rmse: 0.119885\tvalid_1's rmse: 0.182734\n",
      "[6800]\ttraining's rmse: 0.11926\tvalid_1's rmse: 0.182701\n",
      "[6900]\ttraining's rmse: 0.11864\tvalid_1's rmse: 0.182656\n",
      "[7000]\ttraining's rmse: 0.118027\tvalid_1's rmse: 0.182618\n",
      "[7100]\ttraining's rmse: 0.117425\tvalid_1's rmse: 0.182586\n",
      "[7200]\ttraining's rmse: 0.116832\tvalid_1's rmse: 0.182539\n",
      "[7300]\ttraining's rmse: 0.116221\tvalid_1's rmse: 0.182496\n",
      "[7400]\ttraining's rmse: 0.115637\tvalid_1's rmse: 0.182461\n",
      "[7500]\ttraining's rmse: 0.115047\tvalid_1's rmse: 0.182407\n",
      "[7600]\ttraining's rmse: 0.114451\tvalid_1's rmse: 0.182351\n",
      "[7700]\ttraining's rmse: 0.113871\tvalid_1's rmse: 0.182315\n",
      "[7800]\ttraining's rmse: 0.113297\tvalid_1's rmse: 0.182284\n",
      "[7900]\ttraining's rmse: 0.112704\tvalid_1's rmse: 0.182244\n",
      "[8000]\ttraining's rmse: 0.112156\tvalid_1's rmse: 0.182208\n",
      "[8100]\ttraining's rmse: 0.111592\tvalid_1's rmse: 0.182177\n",
      "[8200]\ttraining's rmse: 0.11104\tvalid_1's rmse: 0.182136\n",
      "[8300]\ttraining's rmse: 0.110487\tvalid_1's rmse: 0.182109\n",
      "[8400]\ttraining's rmse: 0.10995\tvalid_1's rmse: 0.182083\n",
      "[8500]\ttraining's rmse: 0.109406\tvalid_1's rmse: 0.182056\n",
      "[8600]\ttraining's rmse: 0.10889\tvalid_1's rmse: 0.182038\n",
      "[8700]\ttraining's rmse: 0.108352\tvalid_1's rmse: 0.182013\n",
      "[8800]\ttraining's rmse: 0.107823\tvalid_1's rmse: 0.18198\n",
      "[8900]\ttraining's rmse: 0.107298\tvalid_1's rmse: 0.181957\n",
      "[9000]\ttraining's rmse: 0.106791\tvalid_1's rmse: 0.181932\n",
      "[9100]\ttraining's rmse: 0.106282\tvalid_1's rmse: 0.181902\n",
      "[9200]\ttraining's rmse: 0.105764\tvalid_1's rmse: 0.181874\n",
      "[9300]\ttraining's rmse: 0.105245\tvalid_1's rmse: 0.181847\n",
      "[9400]\ttraining's rmse: 0.104747\tvalid_1's rmse: 0.181834\n",
      "[9500]\ttraining's rmse: 0.104268\tvalid_1's rmse: 0.181802\n",
      "[9600]\ttraining's rmse: 0.103778\tvalid_1's rmse: 0.181783\n",
      "[9700]\ttraining's rmse: 0.103277\tvalid_1's rmse: 0.181766\n",
      "[9800]\ttraining's rmse: 0.102791\tvalid_1's rmse: 0.181748\n",
      "[9900]\ttraining's rmse: 0.102312\tvalid_1's rmse: 0.181727\n",
      "[10000]\ttraining's rmse: 0.10184\tvalid_1's rmse: 0.181707\n",
      "[10100]\ttraining's rmse: 0.101357\tvalid_1's rmse: 0.181696\n",
      "[10200]\ttraining's rmse: 0.100886\tvalid_1's rmse: 0.181682\n",
      "[10300]\ttraining's rmse: 0.100417\tvalid_1's rmse: 0.181665\n",
      "[10400]\ttraining's rmse: 0.0999486\tvalid_1's rmse: 0.181654\n",
      "[10500]\ttraining's rmse: 0.0994897\tvalid_1's rmse: 0.181637\n",
      "[10600]\ttraining's rmse: 0.0990125\tvalid_1's rmse: 0.1816\n",
      "[10700]\ttraining's rmse: 0.0985504\tvalid_1's rmse: 0.181585\n",
      "[10800]\ttraining's rmse: 0.0980972\tvalid_1's rmse: 0.181569\n",
      "[10900]\ttraining's rmse: 0.0976369\tvalid_1's rmse: 0.181543\n",
      "[11000]\ttraining's rmse: 0.097207\tvalid_1's rmse: 0.181531\n",
      "[11100]\ttraining's rmse: 0.096765\tvalid_1's rmse: 0.181517\n",
      "[11200]\ttraining's rmse: 0.0963304\tvalid_1's rmse: 0.181502\n",
      "[11300]\ttraining's rmse: 0.0958914\tvalid_1's rmse: 0.181481\n",
      "[11400]\ttraining's rmse: 0.0954399\tvalid_1's rmse: 0.181467\n",
      "[11500]\ttraining's rmse: 0.0949955\tvalid_1's rmse: 0.181447\n",
      "[11600]\ttraining's rmse: 0.0945805\tvalid_1's rmse: 0.181437\n",
      "[11700]\ttraining's rmse: 0.0941602\tvalid_1's rmse: 0.181413\n",
      "[11800]\ttraining's rmse: 0.0937453\tvalid_1's rmse: 0.181392\n",
      "[11900]\ttraining's rmse: 0.0933281\tvalid_1's rmse: 0.181369\n",
      "[12000]\ttraining's rmse: 0.0929146\tvalid_1's rmse: 0.181356\n",
      "[12100]\ttraining's rmse: 0.0924832\tvalid_1's rmse: 0.181341\n",
      "[12200]\ttraining's rmse: 0.09206\tvalid_1's rmse: 0.181319\n",
      "[12300]\ttraining's rmse: 0.0916455\tvalid_1's rmse: 0.181304\n",
      "[12400]\ttraining's rmse: 0.0912313\tvalid_1's rmse: 0.181289\n",
      "[12500]\ttraining's rmse: 0.0908179\tvalid_1's rmse: 0.181274\n",
      "[12600]\ttraining's rmse: 0.0904213\tvalid_1's rmse: 0.181253\n",
      "[12700]\ttraining's rmse: 0.0900146\tvalid_1's rmse: 0.181242\n",
      "[12800]\ttraining's rmse: 0.0896215\tvalid_1's rmse: 0.181231\n",
      "[12900]\ttraining's rmse: 0.0892284\tvalid_1's rmse: 0.181221\n",
      "[13000]\ttraining's rmse: 0.0888299\tvalid_1's rmse: 0.181202\n",
      "[13100]\ttraining's rmse: 0.0884279\tvalid_1's rmse: 0.181192\n",
      "[13200]\ttraining's rmse: 0.0880384\tvalid_1's rmse: 0.181183\n",
      "[13300]\ttraining's rmse: 0.0876507\tvalid_1's rmse: 0.181165\n",
      "[13400]\ttraining's rmse: 0.08727\tvalid_1's rmse: 0.181169\n",
      "Early stopping, best iteration is:\n",
      "[13301]\ttraining's rmse: 0.0876485\tvalid_1's rmse: 0.181164\n",
      "0 80.2339823385 121.97023885\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355311\tvalid_1's rmse: 0.360818\n",
      "[200]\ttraining's rmse: 0.257766\tvalid_1's rmse: 0.264054\n",
      "[300]\ttraining's rmse: 0.225722\tvalid_1's rmse: 0.232946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 0.210975\tvalid_1's rmse: 0.219194\n",
      "[500]\ttraining's rmse: 0.20203\tvalid_1's rmse: 0.211414\n",
      "[600]\ttraining's rmse: 0.195491\tvalid_1's rmse: 0.206196\n",
      "[700]\ttraining's rmse: 0.190405\tvalid_1's rmse: 0.202438\n",
      "[800]\ttraining's rmse: 0.186261\tvalid_1's rmse: 0.199645\n",
      "[900]\ttraining's rmse: 0.182768\tvalid_1's rmse: 0.197477\n",
      "[1000]\ttraining's rmse: 0.179707\tvalid_1's rmse: 0.19578\n",
      "[1100]\ttraining's rmse: 0.177015\tvalid_1's rmse: 0.1944\n",
      "[1200]\ttraining's rmse: 0.174651\tvalid_1's rmse: 0.193375\n",
      "[1300]\ttraining's rmse: 0.172479\tvalid_1's rmse: 0.192475\n",
      "[1400]\ttraining's rmse: 0.17051\tvalid_1's rmse: 0.191773\n",
      "[1500]\ttraining's rmse: 0.168643\tvalid_1's rmse: 0.191099\n",
      "[1600]\ttraining's rmse: 0.166936\tvalid_1's rmse: 0.190591\n",
      "[1700]\ttraining's rmse: 0.165335\tvalid_1's rmse: 0.190128\n",
      "[1800]\ttraining's rmse: 0.163811\tvalid_1's rmse: 0.189704\n",
      "[1900]\ttraining's rmse: 0.162357\tvalid_1's rmse: 0.189358\n",
      "[2000]\ttraining's rmse: 0.160985\tvalid_1's rmse: 0.189076\n",
      "[2100]\ttraining's rmse: 0.15966\tvalid_1's rmse: 0.188822\n",
      "[2200]\ttraining's rmse: 0.158365\tvalid_1's rmse: 0.188562\n",
      "[2300]\ttraining's rmse: 0.157077\tvalid_1's rmse: 0.188321\n",
      "[2400]\ttraining's rmse: 0.155859\tvalid_1's rmse: 0.188104\n",
      "[2500]\ttraining's rmse: 0.154659\tvalid_1's rmse: 0.187875\n",
      "[2600]\ttraining's rmse: 0.153518\tvalid_1's rmse: 0.187654\n",
      "[2700]\ttraining's rmse: 0.152382\tvalid_1's rmse: 0.187467\n",
      "[2800]\ttraining's rmse: 0.151309\tvalid_1's rmse: 0.187295\n",
      "[2900]\ttraining's rmse: 0.150237\tvalid_1's rmse: 0.187103\n",
      "[3000]\ttraining's rmse: 0.149195\tvalid_1's rmse: 0.186931\n",
      "[3100]\ttraining's rmse: 0.148163\tvalid_1's rmse: 0.186792\n",
      "[3200]\ttraining's rmse: 0.147165\tvalid_1's rmse: 0.186644\n",
      "[3300]\ttraining's rmse: 0.146168\tvalid_1's rmse: 0.186487\n",
      "[3400]\ttraining's rmse: 0.145207\tvalid_1's rmse: 0.186347\n",
      "[3500]\ttraining's rmse: 0.144284\tvalid_1's rmse: 0.186226\n",
      "[3600]\ttraining's rmse: 0.143373\tvalid_1's rmse: 0.186107\n",
      "[3700]\ttraining's rmse: 0.142472\tvalid_1's rmse: 0.18597\n",
      "[3800]\ttraining's rmse: 0.141572\tvalid_1's rmse: 0.185867\n",
      "[3900]\ttraining's rmse: 0.140702\tvalid_1's rmse: 0.185776\n",
      "[4000]\ttraining's rmse: 0.139855\tvalid_1's rmse: 0.185681\n",
      "[4100]\ttraining's rmse: 0.138994\tvalid_1's rmse: 0.185582\n",
      "[4200]\ttraining's rmse: 0.138161\tvalid_1's rmse: 0.185493\n",
      "[4300]\ttraining's rmse: 0.137332\tvalid_1's rmse: 0.185379\n",
      "[4400]\ttraining's rmse: 0.136515\tvalid_1's rmse: 0.185282\n",
      "[4500]\ttraining's rmse: 0.135717\tvalid_1's rmse: 0.18519\n",
      "[4600]\ttraining's rmse: 0.134929\tvalid_1's rmse: 0.18513\n",
      "[4700]\ttraining's rmse: 0.13415\tvalid_1's rmse: 0.185066\n",
      "[4800]\ttraining's rmse: 0.133357\tvalid_1's rmse: 0.184992\n",
      "[4900]\ttraining's rmse: 0.132596\tvalid_1's rmse: 0.184925\n",
      "[5000]\ttraining's rmse: 0.131812\tvalid_1's rmse: 0.184859\n",
      "[5100]\ttraining's rmse: 0.131055\tvalid_1's rmse: 0.184789\n",
      "[5200]\ttraining's rmse: 0.130318\tvalid_1's rmse: 0.184733\n",
      "[5300]\ttraining's rmse: 0.129593\tvalid_1's rmse: 0.184665\n",
      "[5400]\ttraining's rmse: 0.128863\tvalid_1's rmse: 0.184619\n",
      "[5500]\ttraining's rmse: 0.128148\tvalid_1's rmse: 0.184564\n",
      "[5600]\ttraining's rmse: 0.127448\tvalid_1's rmse: 0.184511\n",
      "[5700]\ttraining's rmse: 0.126748\tvalid_1's rmse: 0.184447\n",
      "[5800]\ttraining's rmse: 0.126062\tvalid_1's rmse: 0.184413\n",
      "[5900]\ttraining's rmse: 0.125391\tvalid_1's rmse: 0.184374\n",
      "[6000]\ttraining's rmse: 0.124709\tvalid_1's rmse: 0.184321\n",
      "[6100]\ttraining's rmse: 0.124041\tvalid_1's rmse: 0.184279\n",
      "[6200]\ttraining's rmse: 0.12336\tvalid_1's rmse: 0.184233\n",
      "[6300]\ttraining's rmse: 0.122717\tvalid_1's rmse: 0.184191\n",
      "[6400]\ttraining's rmse: 0.122075\tvalid_1's rmse: 0.18414\n",
      "[6500]\ttraining's rmse: 0.121435\tvalid_1's rmse: 0.184082\n",
      "[6600]\ttraining's rmse: 0.120812\tvalid_1's rmse: 0.184023\n",
      "[6700]\ttraining's rmse: 0.120162\tvalid_1's rmse: 0.183977\n",
      "[6800]\ttraining's rmse: 0.11954\tvalid_1's rmse: 0.183926\n",
      "[6900]\ttraining's rmse: 0.1189\tvalid_1's rmse: 0.183876\n",
      "[7000]\ttraining's rmse: 0.118275\tvalid_1's rmse: 0.183825\n",
      "[7100]\ttraining's rmse: 0.117679\tvalid_1's rmse: 0.183777\n",
      "[7200]\ttraining's rmse: 0.117091\tvalid_1's rmse: 0.18376\n",
      "[7300]\ttraining's rmse: 0.116488\tvalid_1's rmse: 0.18372\n",
      "[7400]\ttraining's rmse: 0.115895\tvalid_1's rmse: 0.18368\n",
      "[7500]\ttraining's rmse: 0.11531\tvalid_1's rmse: 0.183639\n",
      "[7600]\ttraining's rmse: 0.114712\tvalid_1's rmse: 0.183591\n",
      "[7700]\ttraining's rmse: 0.114141\tvalid_1's rmse: 0.183555\n",
      "[7800]\ttraining's rmse: 0.113573\tvalid_1's rmse: 0.183506\n",
      "[7900]\ttraining's rmse: 0.112999\tvalid_1's rmse: 0.183465\n",
      "[8000]\ttraining's rmse: 0.112433\tvalid_1's rmse: 0.183441\n",
      "[8100]\ttraining's rmse: 0.111879\tvalid_1's rmse: 0.183413\n",
      "[8200]\ttraining's rmse: 0.111332\tvalid_1's rmse: 0.183375\n",
      "[8300]\ttraining's rmse: 0.110788\tvalid_1's rmse: 0.183341\n",
      "[8400]\ttraining's rmse: 0.110252\tvalid_1's rmse: 0.183311\n",
      "[8500]\ttraining's rmse: 0.109718\tvalid_1's rmse: 0.183286\n",
      "[8600]\ttraining's rmse: 0.109164\tvalid_1's rmse: 0.183239\n",
      "[8700]\ttraining's rmse: 0.108652\tvalid_1's rmse: 0.18321\n",
      "[8800]\ttraining's rmse: 0.108136\tvalid_1's rmse: 0.183177\n",
      "[8900]\ttraining's rmse: 0.107619\tvalid_1's rmse: 0.183135\n",
      "[9000]\ttraining's rmse: 0.107102\tvalid_1's rmse: 0.183105\n",
      "[9100]\ttraining's rmse: 0.106603\tvalid_1's rmse: 0.18307\n",
      "[9200]\ttraining's rmse: 0.106074\tvalid_1's rmse: 0.183044\n",
      "[9300]\ttraining's rmse: 0.105556\tvalid_1's rmse: 0.183\n",
      "[9400]\ttraining's rmse: 0.10506\tvalid_1's rmse: 0.182969\n",
      "[9500]\ttraining's rmse: 0.104556\tvalid_1's rmse: 0.182933\n",
      "[9600]\ttraining's rmse: 0.104065\tvalid_1's rmse: 0.182907\n",
      "[9700]\ttraining's rmse: 0.103557\tvalid_1's rmse: 0.182875\n",
      "[9800]\ttraining's rmse: 0.103086\tvalid_1's rmse: 0.182853\n",
      "[9900]\ttraining's rmse: 0.102587\tvalid_1's rmse: 0.18282\n",
      "[10000]\ttraining's rmse: 0.102089\tvalid_1's rmse: 0.182782\n",
      "[10100]\ttraining's rmse: 0.101617\tvalid_1's rmse: 0.182749\n",
      "[10200]\ttraining's rmse: 0.101139\tvalid_1's rmse: 0.18272\n",
      "[10300]\ttraining's rmse: 0.100668\tvalid_1's rmse: 0.182692\n",
      "[10400]\ttraining's rmse: 0.100204\tvalid_1's rmse: 0.182673\n",
      "[10500]\ttraining's rmse: 0.0997232\tvalid_1's rmse: 0.182638\n",
      "[10600]\ttraining's rmse: 0.0992681\tvalid_1's rmse: 0.182617\n",
      "[10700]\ttraining's rmse: 0.098813\tvalid_1's rmse: 0.182587\n",
      "[10800]\ttraining's rmse: 0.0983658\tvalid_1's rmse: 0.18257\n",
      "[10900]\ttraining's rmse: 0.0979111\tvalid_1's rmse: 0.182542\n",
      "[11000]\ttraining's rmse: 0.0974743\tvalid_1's rmse: 0.182525\n",
      "[11100]\ttraining's rmse: 0.0970302\tvalid_1's rmse: 0.1825\n",
      "[11200]\ttraining's rmse: 0.0965836\tvalid_1's rmse: 0.182476\n",
      "[11300]\ttraining's rmse: 0.0961439\tvalid_1's rmse: 0.182458\n",
      "[11400]\ttraining's rmse: 0.0957267\tvalid_1's rmse: 0.182436\n",
      "[11500]\ttraining's rmse: 0.0952954\tvalid_1's rmse: 0.182411\n",
      "[11600]\ttraining's rmse: 0.0948698\tvalid_1's rmse: 0.182387\n",
      "[11700]\ttraining's rmse: 0.0944325\tvalid_1's rmse: 0.182362\n",
      "[11800]\ttraining's rmse: 0.0939995\tvalid_1's rmse: 0.182343\n",
      "[11900]\ttraining's rmse: 0.0935808\tvalid_1's rmse: 0.182331\n",
      "[12000]\ttraining's rmse: 0.0931746\tvalid_1's rmse: 0.182313\n",
      "[12100]\ttraining's rmse: 0.0927567\tvalid_1's rmse: 0.182295\n",
      "[12200]\ttraining's rmse: 0.0923497\tvalid_1's rmse: 0.182281\n",
      "[12300]\ttraining's rmse: 0.0919637\tvalid_1's rmse: 0.182259\n",
      "[12400]\ttraining's rmse: 0.0915557\tvalid_1's rmse: 0.182247\n",
      "[12500]\ttraining's rmse: 0.0911331\tvalid_1's rmse: 0.182216\n",
      "[12600]\ttraining's rmse: 0.0907375\tvalid_1's rmse: 0.182204\n",
      "[12700]\ttraining's rmse: 0.0903453\tvalid_1's rmse: 0.182189\n",
      "[12800]\ttraining's rmse: 0.0899526\tvalid_1's rmse: 0.182177\n",
      "[12900]\ttraining's rmse: 0.0895564\tvalid_1's rmse: 0.182161\n",
      "[13000]\ttraining's rmse: 0.089174\tvalid_1's rmse: 0.182141\n",
      "[13100]\ttraining's rmse: 0.0887807\tvalid_1's rmse: 0.182132\n",
      "[13200]\ttraining's rmse: 0.0883853\tvalid_1's rmse: 0.18211\n",
      "[13300]\ttraining's rmse: 0.0879953\tvalid_1's rmse: 0.182099\n",
      "[13400]\ttraining's rmse: 0.0876143\tvalid_1's rmse: 0.182088\n",
      "[13500]\ttraining's rmse: 0.0872304\tvalid_1's rmse: 0.182084\n",
      "[13600]\ttraining's rmse: 0.0868497\tvalid_1's rmse: 0.182067\n",
      "[13700]\ttraining's rmse: 0.08648\tvalid_1's rmse: 0.182063\n",
      "[13800]\ttraining's rmse: 0.0861229\tvalid_1's rmse: 0.182051\n",
      "[13900]\ttraining's rmse: 0.0857457\tvalid_1's rmse: 0.182034\n",
      "[14000]\ttraining's rmse: 0.0853787\tvalid_1's rmse: 0.182031\n",
      "[14100]\ttraining's rmse: 0.0850081\tvalid_1's rmse: 0.182013\n",
      "[14200]\ttraining's rmse: 0.0846454\tvalid_1's rmse: 0.181994\n",
      "[14300]\ttraining's rmse: 0.0842715\tvalid_1's rmse: 0.181982\n",
      "[14400]\ttraining's rmse: 0.0839084\tvalid_1's rmse: 0.181964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14500]\ttraining's rmse: 0.0835402\tvalid_1's rmse: 0.181961\n",
      "[14600]\ttraining's rmse: 0.0831826\tvalid_1's rmse: 0.181953\n",
      "[14700]\ttraining's rmse: 0.0828209\tvalid_1's rmse: 0.181948\n",
      "[14800]\ttraining's rmse: 0.0824735\tvalid_1's rmse: 0.181939\n",
      "[14900]\ttraining's rmse: 0.0821275\tvalid_1's rmse: 0.18193\n",
      "[15000]\ttraining's rmse: 0.0817735\tvalid_1's rmse: 0.181924\n",
      "[15100]\ttraining's rmse: 0.0814239\tvalid_1's rmse: 0.181916\n",
      "[15200]\ttraining's rmse: 0.0810849\tvalid_1's rmse: 0.181904\n",
      "[15300]\ttraining's rmse: 0.0807255\tvalid_1's rmse: 0.181898\n",
      "[15400]\ttraining's rmse: 0.0803801\tvalid_1's rmse: 0.181895\n",
      "[15500]\ttraining's rmse: 0.0800329\tvalid_1's rmse: 0.18188\n",
      "[15600]\ttraining's rmse: 0.0796917\tvalid_1's rmse: 0.181873\n",
      "[15700]\ttraining's rmse: 0.0793679\tvalid_1's rmse: 0.181865\n",
      "[15800]\ttraining's rmse: 0.0790314\tvalid_1's rmse: 0.181853\n",
      "[15900]\ttraining's rmse: 0.0786945\tvalid_1's rmse: 0.181838\n",
      "[16000]\ttraining's rmse: 0.0783544\tvalid_1's rmse: 0.181823\n",
      "[16100]\ttraining's rmse: 0.0780187\tvalid_1's rmse: 0.181819\n",
      "[16200]\ttraining's rmse: 0.0776905\tvalid_1's rmse: 0.181806\n",
      "[16300]\ttraining's rmse: 0.0773636\tvalid_1's rmse: 0.181801\n",
      "[16400]\ttraining's rmse: 0.0770338\tvalid_1's rmse: 0.181788\n",
      "[16500]\ttraining's rmse: 0.0767004\tvalid_1's rmse: 0.181774\n",
      "[16600]\ttraining's rmse: 0.0763796\tvalid_1's rmse: 0.181765\n",
      "[16700]\ttraining's rmse: 0.076059\tvalid_1's rmse: 0.181752\n",
      "[16800]\ttraining's rmse: 0.0757331\tvalid_1's rmse: 0.181739\n",
      "[16900]\ttraining's rmse: 0.0754209\tvalid_1's rmse: 0.181725\n",
      "[17000]\ttraining's rmse: 0.0750953\tvalid_1's rmse: 0.181711\n",
      "[17100]\ttraining's rmse: 0.0747813\tvalid_1's rmse: 0.181708\n",
      "[17200]\ttraining's rmse: 0.0744652\tvalid_1's rmse: 0.181697\n",
      "[17300]\ttraining's rmse: 0.0741505\tvalid_1's rmse: 0.181683\n",
      "[17400]\ttraining's rmse: 0.0738414\tvalid_1's rmse: 0.181673\n",
      "[17500]\ttraining's rmse: 0.0735481\tvalid_1's rmse: 0.181666\n",
      "[17600]\ttraining's rmse: 0.0732355\tvalid_1's rmse: 0.18166\n",
      "[17700]\ttraining's rmse: 0.0729335\tvalid_1's rmse: 0.181647\n",
      "[17800]\ttraining's rmse: 0.072635\tvalid_1's rmse: 0.181637\n",
      "[17900]\ttraining's rmse: 0.07232\tvalid_1's rmse: 0.181631\n",
      "[18000]\ttraining's rmse: 0.0720239\tvalid_1's rmse: 0.181623\n",
      "[18100]\ttraining's rmse: 0.0717316\tvalid_1's rmse: 0.181618\n",
      "Early stopping, best iteration is:\n",
      "[18056]\ttraining's rmse: 0.0718526\tvalid_1's rmse: 0.181615\n",
      "1 75.0268475214 6393.66273456\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356183\tvalid_1's rmse: 0.359493\n",
      "[200]\ttraining's rmse: 0.258563\tvalid_1's rmse: 0.263259\n",
      "[300]\ttraining's rmse: 0.22628\tvalid_1's rmse: 0.23213\n",
      "[400]\ttraining's rmse: 0.211742\tvalid_1's rmse: 0.218681\n",
      "[500]\ttraining's rmse: 0.202894\tvalid_1's rmse: 0.210982\n",
      "[600]\ttraining's rmse: 0.196365\tvalid_1's rmse: 0.205581\n",
      "[700]\ttraining's rmse: 0.191247\tvalid_1's rmse: 0.201642\n",
      "[800]\ttraining's rmse: 0.18702\tvalid_1's rmse: 0.19866\n",
      "[900]\ttraining's rmse: 0.183482\tvalid_1's rmse: 0.196499\n",
      "[1000]\ttraining's rmse: 0.180399\tvalid_1's rmse: 0.194684\n",
      "[1100]\ttraining's rmse: 0.177697\tvalid_1's rmse: 0.193353\n",
      "[1200]\ttraining's rmse: 0.175298\tvalid_1's rmse: 0.192188\n",
      "[1300]\ttraining's rmse: 0.173178\tvalid_1's rmse: 0.191253\n",
      "[1400]\ttraining's rmse: 0.171221\tvalid_1's rmse: 0.190503\n",
      "[1500]\ttraining's rmse: 0.169411\tvalid_1's rmse: 0.189872\n",
      "[1600]\ttraining's rmse: 0.167686\tvalid_1's rmse: 0.189304\n",
      "[1700]\ttraining's rmse: 0.166081\tvalid_1's rmse: 0.188806\n",
      "[1800]\ttraining's rmse: 0.164543\tvalid_1's rmse: 0.188391\n",
      "[1900]\ttraining's rmse: 0.163102\tvalid_1's rmse: 0.188006\n",
      "[2000]\ttraining's rmse: 0.161716\tvalid_1's rmse: 0.187627\n",
      "[2100]\ttraining's rmse: 0.160423\tvalid_1's rmse: 0.187329\n",
      "[2200]\ttraining's rmse: 0.159149\tvalid_1's rmse: 0.187072\n",
      "[2300]\ttraining's rmse: 0.157931\tvalid_1's rmse: 0.186843\n",
      "[2400]\ttraining's rmse: 0.156745\tvalid_1's rmse: 0.186634\n",
      "[2500]\ttraining's rmse: 0.155579\tvalid_1's rmse: 0.18643\n",
      "[2600]\ttraining's rmse: 0.154472\tvalid_1's rmse: 0.186256\n",
      "[2700]\ttraining's rmse: 0.153388\tvalid_1's rmse: 0.186068\n",
      "[2800]\ttraining's rmse: 0.152266\tvalid_1's rmse: 0.185818\n",
      "[2900]\ttraining's rmse: 0.151207\tvalid_1's rmse: 0.18564\n",
      "[3000]\ttraining's rmse: 0.150155\tvalid_1's rmse: 0.185483\n",
      "[3100]\ttraining's rmse: 0.149156\tvalid_1's rmse: 0.185304\n",
      "[3200]\ttraining's rmse: 0.148144\tvalid_1's rmse: 0.18513\n",
      "[3300]\ttraining's rmse: 0.147162\tvalid_1's rmse: 0.184976\n",
      "[3400]\ttraining's rmse: 0.146209\tvalid_1's rmse: 0.18483\n",
      "[3500]\ttraining's rmse: 0.145248\tvalid_1's rmse: 0.184676\n",
      "[3600]\ttraining's rmse: 0.144292\tvalid_1's rmse: 0.184512\n",
      "[3700]\ttraining's rmse: 0.143353\tvalid_1's rmse: 0.184377\n",
      "[3800]\ttraining's rmse: 0.142443\tvalid_1's rmse: 0.184271\n",
      "[3900]\ttraining's rmse: 0.141543\tvalid_1's rmse: 0.184135\n",
      "[4000]\ttraining's rmse: 0.140647\tvalid_1's rmse: 0.184005\n",
      "[4100]\ttraining's rmse: 0.13976\tvalid_1's rmse: 0.183899\n",
      "[4200]\ttraining's rmse: 0.138918\tvalid_1's rmse: 0.183816\n",
      "[4300]\ttraining's rmse: 0.138068\tvalid_1's rmse: 0.183731\n",
      "[4400]\ttraining's rmse: 0.13724\tvalid_1's rmse: 0.183628\n",
      "[4500]\ttraining's rmse: 0.136414\tvalid_1's rmse: 0.183549\n",
      "[4600]\ttraining's rmse: 0.135601\tvalid_1's rmse: 0.183445\n",
      "[4700]\ttraining's rmse: 0.134792\tvalid_1's rmse: 0.183365\n",
      "[4800]\ttraining's rmse: 0.134021\tvalid_1's rmse: 0.183275\n",
      "[4900]\ttraining's rmse: 0.133221\tvalid_1's rmse: 0.183193\n",
      "[5000]\ttraining's rmse: 0.132464\tvalid_1's rmse: 0.18313\n",
      "[5100]\ttraining's rmse: 0.131705\tvalid_1's rmse: 0.183045\n",
      "[5200]\ttraining's rmse: 0.130958\tvalid_1's rmse: 0.18298\n",
      "[5300]\ttraining's rmse: 0.130205\tvalid_1's rmse: 0.182899\n",
      "[5400]\ttraining's rmse: 0.129471\tvalid_1's rmse: 0.182834\n",
      "[5500]\ttraining's rmse: 0.128742\tvalid_1's rmse: 0.18276\n",
      "[5600]\ttraining's rmse: 0.128013\tvalid_1's rmse: 0.182684\n",
      "[5700]\ttraining's rmse: 0.127307\tvalid_1's rmse: 0.182621\n",
      "[5800]\ttraining's rmse: 0.126617\tvalid_1's rmse: 0.182579\n",
      "[5900]\ttraining's rmse: 0.125904\tvalid_1's rmse: 0.182531\n",
      "[6000]\ttraining's rmse: 0.125229\tvalid_1's rmse: 0.182474\n",
      "[6100]\ttraining's rmse: 0.124557\tvalid_1's rmse: 0.182425\n",
      "[6200]\ttraining's rmse: 0.123897\tvalid_1's rmse: 0.182359\n",
      "[6300]\ttraining's rmse: 0.123232\tvalid_1's rmse: 0.182313\n",
      "[6400]\ttraining's rmse: 0.122562\tvalid_1's rmse: 0.182273\n",
      "[6500]\ttraining's rmse: 0.121931\tvalid_1's rmse: 0.18223\n",
      "[6600]\ttraining's rmse: 0.121285\tvalid_1's rmse: 0.18218\n",
      "[6700]\ttraining's rmse: 0.120656\tvalid_1's rmse: 0.182142\n",
      "[6800]\ttraining's rmse: 0.120025\tvalid_1's rmse: 0.182097\n",
      "[6900]\ttraining's rmse: 0.119407\tvalid_1's rmse: 0.18205\n",
      "[7000]\ttraining's rmse: 0.118799\tvalid_1's rmse: 0.18201\n",
      "[7100]\ttraining's rmse: 0.118202\tvalid_1's rmse: 0.18197\n",
      "[7200]\ttraining's rmse: 0.117586\tvalid_1's rmse: 0.181941\n",
      "[7300]\ttraining's rmse: 0.116963\tvalid_1's rmse: 0.1819\n",
      "[7400]\ttraining's rmse: 0.116381\tvalid_1's rmse: 0.181865\n",
      "[7500]\ttraining's rmse: 0.115786\tvalid_1's rmse: 0.181827\n",
      "[7600]\ttraining's rmse: 0.115179\tvalid_1's rmse: 0.181801\n",
      "[7700]\ttraining's rmse: 0.114604\tvalid_1's rmse: 0.181773\n",
      "[7800]\ttraining's rmse: 0.114017\tvalid_1's rmse: 0.181731\n",
      "[7900]\ttraining's rmse: 0.113425\tvalid_1's rmse: 0.181696\n",
      "[8000]\ttraining's rmse: 0.112854\tvalid_1's rmse: 0.181668\n",
      "[8100]\ttraining's rmse: 0.112286\tvalid_1's rmse: 0.181628\n",
      "[8200]\ttraining's rmse: 0.111738\tvalid_1's rmse: 0.1816\n",
      "[8300]\ttraining's rmse: 0.11117\tvalid_1's rmse: 0.181571\n",
      "[8400]\ttraining's rmse: 0.110619\tvalid_1's rmse: 0.181546\n",
      "[8500]\ttraining's rmse: 0.110094\tvalid_1's rmse: 0.181532\n",
      "[8600]\ttraining's rmse: 0.109542\tvalid_1's rmse: 0.181502\n",
      "[8700]\ttraining's rmse: 0.109004\tvalid_1's rmse: 0.181476\n",
      "[8800]\ttraining's rmse: 0.108473\tvalid_1's rmse: 0.181444\n",
      "[8900]\ttraining's rmse: 0.107936\tvalid_1's rmse: 0.181435\n",
      "[9000]\ttraining's rmse: 0.1074\tvalid_1's rmse: 0.181405\n",
      "[9100]\ttraining's rmse: 0.10687\tvalid_1's rmse: 0.181375\n",
      "[9200]\ttraining's rmse: 0.106357\tvalid_1's rmse: 0.181354\n",
      "[9300]\ttraining's rmse: 0.105843\tvalid_1's rmse: 0.181331\n",
      "[9400]\ttraining's rmse: 0.105334\tvalid_1's rmse: 0.181308\n",
      "[9500]\ttraining's rmse: 0.104817\tvalid_1's rmse: 0.181276\n",
      "[9600]\ttraining's rmse: 0.104319\tvalid_1's rmse: 0.181254\n",
      "[9700]\ttraining's rmse: 0.103822\tvalid_1's rmse: 0.181237\n",
      "[9800]\ttraining's rmse: 0.103317\tvalid_1's rmse: 0.181215\n",
      "[9900]\ttraining's rmse: 0.102829\tvalid_1's rmse: 0.181185\n",
      "[10000]\ttraining's rmse: 0.102338\tvalid_1's rmse: 0.181163\n",
      "[10100]\ttraining's rmse: 0.101855\tvalid_1's rmse: 0.181137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10200]\ttraining's rmse: 0.101376\tvalid_1's rmse: 0.18112\n",
      "[10300]\ttraining's rmse: 0.100907\tvalid_1's rmse: 0.181103\n",
      "[10400]\ttraining's rmse: 0.100444\tvalid_1's rmse: 0.181082\n",
      "[10500]\ttraining's rmse: 0.0999699\tvalid_1's rmse: 0.181058\n",
      "[10600]\ttraining's rmse: 0.0994948\tvalid_1's rmse: 0.181024\n",
      "[10700]\ttraining's rmse: 0.099027\tvalid_1's rmse: 0.181003\n",
      "[10800]\ttraining's rmse: 0.0985815\tvalid_1's rmse: 0.180989\n",
      "[10900]\ttraining's rmse: 0.0981196\tvalid_1's rmse: 0.180969\n",
      "[11000]\ttraining's rmse: 0.0976657\tvalid_1's rmse: 0.180942\n",
      "[11100]\ttraining's rmse: 0.0972124\tvalid_1's rmse: 0.180922\n",
      "[11200]\ttraining's rmse: 0.0967652\tvalid_1's rmse: 0.180901\n",
      "[11300]\ttraining's rmse: 0.0963183\tvalid_1's rmse: 0.180882\n",
      "[11400]\ttraining's rmse: 0.0958688\tvalid_1's rmse: 0.180848\n",
      "[11500]\ttraining's rmse: 0.0954376\tvalid_1's rmse: 0.180826\n",
      "[11600]\ttraining's rmse: 0.0949875\tvalid_1's rmse: 0.180808\n",
      "[11700]\ttraining's rmse: 0.0945458\tvalid_1's rmse: 0.180786\n",
      "[11800]\ttraining's rmse: 0.0941215\tvalid_1's rmse: 0.18077\n",
      "[11900]\ttraining's rmse: 0.093697\tvalid_1's rmse: 0.180754\n",
      "[12000]\ttraining's rmse: 0.0932768\tvalid_1's rmse: 0.180731\n",
      "[12100]\ttraining's rmse: 0.0928441\tvalid_1's rmse: 0.180718\n",
      "[12200]\ttraining's rmse: 0.0924262\tvalid_1's rmse: 0.180699\n",
      "[12300]\ttraining's rmse: 0.0920152\tvalid_1's rmse: 0.180681\n",
      "[12400]\ttraining's rmse: 0.0916003\tvalid_1's rmse: 0.180664\n",
      "[12500]\ttraining's rmse: 0.091192\tvalid_1's rmse: 0.180658\n",
      "[12600]\ttraining's rmse: 0.0907798\tvalid_1's rmse: 0.180636\n",
      "[12700]\ttraining's rmse: 0.0903715\tvalid_1's rmse: 0.180621\n",
      "[12800]\ttraining's rmse: 0.0899684\tvalid_1's rmse: 0.180616\n",
      "[12900]\ttraining's rmse: 0.0895753\tvalid_1's rmse: 0.180606\n",
      "[13000]\ttraining's rmse: 0.0891712\tvalid_1's rmse: 0.180592\n",
      "[13100]\ttraining's rmse: 0.0887775\tvalid_1's rmse: 0.180586\n",
      "[13200]\ttraining's rmse: 0.0883888\tvalid_1's rmse: 0.180572\n",
      "[13300]\ttraining's rmse: 0.0880095\tvalid_1's rmse: 0.180547\n",
      "[13400]\ttraining's rmse: 0.0876056\tvalid_1's rmse: 0.180527\n",
      "[13500]\ttraining's rmse: 0.0872237\tvalid_1's rmse: 0.180521\n",
      "[13600]\ttraining's rmse: 0.0868427\tvalid_1's rmse: 0.180502\n",
      "[13700]\ttraining's rmse: 0.0864654\tvalid_1's rmse: 0.180491\n",
      "[13800]\ttraining's rmse: 0.086084\tvalid_1's rmse: 0.18049\n",
      "[13900]\ttraining's rmse: 0.0856944\tvalid_1's rmse: 0.180474\n",
      "[14000]\ttraining's rmse: 0.0853141\tvalid_1's rmse: 0.180463\n",
      "[14100]\ttraining's rmse: 0.0849535\tvalid_1's rmse: 0.180455\n",
      "[14200]\ttraining's rmse: 0.0845951\tvalid_1's rmse: 0.180449\n",
      "[14300]\ttraining's rmse: 0.0842277\tvalid_1's rmse: 0.180436\n",
      "[14400]\ttraining's rmse: 0.0838544\tvalid_1's rmse: 0.180418\n",
      "[14500]\ttraining's rmse: 0.0834928\tvalid_1's rmse: 0.180407\n",
      "[14600]\ttraining's rmse: 0.0831386\tvalid_1's rmse: 0.180393\n",
      "[14700]\ttraining's rmse: 0.0827787\tvalid_1's rmse: 0.180389\n",
      "[14800]\ttraining's rmse: 0.0824171\tvalid_1's rmse: 0.180381\n",
      "[14900]\ttraining's rmse: 0.0820637\tvalid_1's rmse: 0.180369\n",
      "[15000]\ttraining's rmse: 0.0817165\tvalid_1's rmse: 0.180361\n",
      "[15100]\ttraining's rmse: 0.0813564\tvalid_1's rmse: 0.180342\n",
      "[15200]\ttraining's rmse: 0.0810058\tvalid_1's rmse: 0.180328\n",
      "[15300]\ttraining's rmse: 0.0806504\tvalid_1's rmse: 0.180313\n",
      "[15400]\ttraining's rmse: 0.0803022\tvalid_1's rmse: 0.1803\n",
      "[15500]\ttraining's rmse: 0.0799516\tvalid_1's rmse: 0.180287\n",
      "[15600]\ttraining's rmse: 0.079612\tvalid_1's rmse: 0.18028\n",
      "[15700]\ttraining's rmse: 0.0792728\tvalid_1's rmse: 0.180275\n",
      "[15800]\ttraining's rmse: 0.0789375\tvalid_1's rmse: 0.180263\n",
      "[15900]\ttraining's rmse: 0.0786037\tvalid_1's rmse: 0.180261\n",
      "[16000]\ttraining's rmse: 0.0782641\tvalid_1's rmse: 0.180253\n",
      "[16100]\ttraining's rmse: 0.0779395\tvalid_1's rmse: 0.180252\n",
      "[16200]\ttraining's rmse: 0.0776143\tvalid_1's rmse: 0.180249\n",
      "[16300]\ttraining's rmse: 0.0772915\tvalid_1's rmse: 0.180242\n",
      "[16400]\ttraining's rmse: 0.0769601\tvalid_1's rmse: 0.180237\n",
      "[16500]\ttraining's rmse: 0.0766281\tvalid_1's rmse: 0.180232\n",
      "[16600]\ttraining's rmse: 0.0763001\tvalid_1's rmse: 0.180226\n",
      "[16700]\ttraining's rmse: 0.0759891\tvalid_1's rmse: 0.180224\n",
      "[16800]\ttraining's rmse: 0.0756688\tvalid_1's rmse: 0.18022\n",
      "[16900]\ttraining's rmse: 0.0753526\tvalid_1's rmse: 0.180213\n",
      "[17000]\ttraining's rmse: 0.0750392\tvalid_1's rmse: 0.180205\n",
      "[17100]\ttraining's rmse: 0.0747207\tvalid_1's rmse: 0.180204\n",
      "Early stopping, best iteration is:\n",
      "[17063]\ttraining's rmse: 0.0748394\tvalid_1's rmse: 0.180202\n",
      "2 76.2351933519 186.401156925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 2\n",
      "59.8449209221\n",
      "140.153554485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:10<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356052\tvalid_1's rmse: 0.354379\n",
      "[200]\ttraining's rmse: 0.258416\tvalid_1's rmse: 0.259987\n",
      "[300]\ttraining's rmse: 0.225732\tvalid_1's rmse: 0.229645\n",
      "[400]\ttraining's rmse: 0.211141\tvalid_1's rmse: 0.217041\n",
      "[500]\ttraining's rmse: 0.202199\tvalid_1's rmse: 0.209835\n",
      "[600]\ttraining's rmse: 0.195629\tvalid_1's rmse: 0.204934\n",
      "[700]\ttraining's rmse: 0.190568\tvalid_1's rmse: 0.201415\n",
      "[800]\ttraining's rmse: 0.186435\tvalid_1's rmse: 0.198781\n",
      "[900]\ttraining's rmse: 0.182981\tvalid_1's rmse: 0.196752\n",
      "[1000]\ttraining's rmse: 0.18\tvalid_1's rmse: 0.195125\n",
      "[1100]\ttraining's rmse: 0.177345\tvalid_1's rmse: 0.193875\n",
      "[1200]\ttraining's rmse: 0.174929\tvalid_1's rmse: 0.192856\n",
      "[1300]\ttraining's rmse: 0.172757\tvalid_1's rmse: 0.192015\n",
      "[1400]\ttraining's rmse: 0.170776\tvalid_1's rmse: 0.191273\n",
      "[1500]\ttraining's rmse: 0.168932\tvalid_1's rmse: 0.190702\n",
      "[1600]\ttraining's rmse: 0.167199\tvalid_1's rmse: 0.19014\n",
      "[1700]\ttraining's rmse: 0.165557\tvalid_1's rmse: 0.189642\n",
      "[1800]\ttraining's rmse: 0.164001\tvalid_1's rmse: 0.189218\n",
      "[1900]\ttraining's rmse: 0.162526\tvalid_1's rmse: 0.188772\n",
      "[2000]\ttraining's rmse: 0.161116\tvalid_1's rmse: 0.188412\n",
      "[2100]\ttraining's rmse: 0.15974\tvalid_1's rmse: 0.188081\n",
      "[2200]\ttraining's rmse: 0.158424\tvalid_1's rmse: 0.18776\n",
      "[2300]\ttraining's rmse: 0.157158\tvalid_1's rmse: 0.187479\n",
      "[2400]\ttraining's rmse: 0.155936\tvalid_1's rmse: 0.187218\n",
      "[2500]\ttraining's rmse: 0.154742\tvalid_1's rmse: 0.186995\n",
      "[2600]\ttraining's rmse: 0.153605\tvalid_1's rmse: 0.18677\n",
      "[2700]\ttraining's rmse: 0.152471\tvalid_1's rmse: 0.186547\n",
      "[2800]\ttraining's rmse: 0.151384\tvalid_1's rmse: 0.186359\n",
      "[2900]\ttraining's rmse: 0.150325\tvalid_1's rmse: 0.186183\n",
      "[3000]\ttraining's rmse: 0.149287\tvalid_1's rmse: 0.186012\n",
      "[3100]\ttraining's rmse: 0.148258\tvalid_1's rmse: 0.185838\n",
      "[3200]\ttraining's rmse: 0.147278\tvalid_1's rmse: 0.185693\n",
      "[3300]\ttraining's rmse: 0.146291\tvalid_1's rmse: 0.185541\n",
      "[3400]\ttraining's rmse: 0.145336\tvalid_1's rmse: 0.185414\n",
      "[3500]\ttraining's rmse: 0.144384\tvalid_1's rmse: 0.185285\n",
      "[3600]\ttraining's rmse: 0.143473\tvalid_1's rmse: 0.185176\n",
      "[3700]\ttraining's rmse: 0.142582\tvalid_1's rmse: 0.18508\n",
      "[3800]\ttraining's rmse: 0.141689\tvalid_1's rmse: 0.18498\n",
      "[3900]\ttraining's rmse: 0.140821\tvalid_1's rmse: 0.184879\n",
      "[4000]\ttraining's rmse: 0.139955\tvalid_1's rmse: 0.184774\n",
      "[4100]\ttraining's rmse: 0.139097\tvalid_1's rmse: 0.184672\n",
      "[4200]\ttraining's rmse: 0.138236\tvalid_1's rmse: 0.18457\n",
      "[4300]\ttraining's rmse: 0.137423\tvalid_1's rmse: 0.184478\n",
      "[4400]\ttraining's rmse: 0.1366\tvalid_1's rmse: 0.184381\n",
      "[4500]\ttraining's rmse: 0.135814\tvalid_1's rmse: 0.184309\n",
      "[4600]\ttraining's rmse: 0.13501\tvalid_1's rmse: 0.184222\n",
      "[4700]\ttraining's rmse: 0.134218\tvalid_1's rmse: 0.184132\n",
      "[4800]\ttraining's rmse: 0.133449\tvalid_1's rmse: 0.184049\n",
      "[4900]\ttraining's rmse: 0.132672\tvalid_1's rmse: 0.183982\n",
      "[5000]\ttraining's rmse: 0.13191\tvalid_1's rmse: 0.183906\n",
      "[5100]\ttraining's rmse: 0.131141\tvalid_1's rmse: 0.18383\n",
      "[5200]\ttraining's rmse: 0.130378\tvalid_1's rmse: 0.183754\n",
      "[5300]\ttraining's rmse: 0.129665\tvalid_1's rmse: 0.183683\n",
      "[5400]\ttraining's rmse: 0.128942\tvalid_1's rmse: 0.183613\n",
      "[5500]\ttraining's rmse: 0.128211\tvalid_1's rmse: 0.183555\n",
      "[5600]\ttraining's rmse: 0.1275\tvalid_1's rmse: 0.183484\n",
      "[5700]\ttraining's rmse: 0.126806\tvalid_1's rmse: 0.183411\n",
      "[5800]\ttraining's rmse: 0.126122\tvalid_1's rmse: 0.183343\n",
      "[5900]\ttraining's rmse: 0.125417\tvalid_1's rmse: 0.183286\n",
      "[6000]\ttraining's rmse: 0.124736\tvalid_1's rmse: 0.18323\n",
      "[6100]\ttraining's rmse: 0.124068\tvalid_1's rmse: 0.183178\n",
      "[6200]\ttraining's rmse: 0.123424\tvalid_1's rmse: 0.18312\n",
      "[6300]\ttraining's rmse: 0.122768\tvalid_1's rmse: 0.183064\n",
      "[6400]\ttraining's rmse: 0.122116\tvalid_1's rmse: 0.183019\n",
      "[6500]\ttraining's rmse: 0.121462\tvalid_1's rmse: 0.182968\n",
      "[6600]\ttraining's rmse: 0.120822\tvalid_1's rmse: 0.182915\n",
      "[6700]\ttraining's rmse: 0.120195\tvalid_1's rmse: 0.182878\n",
      "[6800]\ttraining's rmse: 0.119577\tvalid_1's rmse: 0.182832\n",
      "[6900]\ttraining's rmse: 0.118959\tvalid_1's rmse: 0.182789\n",
      "[7000]\ttraining's rmse: 0.118345\tvalid_1's rmse: 0.182747\n",
      "[7100]\ttraining's rmse: 0.117741\tvalid_1's rmse: 0.182708\n",
      "[7200]\ttraining's rmse: 0.117146\tvalid_1's rmse: 0.182675\n",
      "[7300]\ttraining's rmse: 0.116572\tvalid_1's rmse: 0.182633\n",
      "[7400]\ttraining's rmse: 0.115989\tvalid_1's rmse: 0.182589\n",
      "[7500]\ttraining's rmse: 0.115422\tvalid_1's rmse: 0.182561\n",
      "[7600]\ttraining's rmse: 0.114835\tvalid_1's rmse: 0.182522\n",
      "[7700]\ttraining's rmse: 0.114252\tvalid_1's rmse: 0.182485\n",
      "[7800]\ttraining's rmse: 0.113693\tvalid_1's rmse: 0.182453\n",
      "[7900]\ttraining's rmse: 0.113135\tvalid_1's rmse: 0.182429\n",
      "[8000]\ttraining's rmse: 0.112574\tvalid_1's rmse: 0.182394\n",
      "[8100]\ttraining's rmse: 0.112015\tvalid_1's rmse: 0.182359\n",
      "[8200]\ttraining's rmse: 0.11146\tvalid_1's rmse: 0.182328\n",
      "[8300]\ttraining's rmse: 0.110913\tvalid_1's rmse: 0.182303\n",
      "[8400]\ttraining's rmse: 0.110368\tvalid_1's rmse: 0.182261\n",
      "[8500]\ttraining's rmse: 0.109836\tvalid_1's rmse: 0.182233\n",
      "[8600]\ttraining's rmse: 0.109298\tvalid_1's rmse: 0.182205\n",
      "[8700]\ttraining's rmse: 0.108789\tvalid_1's rmse: 0.182184\n",
      "[8800]\ttraining's rmse: 0.108268\tvalid_1's rmse: 0.182157\n",
      "[8900]\ttraining's rmse: 0.107734\tvalid_1's rmse: 0.182135\n",
      "[9000]\ttraining's rmse: 0.107225\tvalid_1's rmse: 0.182116\n",
      "[9100]\ttraining's rmse: 0.106699\tvalid_1's rmse: 0.18209\n",
      "[9200]\ttraining's rmse: 0.106192\tvalid_1's rmse: 0.182074\n",
      "[9300]\ttraining's rmse: 0.10568\tvalid_1's rmse: 0.182053\n",
      "[9400]\ttraining's rmse: 0.105173\tvalid_1's rmse: 0.182031\n",
      "[9500]\ttraining's rmse: 0.104655\tvalid_1's rmse: 0.182007\n",
      "[9600]\ttraining's rmse: 0.104154\tvalid_1's rmse: 0.18199\n",
      "[9700]\ttraining's rmse: 0.103663\tvalid_1's rmse: 0.181966\n",
      "[9800]\ttraining's rmse: 0.103173\tvalid_1's rmse: 0.181944\n",
      "[9900]\ttraining's rmse: 0.102692\tvalid_1's rmse: 0.181938\n",
      "[10000]\ttraining's rmse: 0.102206\tvalid_1's rmse: 0.18193\n",
      "[10100]\ttraining's rmse: 0.101714\tvalid_1's rmse: 0.18191\n",
      "[10200]\ttraining's rmse: 0.101246\tvalid_1's rmse: 0.181893\n",
      "[10300]\ttraining's rmse: 0.100768\tvalid_1's rmse: 0.181889\n",
      "[10400]\ttraining's rmse: 0.10029\tvalid_1's rmse: 0.181865\n",
      "[10500]\ttraining's rmse: 0.0998231\tvalid_1's rmse: 0.181846\n",
      "[10600]\ttraining's rmse: 0.0993771\tvalid_1's rmse: 0.181823\n",
      "[10700]\ttraining's rmse: 0.0989215\tvalid_1's rmse: 0.181805\n",
      "[10800]\ttraining's rmse: 0.0984592\tvalid_1's rmse: 0.181795\n",
      "[10900]\ttraining's rmse: 0.0980136\tvalid_1's rmse: 0.181783\n",
      "[11000]\ttraining's rmse: 0.0975924\tvalid_1's rmse: 0.18177\n",
      "[11100]\ttraining's rmse: 0.0971422\tvalid_1's rmse: 0.181754\n",
      "[11200]\ttraining's rmse: 0.0966998\tvalid_1's rmse: 0.181732\n",
      "[11300]\ttraining's rmse: 0.0962487\tvalid_1's rmse: 0.181719\n",
      "[11400]\ttraining's rmse: 0.0958119\tvalid_1's rmse: 0.181704\n",
      "[11500]\ttraining's rmse: 0.0953734\tvalid_1's rmse: 0.181701\n",
      "[11600]\ttraining's rmse: 0.094945\tvalid_1's rmse: 0.181688\n",
      "[11700]\ttraining's rmse: 0.0945148\tvalid_1's rmse: 0.181681\n",
      "[11800]\ttraining's rmse: 0.0940857\tvalid_1's rmse: 0.181664\n",
      "[11900]\ttraining's rmse: 0.0936582\tvalid_1's rmse: 0.181651\n",
      "[12000]\ttraining's rmse: 0.093229\tvalid_1's rmse: 0.18164\n",
      "[12100]\ttraining's rmse: 0.0928187\tvalid_1's rmse: 0.181627\n",
      "[12200]\ttraining's rmse: 0.0924085\tvalid_1's rmse: 0.181617\n",
      "[12300]\ttraining's rmse: 0.0919987\tvalid_1's rmse: 0.181602\n",
      "[12400]\ttraining's rmse: 0.0915934\tvalid_1's rmse: 0.181591\n",
      "[12500]\ttraining's rmse: 0.0911689\tvalid_1's rmse: 0.181572\n",
      "[12600]\ttraining's rmse: 0.0907612\tvalid_1's rmse: 0.181554\n",
      "[12700]\ttraining's rmse: 0.0903571\tvalid_1's rmse: 0.181539\n",
      "[12800]\ttraining's rmse: 0.0899482\tvalid_1's rmse: 0.181522\n",
      "[12900]\ttraining's rmse: 0.0895502\tvalid_1's rmse: 0.181515\n",
      "[13000]\ttraining's rmse: 0.0891584\tvalid_1's rmse: 0.181505\n",
      "[13100]\ttraining's rmse: 0.088774\tvalid_1's rmse: 0.181487\n",
      "[13200]\ttraining's rmse: 0.0883815\tvalid_1's rmse: 0.181469\n",
      "[13300]\ttraining's rmse: 0.0880036\tvalid_1's rmse: 0.181453\n",
      "[13400]\ttraining's rmse: 0.0876191\tvalid_1's rmse: 0.18144\n",
      "[13500]\ttraining's rmse: 0.0872374\tvalid_1's rmse: 0.18143\n",
      "[13600]\ttraining's rmse: 0.0868527\tvalid_1's rmse: 0.181426\n",
      "Early stopping, best iteration is:\n",
      "[13535]\ttraining's rmse: 0.087101\tvalid_1's rmse: 0.181421\n",
      "0 78.8450033158 118.96905609\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355311\tvalid_1's rmse: 0.360709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 0.257888\tvalid_1's rmse: 0.264014\n",
      "[300]\ttraining's rmse: 0.225697\tvalid_1's rmse: 0.232619\n",
      "[400]\ttraining's rmse: 0.210963\tvalid_1's rmse: 0.21898\n",
      "[500]\ttraining's rmse: 0.202066\tvalid_1's rmse: 0.211173\n",
      "[600]\ttraining's rmse: 0.195555\tvalid_1's rmse: 0.20596\n",
      "[700]\ttraining's rmse: 0.190441\tvalid_1's rmse: 0.202125\n",
      "[800]\ttraining's rmse: 0.186338\tvalid_1's rmse: 0.199276\n",
      "[900]\ttraining's rmse: 0.182907\tvalid_1's rmse: 0.197106\n",
      "[1000]\ttraining's rmse: 0.179946\tvalid_1's rmse: 0.19542\n",
      "[1100]\ttraining's rmse: 0.177311\tvalid_1's rmse: 0.194077\n",
      "[1200]\ttraining's rmse: 0.17491\tvalid_1's rmse: 0.192992\n",
      "[1300]\ttraining's rmse: 0.172781\tvalid_1's rmse: 0.192087\n",
      "[1400]\ttraining's rmse: 0.170822\tvalid_1's rmse: 0.191335\n",
      "[1500]\ttraining's rmse: 0.16898\tvalid_1's rmse: 0.190732\n",
      "[1600]\ttraining's rmse: 0.167245\tvalid_1's rmse: 0.190165\n",
      "[1700]\ttraining's rmse: 0.165627\tvalid_1's rmse: 0.189713\n",
      "[1800]\ttraining's rmse: 0.164094\tvalid_1's rmse: 0.189314\n",
      "[1900]\ttraining's rmse: 0.162667\tvalid_1's rmse: 0.188935\n",
      "[2000]\ttraining's rmse: 0.161234\tvalid_1's rmse: 0.188554\n",
      "[2100]\ttraining's rmse: 0.159911\tvalid_1's rmse: 0.188275\n",
      "[2200]\ttraining's rmse: 0.158575\tvalid_1's rmse: 0.187961\n",
      "[2300]\ttraining's rmse: 0.157306\tvalid_1's rmse: 0.187691\n",
      "[2400]\ttraining's rmse: 0.156085\tvalid_1's rmse: 0.187441\n",
      "[2500]\ttraining's rmse: 0.154909\tvalid_1's rmse: 0.187215\n",
      "[2600]\ttraining's rmse: 0.153767\tvalid_1's rmse: 0.18702\n",
      "[2700]\ttraining's rmse: 0.152631\tvalid_1's rmse: 0.186828\n",
      "[2800]\ttraining's rmse: 0.151543\tvalid_1's rmse: 0.18665\n",
      "[2900]\ttraining's rmse: 0.150456\tvalid_1's rmse: 0.186474\n",
      "[3000]\ttraining's rmse: 0.14939\tvalid_1's rmse: 0.186336\n",
      "[3100]\ttraining's rmse: 0.148373\tvalid_1's rmse: 0.186197\n",
      "[3200]\ttraining's rmse: 0.147378\tvalid_1's rmse: 0.186055\n",
      "[3300]\ttraining's rmse: 0.146346\tvalid_1's rmse: 0.185899\n",
      "[3400]\ttraining's rmse: 0.145345\tvalid_1's rmse: 0.185766\n",
      "[3500]\ttraining's rmse: 0.14439\tvalid_1's rmse: 0.185634\n",
      "[3600]\ttraining's rmse: 0.143435\tvalid_1's rmse: 0.185516\n",
      "[3700]\ttraining's rmse: 0.142494\tvalid_1's rmse: 0.185383\n",
      "[3800]\ttraining's rmse: 0.141578\tvalid_1's rmse: 0.185274\n",
      "[3900]\ttraining's rmse: 0.140652\tvalid_1's rmse: 0.185171\n",
      "[4000]\ttraining's rmse: 0.139781\tvalid_1's rmse: 0.185082\n",
      "[4100]\ttraining's rmse: 0.138908\tvalid_1's rmse: 0.184968\n",
      "[4200]\ttraining's rmse: 0.138035\tvalid_1's rmse: 0.184868\n",
      "[4300]\ttraining's rmse: 0.137179\tvalid_1's rmse: 0.18478\n",
      "[4400]\ttraining's rmse: 0.136359\tvalid_1's rmse: 0.184692\n",
      "[4500]\ttraining's rmse: 0.135522\tvalid_1's rmse: 0.184609\n",
      "[4600]\ttraining's rmse: 0.1347\tvalid_1's rmse: 0.184513\n",
      "[4700]\ttraining's rmse: 0.133921\tvalid_1's rmse: 0.18445\n",
      "[4800]\ttraining's rmse: 0.133114\tvalid_1's rmse: 0.184369\n",
      "[4900]\ttraining's rmse: 0.132342\tvalid_1's rmse: 0.18429\n",
      "[5000]\ttraining's rmse: 0.131566\tvalid_1's rmse: 0.1842\n",
      "[5100]\ttraining's rmse: 0.130776\tvalid_1's rmse: 0.184133\n",
      "[5200]\ttraining's rmse: 0.130022\tvalid_1's rmse: 0.184065\n",
      "[5300]\ttraining's rmse: 0.129274\tvalid_1's rmse: 0.184\n",
      "[5400]\ttraining's rmse: 0.128542\tvalid_1's rmse: 0.183947\n",
      "[5500]\ttraining's rmse: 0.127832\tvalid_1's rmse: 0.183883\n",
      "[5600]\ttraining's rmse: 0.127128\tvalid_1's rmse: 0.18383\n",
      "[5700]\ttraining's rmse: 0.126427\tvalid_1's rmse: 0.183779\n",
      "[5800]\ttraining's rmse: 0.125737\tvalid_1's rmse: 0.183725\n",
      "[5900]\ttraining's rmse: 0.125025\tvalid_1's rmse: 0.183664\n",
      "[6000]\ttraining's rmse: 0.124351\tvalid_1's rmse: 0.183622\n",
      "[6100]\ttraining's rmse: 0.123672\tvalid_1's rmse: 0.183558\n",
      "[6200]\ttraining's rmse: 0.123007\tvalid_1's rmse: 0.183514\n",
      "[6300]\ttraining's rmse: 0.12236\tvalid_1's rmse: 0.183472\n",
      "[6400]\ttraining's rmse: 0.121691\tvalid_1's rmse: 0.183427\n",
      "[6500]\ttraining's rmse: 0.121036\tvalid_1's rmse: 0.183378\n",
      "[6600]\ttraining's rmse: 0.120367\tvalid_1's rmse: 0.183337\n",
      "[6700]\ttraining's rmse: 0.11973\tvalid_1's rmse: 0.183288\n",
      "[6800]\ttraining's rmse: 0.119093\tvalid_1's rmse: 0.183237\n",
      "[6900]\ttraining's rmse: 0.118455\tvalid_1's rmse: 0.183215\n",
      "[7000]\ttraining's rmse: 0.117814\tvalid_1's rmse: 0.18316\n",
      "[7100]\ttraining's rmse: 0.1172\tvalid_1's rmse: 0.183121\n",
      "[7200]\ttraining's rmse: 0.116589\tvalid_1's rmse: 0.183098\n",
      "[7300]\ttraining's rmse: 0.115983\tvalid_1's rmse: 0.183063\n",
      "[7400]\ttraining's rmse: 0.115377\tvalid_1's rmse: 0.183022\n",
      "[7500]\ttraining's rmse: 0.114794\tvalid_1's rmse: 0.182977\n",
      "[7600]\ttraining's rmse: 0.114215\tvalid_1's rmse: 0.182944\n",
      "[7700]\ttraining's rmse: 0.113637\tvalid_1's rmse: 0.182909\n",
      "[7800]\ttraining's rmse: 0.113062\tvalid_1's rmse: 0.182874\n",
      "[7900]\ttraining's rmse: 0.112498\tvalid_1's rmse: 0.18285\n",
      "[8000]\ttraining's rmse: 0.111918\tvalid_1's rmse: 0.182802\n",
      "[8100]\ttraining's rmse: 0.11135\tvalid_1's rmse: 0.182763\n",
      "[8200]\ttraining's rmse: 0.110785\tvalid_1's rmse: 0.182737\n",
      "[8300]\ttraining's rmse: 0.110241\tvalid_1's rmse: 0.182712\n",
      "[8400]\ttraining's rmse: 0.109702\tvalid_1's rmse: 0.182677\n",
      "[8500]\ttraining's rmse: 0.109159\tvalid_1's rmse: 0.182658\n",
      "[8600]\ttraining's rmse: 0.108634\tvalid_1's rmse: 0.182633\n",
      "[8700]\ttraining's rmse: 0.108116\tvalid_1's rmse: 0.182612\n",
      "[8800]\ttraining's rmse: 0.10759\tvalid_1's rmse: 0.182583\n",
      "[8900]\ttraining's rmse: 0.107056\tvalid_1's rmse: 0.182554\n",
      "[9000]\ttraining's rmse: 0.106544\tvalid_1's rmse: 0.182523\n",
      "[9100]\ttraining's rmse: 0.106041\tvalid_1's rmse: 0.182511\n",
      "[9200]\ttraining's rmse: 0.105534\tvalid_1's rmse: 0.182493\n",
      "[9300]\ttraining's rmse: 0.105034\tvalid_1's rmse: 0.182473\n",
      "[9400]\ttraining's rmse: 0.104532\tvalid_1's rmse: 0.182448\n",
      "[9500]\ttraining's rmse: 0.104041\tvalid_1's rmse: 0.182423\n",
      "[9600]\ttraining's rmse: 0.103539\tvalid_1's rmse: 0.182403\n",
      "[9700]\ttraining's rmse: 0.103045\tvalid_1's rmse: 0.182373\n",
      "[9800]\ttraining's rmse: 0.102548\tvalid_1's rmse: 0.182352\n",
      "[9900]\ttraining's rmse: 0.102057\tvalid_1's rmse: 0.18233\n",
      "[10000]\ttraining's rmse: 0.101577\tvalid_1's rmse: 0.182315\n",
      "[10100]\ttraining's rmse: 0.1011\tvalid_1's rmse: 0.182299\n",
      "[10200]\ttraining's rmse: 0.100618\tvalid_1's rmse: 0.182281\n",
      "[10300]\ttraining's rmse: 0.10015\tvalid_1's rmse: 0.182258\n",
      "[10400]\ttraining's rmse: 0.0996861\tvalid_1's rmse: 0.182243\n",
      "[10500]\ttraining's rmse: 0.0992205\tvalid_1's rmse: 0.182222\n",
      "[10600]\ttraining's rmse: 0.0987465\tvalid_1's rmse: 0.182207\n",
      "[10700]\ttraining's rmse: 0.0982755\tvalid_1's rmse: 0.182191\n",
      "[10800]\ttraining's rmse: 0.0978254\tvalid_1's rmse: 0.182175\n",
      "[10900]\ttraining's rmse: 0.0973788\tvalid_1's rmse: 0.182158\n",
      "[11000]\ttraining's rmse: 0.0969272\tvalid_1's rmse: 0.182137\n",
      "[11100]\ttraining's rmse: 0.0964888\tvalid_1's rmse: 0.182109\n",
      "[11200]\ttraining's rmse: 0.0960507\tvalid_1's rmse: 0.182096\n",
      "[11300]\ttraining's rmse: 0.0956056\tvalid_1's rmse: 0.182078\n",
      "[11400]\ttraining's rmse: 0.0951726\tvalid_1's rmse: 0.18206\n",
      "[11500]\ttraining's rmse: 0.0947219\tvalid_1's rmse: 0.182046\n",
      "[11600]\ttraining's rmse: 0.0942776\tvalid_1's rmse: 0.182026\n",
      "[11700]\ttraining's rmse: 0.0938373\tvalid_1's rmse: 0.182004\n",
      "[11800]\ttraining's rmse: 0.0934144\tvalid_1's rmse: 0.181993\n",
      "[11900]\ttraining's rmse: 0.0929934\tvalid_1's rmse: 0.181973\n",
      "[12000]\ttraining's rmse: 0.0925668\tvalid_1's rmse: 0.181964\n",
      "[12100]\ttraining's rmse: 0.0921505\tvalid_1's rmse: 0.181946\n",
      "[12200]\ttraining's rmse: 0.0917276\tvalid_1's rmse: 0.181927\n",
      "[12300]\ttraining's rmse: 0.0913145\tvalid_1's rmse: 0.181905\n",
      "[12400]\ttraining's rmse: 0.0909056\tvalid_1's rmse: 0.181893\n",
      "[12500]\ttraining's rmse: 0.0905038\tvalid_1's rmse: 0.181867\n",
      "[12600]\ttraining's rmse: 0.0901182\tvalid_1's rmse: 0.181849\n",
      "[12700]\ttraining's rmse: 0.0897059\tvalid_1's rmse: 0.181832\n",
      "[12800]\ttraining's rmse: 0.0893018\tvalid_1's rmse: 0.181808\n",
      "[12900]\ttraining's rmse: 0.0889058\tvalid_1's rmse: 0.181794\n",
      "[13000]\ttraining's rmse: 0.0885069\tvalid_1's rmse: 0.181771\n",
      "[13100]\ttraining's rmse: 0.0881052\tvalid_1's rmse: 0.181751\n",
      "[13200]\ttraining's rmse: 0.087708\tvalid_1's rmse: 0.181731\n",
      "[13300]\ttraining's rmse: 0.0873312\tvalid_1's rmse: 0.18171\n",
      "[13400]\ttraining's rmse: 0.086947\tvalid_1's rmse: 0.181687\n",
      "[13500]\ttraining's rmse: 0.0865693\tvalid_1's rmse: 0.181673\n",
      "[13600]\ttraining's rmse: 0.0861851\tvalid_1's rmse: 0.181653\n",
      "[13700]\ttraining's rmse: 0.0858069\tvalid_1's rmse: 0.181632\n",
      "[13800]\ttraining's rmse: 0.0854399\tvalid_1's rmse: 0.181621\n",
      "[13900]\ttraining's rmse: 0.0850718\tvalid_1's rmse: 0.181605\n",
      "[14000]\ttraining's rmse: 0.0847029\tvalid_1's rmse: 0.181591\n",
      "[14100]\ttraining's rmse: 0.0843381\tvalid_1's rmse: 0.181575\n",
      "[14200]\ttraining's rmse: 0.0839731\tvalid_1's rmse: 0.181557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14300]\ttraining's rmse: 0.0836114\tvalid_1's rmse: 0.181544\n",
      "[14400]\ttraining's rmse: 0.0832546\tvalid_1's rmse: 0.181527\n",
      "[14500]\ttraining's rmse: 0.082902\tvalid_1's rmse: 0.181514\n",
      "[14600]\ttraining's rmse: 0.0825314\tvalid_1's rmse: 0.181497\n",
      "[14700]\ttraining's rmse: 0.0821645\tvalid_1's rmse: 0.181477\n",
      "[14800]\ttraining's rmse: 0.0818162\tvalid_1's rmse: 0.181465\n",
      "[14900]\ttraining's rmse: 0.0814573\tvalid_1's rmse: 0.181454\n",
      "[15000]\ttraining's rmse: 0.0811067\tvalid_1's rmse: 0.181442\n",
      "[15100]\ttraining's rmse: 0.080758\tvalid_1's rmse: 0.181423\n",
      "[15200]\ttraining's rmse: 0.0804166\tvalid_1's rmse: 0.18142\n",
      "[15300]\ttraining's rmse: 0.0800781\tvalid_1's rmse: 0.181409\n",
      "[15400]\ttraining's rmse: 0.0797376\tvalid_1's rmse: 0.181399\n",
      "[15500]\ttraining's rmse: 0.0793947\tvalid_1's rmse: 0.181387\n",
      "[15600]\ttraining's rmse: 0.0790572\tvalid_1's rmse: 0.181379\n",
      "[15700]\ttraining's rmse: 0.0787115\tvalid_1's rmse: 0.181366\n",
      "[15800]\ttraining's rmse: 0.0783825\tvalid_1's rmse: 0.181348\n",
      "[15900]\ttraining's rmse: 0.0780654\tvalid_1's rmse: 0.181335\n",
      "[16000]\ttraining's rmse: 0.0777433\tvalid_1's rmse: 0.181323\n",
      "[16100]\ttraining's rmse: 0.0774183\tvalid_1's rmse: 0.181306\n",
      "[16200]\ttraining's rmse: 0.0770884\tvalid_1's rmse: 0.181298\n",
      "[16300]\ttraining's rmse: 0.0767654\tvalid_1's rmse: 0.181287\n",
      "[16400]\ttraining's rmse: 0.0764437\tvalid_1's rmse: 0.181283\n",
      "[16500]\ttraining's rmse: 0.0761269\tvalid_1's rmse: 0.181275\n",
      "[16600]\ttraining's rmse: 0.0758111\tvalid_1's rmse: 0.181266\n",
      "[16700]\ttraining's rmse: 0.0754977\tvalid_1's rmse: 0.181251\n",
      "[16800]\ttraining's rmse: 0.0751817\tvalid_1's rmse: 0.181237\n",
      "[16900]\ttraining's rmse: 0.074864\tvalid_1's rmse: 0.181234\n",
      "[17000]\ttraining's rmse: 0.0745481\tvalid_1's rmse: 0.181227\n",
      "[17100]\ttraining's rmse: 0.0742391\tvalid_1's rmse: 0.181219\n",
      "[17200]\ttraining's rmse: 0.0739429\tvalid_1's rmse: 0.181213\n",
      "[17300]\ttraining's rmse: 0.0736374\tvalid_1's rmse: 0.181204\n",
      "[17400]\ttraining's rmse: 0.0733372\tvalid_1's rmse: 0.181194\n",
      "[17500]\ttraining's rmse: 0.07305\tvalid_1's rmse: 0.181189\n",
      "[17600]\ttraining's rmse: 0.0727493\tvalid_1's rmse: 0.181179\n",
      "[17700]\ttraining's rmse: 0.0724543\tvalid_1's rmse: 0.181174\n",
      "[17800]\ttraining's rmse: 0.0721562\tvalid_1's rmse: 0.181161\n",
      "[17900]\ttraining's rmse: 0.0718614\tvalid_1's rmse: 0.181159\n",
      "[18000]\ttraining's rmse: 0.0715811\tvalid_1's rmse: 0.181155\n",
      "[18100]\ttraining's rmse: 0.0712977\tvalid_1's rmse: 0.181149\n",
      "[18200]\ttraining's rmse: 0.0709973\tvalid_1's rmse: 0.18114\n",
      "[18300]\ttraining's rmse: 0.0707049\tvalid_1's rmse: 0.181133\n",
      "[18400]\ttraining's rmse: 0.0704119\tvalid_1's rmse: 0.181127\n",
      "[18500]\ttraining's rmse: 0.0701187\tvalid_1's rmse: 0.181125\n",
      "[18600]\ttraining's rmse: 0.0698271\tvalid_1's rmse: 0.181118\n",
      "[18700]\ttraining's rmse: 0.0695454\tvalid_1's rmse: 0.181109\n",
      "[18800]\ttraining's rmse: 0.0692566\tvalid_1's rmse: 0.181107\n",
      "[18900]\ttraining's rmse: 0.068981\tvalid_1's rmse: 0.181102\n",
      "Early stopping, best iteration is:\n",
      "[18864]\ttraining's rmse: 0.0690747\tvalid_1's rmse: 0.181102\n",
      "1 76.3034359632 1561.15766384\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356141\tvalid_1's rmse: 0.359306\n",
      "[200]\ttraining's rmse: 0.258595\tvalid_1's rmse: 0.2632\n",
      "[300]\ttraining's rmse: 0.226123\tvalid_1's rmse: 0.231727\n",
      "[400]\ttraining's rmse: 0.211693\tvalid_1's rmse: 0.218377\n",
      "[500]\ttraining's rmse: 0.202877\tvalid_1's rmse: 0.210766\n",
      "[600]\ttraining's rmse: 0.196363\tvalid_1's rmse: 0.20542\n",
      "[700]\ttraining's rmse: 0.191254\tvalid_1's rmse: 0.201486\n",
      "[800]\ttraining's rmse: 0.187104\tvalid_1's rmse: 0.198581\n",
      "[900]\ttraining's rmse: 0.183587\tvalid_1's rmse: 0.196407\n",
      "[1000]\ttraining's rmse: 0.180524\tvalid_1's rmse: 0.194776\n",
      "[1100]\ttraining's rmse: 0.177811\tvalid_1's rmse: 0.193394\n",
      "[1200]\ttraining's rmse: 0.175395\tvalid_1's rmse: 0.192243\n",
      "[1300]\ttraining's rmse: 0.17323\tvalid_1's rmse: 0.191331\n",
      "[1400]\ttraining's rmse: 0.171264\tvalid_1's rmse: 0.190624\n",
      "[1500]\ttraining's rmse: 0.169402\tvalid_1's rmse: 0.189994\n",
      "[1600]\ttraining's rmse: 0.167675\tvalid_1's rmse: 0.189461\n",
      "[1700]\ttraining's rmse: 0.166026\tvalid_1's rmse: 0.188987\n",
      "[1800]\ttraining's rmse: 0.164483\tvalid_1's rmse: 0.188584\n",
      "[1900]\ttraining's rmse: 0.162986\tvalid_1's rmse: 0.188186\n",
      "[2000]\ttraining's rmse: 0.161581\tvalid_1's rmse: 0.187919\n",
      "[2100]\ttraining's rmse: 0.160218\tvalid_1's rmse: 0.187624\n",
      "[2200]\ttraining's rmse: 0.158916\tvalid_1's rmse: 0.187345\n",
      "[2300]\ttraining's rmse: 0.157657\tvalid_1's rmse: 0.187098\n",
      "[2400]\ttraining's rmse: 0.156416\tvalid_1's rmse: 0.186857\n",
      "[2500]\ttraining's rmse: 0.155217\tvalid_1's rmse: 0.186619\n",
      "[2600]\ttraining's rmse: 0.154046\tvalid_1's rmse: 0.186418\n",
      "[2700]\ttraining's rmse: 0.152891\tvalid_1's rmse: 0.186195\n",
      "[2800]\ttraining's rmse: 0.151804\tvalid_1's rmse: 0.186025\n",
      "[2900]\ttraining's rmse: 0.150735\tvalid_1's rmse: 0.185846\n",
      "[3000]\ttraining's rmse: 0.149677\tvalid_1's rmse: 0.185665\n",
      "[3100]\ttraining's rmse: 0.148646\tvalid_1's rmse: 0.185498\n",
      "[3200]\ttraining's rmse: 0.147639\tvalid_1's rmse: 0.185344\n",
      "[3300]\ttraining's rmse: 0.146663\tvalid_1's rmse: 0.185173\n",
      "[3400]\ttraining's rmse: 0.145697\tvalid_1's rmse: 0.185024\n",
      "[3500]\ttraining's rmse: 0.144757\tvalid_1's rmse: 0.184888\n",
      "[3600]\ttraining's rmse: 0.143816\tvalid_1's rmse: 0.184728\n",
      "[3700]\ttraining's rmse: 0.142891\tvalid_1's rmse: 0.184595\n",
      "[3800]\ttraining's rmse: 0.141959\tvalid_1's rmse: 0.184486\n",
      "[3900]\ttraining's rmse: 0.141074\tvalid_1's rmse: 0.184373\n",
      "[4000]\ttraining's rmse: 0.140209\tvalid_1's rmse: 0.18428\n",
      "[4100]\ttraining's rmse: 0.139338\tvalid_1's rmse: 0.18418\n",
      "[4200]\ttraining's rmse: 0.138469\tvalid_1's rmse: 0.184085\n",
      "[4300]\ttraining's rmse: 0.137648\tvalid_1's rmse: 0.18401\n",
      "[4400]\ttraining's rmse: 0.136829\tvalid_1's rmse: 0.183932\n",
      "[4500]\ttraining's rmse: 0.136028\tvalid_1's rmse: 0.183853\n",
      "[4600]\ttraining's rmse: 0.135212\tvalid_1's rmse: 0.183781\n",
      "[4700]\ttraining's rmse: 0.134419\tvalid_1's rmse: 0.183705\n",
      "[4800]\ttraining's rmse: 0.133641\tvalid_1's rmse: 0.183636\n",
      "[4900]\ttraining's rmse: 0.132883\tvalid_1's rmse: 0.183558\n",
      "[5000]\ttraining's rmse: 0.132109\tvalid_1's rmse: 0.183492\n",
      "[5100]\ttraining's rmse: 0.13136\tvalid_1's rmse: 0.183399\n",
      "[5200]\ttraining's rmse: 0.13062\tvalid_1's rmse: 0.183334\n",
      "[5300]\ttraining's rmse: 0.129866\tvalid_1's rmse: 0.183259\n",
      "[5400]\ttraining's rmse: 0.129144\tvalid_1's rmse: 0.183165\n",
      "[5500]\ttraining's rmse: 0.128434\tvalid_1's rmse: 0.183115\n",
      "[5600]\ttraining's rmse: 0.127726\tvalid_1's rmse: 0.18305\n",
      "[5700]\ttraining's rmse: 0.12703\tvalid_1's rmse: 0.182986\n",
      "[5800]\ttraining's rmse: 0.126324\tvalid_1's rmse: 0.182925\n",
      "[5900]\ttraining's rmse: 0.125638\tvalid_1's rmse: 0.182866\n",
      "[6000]\ttraining's rmse: 0.124949\tvalid_1's rmse: 0.182818\n",
      "[6100]\ttraining's rmse: 0.124265\tvalid_1's rmse: 0.182763\n",
      "[6200]\ttraining's rmse: 0.123586\tvalid_1's rmse: 0.182699\n",
      "[6300]\ttraining's rmse: 0.122923\tvalid_1's rmse: 0.182658\n",
      "[6400]\ttraining's rmse: 0.12227\tvalid_1's rmse: 0.182593\n",
      "[6500]\ttraining's rmse: 0.12162\tvalid_1's rmse: 0.182537\n",
      "[6600]\ttraining's rmse: 0.120968\tvalid_1's rmse: 0.182486\n",
      "[6700]\ttraining's rmse: 0.120338\tvalid_1's rmse: 0.182452\n",
      "[6800]\ttraining's rmse: 0.119691\tvalid_1's rmse: 0.18241\n",
      "[6900]\ttraining's rmse: 0.119067\tvalid_1's rmse: 0.182379\n",
      "[7000]\ttraining's rmse: 0.118444\tvalid_1's rmse: 0.182348\n",
      "[7100]\ttraining's rmse: 0.117837\tvalid_1's rmse: 0.182301\n",
      "[7200]\ttraining's rmse: 0.117222\tvalid_1's rmse: 0.182262\n",
      "[7300]\ttraining's rmse: 0.11663\tvalid_1's rmse: 0.182226\n",
      "[7400]\ttraining's rmse: 0.11602\tvalid_1's rmse: 0.18219\n",
      "[7500]\ttraining's rmse: 0.115432\tvalid_1's rmse: 0.182155\n",
      "[7600]\ttraining's rmse: 0.114857\tvalid_1's rmse: 0.182113\n",
      "[7700]\ttraining's rmse: 0.114269\tvalid_1's rmse: 0.182075\n",
      "[7800]\ttraining's rmse: 0.113703\tvalid_1's rmse: 0.182054\n",
      "[7900]\ttraining's rmse: 0.113141\tvalid_1's rmse: 0.182027\n",
      "[8000]\ttraining's rmse: 0.112576\tvalid_1's rmse: 0.181997\n",
      "[8100]\ttraining's rmse: 0.112022\tvalid_1's rmse: 0.181959\n",
      "[8200]\ttraining's rmse: 0.111474\tvalid_1's rmse: 0.181937\n",
      "[8300]\ttraining's rmse: 0.110934\tvalid_1's rmse: 0.181907\n",
      "[8400]\ttraining's rmse: 0.110396\tvalid_1's rmse: 0.181885\n",
      "[8500]\ttraining's rmse: 0.109872\tvalid_1's rmse: 0.181863\n",
      "[8600]\ttraining's rmse: 0.109351\tvalid_1's rmse: 0.181825\n",
      "[8700]\ttraining's rmse: 0.108831\tvalid_1's rmse: 0.181795\n",
      "[8800]\ttraining's rmse: 0.108302\tvalid_1's rmse: 0.181778\n",
      "[8900]\ttraining's rmse: 0.107771\tvalid_1's rmse: 0.181747\n",
      "[9000]\ttraining's rmse: 0.107258\tvalid_1's rmse: 0.18173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9100]\ttraining's rmse: 0.106746\tvalid_1's rmse: 0.181707\n",
      "[9200]\ttraining's rmse: 0.10625\tvalid_1's rmse: 0.181693\n",
      "[9300]\ttraining's rmse: 0.105734\tvalid_1's rmse: 0.181661\n",
      "[9400]\ttraining's rmse: 0.105223\tvalid_1's rmse: 0.181624\n",
      "[9500]\ttraining's rmse: 0.104711\tvalid_1's rmse: 0.181609\n",
      "[9600]\ttraining's rmse: 0.104226\tvalid_1's rmse: 0.181592\n",
      "[9700]\ttraining's rmse: 0.103736\tvalid_1's rmse: 0.181579\n",
      "[9800]\ttraining's rmse: 0.103241\tvalid_1's rmse: 0.181553\n",
      "[9900]\ttraining's rmse: 0.102763\tvalid_1's rmse: 0.181517\n",
      "[10000]\ttraining's rmse: 0.102285\tvalid_1's rmse: 0.181492\n",
      "[10100]\ttraining's rmse: 0.101812\tvalid_1's rmse: 0.181462\n",
      "[10200]\ttraining's rmse: 0.101349\tvalid_1's rmse: 0.181444\n",
      "[10300]\ttraining's rmse: 0.10088\tvalid_1's rmse: 0.18142\n",
      "[10400]\ttraining's rmse: 0.100418\tvalid_1's rmse: 0.181395\n",
      "[10500]\ttraining's rmse: 0.0999506\tvalid_1's rmse: 0.18138\n",
      "[10600]\ttraining's rmse: 0.0994969\tvalid_1's rmse: 0.181356\n",
      "[10700]\ttraining's rmse: 0.0990484\tvalid_1's rmse: 0.181332\n",
      "[10800]\ttraining's rmse: 0.0985905\tvalid_1's rmse: 0.181315\n",
      "[10900]\ttraining's rmse: 0.0981435\tvalid_1's rmse: 0.181294\n",
      "[11000]\ttraining's rmse: 0.0976949\tvalid_1's rmse: 0.181282\n",
      "[11100]\ttraining's rmse: 0.0972526\tvalid_1's rmse: 0.181266\n",
      "[11200]\ttraining's rmse: 0.0968161\tvalid_1's rmse: 0.181246\n",
      "[11300]\ttraining's rmse: 0.0963663\tvalid_1's rmse: 0.181226\n",
      "[11400]\ttraining's rmse: 0.0959504\tvalid_1's rmse: 0.181205\n",
      "[11500]\ttraining's rmse: 0.0955219\tvalid_1's rmse: 0.181187\n",
      "[11600]\ttraining's rmse: 0.0950858\tvalid_1's rmse: 0.181157\n",
      "[11700]\ttraining's rmse: 0.0946684\tvalid_1's rmse: 0.181139\n",
      "[11800]\ttraining's rmse: 0.0942492\tvalid_1's rmse: 0.181132\n",
      "[11900]\ttraining's rmse: 0.0938215\tvalid_1's rmse: 0.181112\n",
      "[12000]\ttraining's rmse: 0.0933978\tvalid_1's rmse: 0.181092\n",
      "[12100]\ttraining's rmse: 0.0929861\tvalid_1's rmse: 0.18108\n",
      "[12200]\ttraining's rmse: 0.0925798\tvalid_1's rmse: 0.181067\n",
      "[12300]\ttraining's rmse: 0.092175\tvalid_1's rmse: 0.181048\n",
      "[12400]\ttraining's rmse: 0.0917641\tvalid_1's rmse: 0.181029\n",
      "[12500]\ttraining's rmse: 0.0913471\tvalid_1's rmse: 0.181004\n",
      "[12600]\ttraining's rmse: 0.0909415\tvalid_1's rmse: 0.180988\n",
      "[12700]\ttraining's rmse: 0.0905492\tvalid_1's rmse: 0.180979\n",
      "[12800]\ttraining's rmse: 0.0901518\tvalid_1's rmse: 0.180962\n",
      "[12900]\ttraining's rmse: 0.0897651\tvalid_1's rmse: 0.180945\n",
      "[13000]\ttraining's rmse: 0.0893725\tvalid_1's rmse: 0.180927\n",
      "[13100]\ttraining's rmse: 0.0889825\tvalid_1's rmse: 0.18091\n",
      "[13200]\ttraining's rmse: 0.0885799\tvalid_1's rmse: 0.180893\n",
      "[13300]\ttraining's rmse: 0.0881903\tvalid_1's rmse: 0.180874\n",
      "[13400]\ttraining's rmse: 0.0877991\tvalid_1's rmse: 0.180856\n",
      "[13500]\ttraining's rmse: 0.0874239\tvalid_1's rmse: 0.18084\n",
      "[13600]\ttraining's rmse: 0.0870324\tvalid_1's rmse: 0.180829\n",
      "[13700]\ttraining's rmse: 0.0866482\tvalid_1's rmse: 0.180817\n",
      "[13800]\ttraining's rmse: 0.0862764\tvalid_1's rmse: 0.180804\n",
      "[13900]\ttraining's rmse: 0.0858998\tvalid_1's rmse: 0.180796\n",
      "[14000]\ttraining's rmse: 0.0855242\tvalid_1's rmse: 0.180792\n",
      "[14100]\ttraining's rmse: 0.085158\tvalid_1's rmse: 0.180783\n",
      "[14200]\ttraining's rmse: 0.0847973\tvalid_1's rmse: 0.180771\n",
      "[14300]\ttraining's rmse: 0.0844468\tvalid_1's rmse: 0.180761\n",
      "[14400]\ttraining's rmse: 0.0840786\tvalid_1's rmse: 0.180751\n",
      "[14500]\ttraining's rmse: 0.0837058\tvalid_1's rmse: 0.180738\n",
      "[14600]\ttraining's rmse: 0.0833571\tvalid_1's rmse: 0.180728\n",
      "[14700]\ttraining's rmse: 0.0830009\tvalid_1's rmse: 0.180721\n",
      "[14800]\ttraining's rmse: 0.0826473\tvalid_1's rmse: 0.180712\n",
      "[14900]\ttraining's rmse: 0.0822917\tvalid_1's rmse: 0.180706\n",
      "[15000]\ttraining's rmse: 0.0819478\tvalid_1's rmse: 0.180707\n",
      "Early stopping, best iteration is:\n",
      "[14927]\ttraining's rmse: 0.0822046\tvalid_1's rmse: 0.180704\n",
      "2 76.6187430299 213.758632714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 3\n",
      "60.329488352\n",
      "146.330042299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:13<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356266\tvalid_1's rmse: 0.354439\n",
      "[200]\ttraining's rmse: 0.258193\tvalid_1's rmse: 0.259486\n",
      "[300]\ttraining's rmse: 0.225943\tvalid_1's rmse: 0.229512\n",
      "[400]\ttraining's rmse: 0.211044\tvalid_1's rmse: 0.216585\n",
      "[500]\ttraining's rmse: 0.202068\tvalid_1's rmse: 0.209495\n",
      "[600]\ttraining's rmse: 0.195551\tvalid_1's rmse: 0.204744\n",
      "[700]\ttraining's rmse: 0.190475\tvalid_1's rmse: 0.201371\n",
      "[800]\ttraining's rmse: 0.186282\tvalid_1's rmse: 0.198742\n",
      "[900]\ttraining's rmse: 0.182705\tvalid_1's rmse: 0.196696\n",
      "[1000]\ttraining's rmse: 0.179604\tvalid_1's rmse: 0.195012\n",
      "[1100]\ttraining's rmse: 0.176884\tvalid_1's rmse: 0.193656\n",
      "[1200]\ttraining's rmse: 0.174458\tvalid_1's rmse: 0.192602\n",
      "[1300]\ttraining's rmse: 0.172221\tvalid_1's rmse: 0.191727\n",
      "[1400]\ttraining's rmse: 0.170204\tvalid_1's rmse: 0.191032\n",
      "[1500]\ttraining's rmse: 0.168344\tvalid_1's rmse: 0.190389\n",
      "[1600]\ttraining's rmse: 0.166569\tvalid_1's rmse: 0.189826\n",
      "[1700]\ttraining's rmse: 0.164899\tvalid_1's rmse: 0.189322\n",
      "[1800]\ttraining's rmse: 0.163338\tvalid_1's rmse: 0.188918\n",
      "[1900]\ttraining's rmse: 0.161896\tvalid_1's rmse: 0.188557\n",
      "[2000]\ttraining's rmse: 0.16046\tvalid_1's rmse: 0.188222\n",
      "[2100]\ttraining's rmse: 0.159109\tvalid_1's rmse: 0.187902\n",
      "[2200]\ttraining's rmse: 0.157814\tvalid_1's rmse: 0.187652\n",
      "[2300]\ttraining's rmse: 0.156557\tvalid_1's rmse: 0.187388\n",
      "[2400]\ttraining's rmse: 0.155357\tvalid_1's rmse: 0.187174\n",
      "[2500]\ttraining's rmse: 0.154167\tvalid_1's rmse: 0.186976\n",
      "[2600]\ttraining's rmse: 0.153017\tvalid_1's rmse: 0.186772\n",
      "[2700]\ttraining's rmse: 0.151901\tvalid_1's rmse: 0.186598\n",
      "[2800]\ttraining's rmse: 0.15083\tvalid_1's rmse: 0.186428\n",
      "[2900]\ttraining's rmse: 0.149768\tvalid_1's rmse: 0.186267\n",
      "[3000]\ttraining's rmse: 0.148728\tvalid_1's rmse: 0.186124\n",
      "[3100]\ttraining's rmse: 0.147714\tvalid_1's rmse: 0.185976\n",
      "[3200]\ttraining's rmse: 0.146718\tvalid_1's rmse: 0.185873\n",
      "[3300]\ttraining's rmse: 0.145732\tvalid_1's rmse: 0.185732\n",
      "[3400]\ttraining's rmse: 0.144759\tvalid_1's rmse: 0.185606\n",
      "[3500]\ttraining's rmse: 0.143798\tvalid_1's rmse: 0.185488\n",
      "[3600]\ttraining's rmse: 0.142869\tvalid_1's rmse: 0.185382\n",
      "[3700]\ttraining's rmse: 0.141961\tvalid_1's rmse: 0.185274\n",
      "[3800]\ttraining's rmse: 0.141075\tvalid_1's rmse: 0.185183\n",
      "[3900]\ttraining's rmse: 0.140196\tvalid_1's rmse: 0.185085\n",
      "[4000]\ttraining's rmse: 0.13934\tvalid_1's rmse: 0.185007\n",
      "[4100]\ttraining's rmse: 0.138498\tvalid_1's rmse: 0.184918\n",
      "[4200]\ttraining's rmse: 0.137647\tvalid_1's rmse: 0.184838\n",
      "[4300]\ttraining's rmse: 0.1368\tvalid_1's rmse: 0.184753\n",
      "[4400]\ttraining's rmse: 0.135978\tvalid_1's rmse: 0.184659\n",
      "[4500]\ttraining's rmse: 0.135166\tvalid_1's rmse: 0.184576\n",
      "[4600]\ttraining's rmse: 0.13435\tvalid_1's rmse: 0.184498\n",
      "[4700]\ttraining's rmse: 0.133542\tvalid_1's rmse: 0.184407\n",
      "[4800]\ttraining's rmse: 0.132787\tvalid_1's rmse: 0.184355\n",
      "[4900]\ttraining's rmse: 0.132015\tvalid_1's rmse: 0.184271\n",
      "[5000]\ttraining's rmse: 0.13125\tvalid_1's rmse: 0.184195\n",
      "[5100]\ttraining's rmse: 0.130486\tvalid_1's rmse: 0.184121\n",
      "[5200]\ttraining's rmse: 0.129744\tvalid_1's rmse: 0.184048\n",
      "[5300]\ttraining's rmse: 0.128994\tvalid_1's rmse: 0.183982\n",
      "[5400]\ttraining's rmse: 0.128269\tvalid_1's rmse: 0.183915\n",
      "[5500]\ttraining's rmse: 0.127538\tvalid_1's rmse: 0.183858\n",
      "[5600]\ttraining's rmse: 0.126813\tvalid_1's rmse: 0.183802\n",
      "[5700]\ttraining's rmse: 0.126105\tvalid_1's rmse: 0.183741\n",
      "[5800]\ttraining's rmse: 0.125396\tvalid_1's rmse: 0.183693\n",
      "[5900]\ttraining's rmse: 0.124716\tvalid_1's rmse: 0.183631\n",
      "[6000]\ttraining's rmse: 0.124024\tvalid_1's rmse: 0.183567\n",
      "[6100]\ttraining's rmse: 0.123344\tvalid_1's rmse: 0.183546\n",
      "[6200]\ttraining's rmse: 0.12267\tvalid_1's rmse: 0.183511\n",
      "[6300]\ttraining's rmse: 0.122008\tvalid_1's rmse: 0.183475\n",
      "[6400]\ttraining's rmse: 0.121337\tvalid_1's rmse: 0.183419\n",
      "[6500]\ttraining's rmse: 0.120687\tvalid_1's rmse: 0.183382\n",
      "[6600]\ttraining's rmse: 0.120039\tvalid_1's rmse: 0.183347\n",
      "[6700]\ttraining's rmse: 0.119391\tvalid_1's rmse: 0.183314\n",
      "[6800]\ttraining's rmse: 0.118758\tvalid_1's rmse: 0.183266\n",
      "[6900]\ttraining's rmse: 0.118127\tvalid_1's rmse: 0.18324\n",
      "[7000]\ttraining's rmse: 0.117514\tvalid_1's rmse: 0.183215\n",
      "[7100]\ttraining's rmse: 0.1169\tvalid_1's rmse: 0.183184\n",
      "[7200]\ttraining's rmse: 0.116291\tvalid_1's rmse: 0.183147\n",
      "[7300]\ttraining's rmse: 0.115696\tvalid_1's rmse: 0.183118\n",
      "[7400]\ttraining's rmse: 0.115111\tvalid_1's rmse: 0.183088\n",
      "[7500]\ttraining's rmse: 0.114521\tvalid_1's rmse: 0.18306\n",
      "[7600]\ttraining's rmse: 0.113939\tvalid_1's rmse: 0.183035\n",
      "[7700]\ttraining's rmse: 0.113366\tvalid_1's rmse: 0.183013\n",
      "[7800]\ttraining's rmse: 0.112809\tvalid_1's rmse: 0.182984\n",
      "[7900]\ttraining's rmse: 0.112259\tvalid_1's rmse: 0.182951\n",
      "[8000]\ttraining's rmse: 0.111692\tvalid_1's rmse: 0.182919\n",
      "[8100]\ttraining's rmse: 0.111123\tvalid_1's rmse: 0.182882\n",
      "[8200]\ttraining's rmse: 0.110589\tvalid_1's rmse: 0.182854\n",
      "[8300]\ttraining's rmse: 0.110033\tvalid_1's rmse: 0.182828\n",
      "[8400]\ttraining's rmse: 0.10949\tvalid_1's rmse: 0.18281\n",
      "[8500]\ttraining's rmse: 0.108957\tvalid_1's rmse: 0.182777\n",
      "[8600]\ttraining's rmse: 0.108419\tvalid_1's rmse: 0.182742\n",
      "[8700]\ttraining's rmse: 0.107894\tvalid_1's rmse: 0.182712\n",
      "[8800]\ttraining's rmse: 0.10736\tvalid_1's rmse: 0.182686\n",
      "[8900]\ttraining's rmse: 0.106834\tvalid_1's rmse: 0.182658\n",
      "[9000]\ttraining's rmse: 0.106319\tvalid_1's rmse: 0.182632\n",
      "[9100]\ttraining's rmse: 0.105811\tvalid_1's rmse: 0.182606\n",
      "[9200]\ttraining's rmse: 0.105293\tvalid_1's rmse: 0.182572\n",
      "[9300]\ttraining's rmse: 0.104787\tvalid_1's rmse: 0.182541\n",
      "[9400]\ttraining's rmse: 0.104293\tvalid_1's rmse: 0.182507\n",
      "[9500]\ttraining's rmse: 0.103799\tvalid_1's rmse: 0.182483\n",
      "[9600]\ttraining's rmse: 0.10331\tvalid_1's rmse: 0.182455\n",
      "[9700]\ttraining's rmse: 0.102828\tvalid_1's rmse: 0.182426\n",
      "[9800]\ttraining's rmse: 0.102356\tvalid_1's rmse: 0.182404\n",
      "[9900]\ttraining's rmse: 0.101882\tvalid_1's rmse: 0.182389\n",
      "[10000]\ttraining's rmse: 0.101401\tvalid_1's rmse: 0.182361\n",
      "[10100]\ttraining's rmse: 0.100921\tvalid_1's rmse: 0.182343\n",
      "[10200]\ttraining's rmse: 0.100442\tvalid_1's rmse: 0.182315\n",
      "[10300]\ttraining's rmse: 0.0999813\tvalid_1's rmse: 0.182295\n",
      "[10400]\ttraining's rmse: 0.0995264\tvalid_1's rmse: 0.182273\n",
      "[10500]\ttraining's rmse: 0.0990503\tvalid_1's rmse: 0.182245\n",
      "[10600]\ttraining's rmse: 0.0985879\tvalid_1's rmse: 0.182215\n",
      "[10700]\ttraining's rmse: 0.0981215\tvalid_1's rmse: 0.182197\n",
      "[10800]\ttraining's rmse: 0.097662\tvalid_1's rmse: 0.182176\n",
      "[10900]\ttraining's rmse: 0.0972205\tvalid_1's rmse: 0.182161\n",
      "[11000]\ttraining's rmse: 0.0967709\tvalid_1's rmse: 0.182145\n",
      "[11100]\ttraining's rmse: 0.0963153\tvalid_1's rmse: 0.18213\n",
      "[11200]\ttraining's rmse: 0.0958686\tvalid_1's rmse: 0.18212\n",
      "[11300]\ttraining's rmse: 0.0954403\tvalid_1's rmse: 0.18211\n",
      "[11400]\ttraining's rmse: 0.0950056\tvalid_1's rmse: 0.182097\n",
      "[11500]\ttraining's rmse: 0.0945767\tvalid_1's rmse: 0.182088\n",
      "[11600]\ttraining's rmse: 0.0941428\tvalid_1's rmse: 0.18207\n",
      "[11700]\ttraining's rmse: 0.0937247\tvalid_1's rmse: 0.182056\n",
      "[11800]\ttraining's rmse: 0.0933038\tvalid_1's rmse: 0.182048\n",
      "[11900]\ttraining's rmse: 0.0928836\tvalid_1's rmse: 0.182031\n",
      "[12000]\ttraining's rmse: 0.0924571\tvalid_1's rmse: 0.182014\n",
      "[12100]\ttraining's rmse: 0.0920338\tvalid_1's rmse: 0.181991\n",
      "[12200]\ttraining's rmse: 0.0916203\tvalid_1's rmse: 0.181976\n",
      "[12300]\ttraining's rmse: 0.0912148\tvalid_1's rmse: 0.181957\n",
      "[12400]\ttraining's rmse: 0.0908065\tvalid_1's rmse: 0.181945\n",
      "[12500]\ttraining's rmse: 0.0904034\tvalid_1's rmse: 0.181934\n",
      "[12600]\ttraining's rmse: 0.090011\tvalid_1's rmse: 0.181924\n",
      "[12700]\ttraining's rmse: 0.0896101\tvalid_1's rmse: 0.181914\n",
      "[12800]\ttraining's rmse: 0.0892138\tvalid_1's rmse: 0.181904\n",
      "[12900]\ttraining's rmse: 0.0888228\tvalid_1's rmse: 0.181893\n",
      "[13000]\ttraining's rmse: 0.0884341\tvalid_1's rmse: 0.181886\n",
      "[13100]\ttraining's rmse: 0.0880467\tvalid_1's rmse: 0.181881\n",
      "[13200]\ttraining's rmse: 0.0876492\tvalid_1's rmse: 0.181867\n",
      "[13300]\ttraining's rmse: 0.0872722\tvalid_1's rmse: 0.181857\n",
      "[13400]\ttraining's rmse: 0.0868839\tvalid_1's rmse: 0.181846\n",
      "[13500]\ttraining's rmse: 0.0865186\tvalid_1's rmse: 0.181839\n",
      "[13600]\ttraining's rmse: 0.0861449\tvalid_1's rmse: 0.181831\n",
      "[13700]\ttraining's rmse: 0.0857637\tvalid_1's rmse: 0.181822\n",
      "[13800]\ttraining's rmse: 0.0853967\tvalid_1's rmse: 0.181822\n",
      "[13900]\ttraining's rmse: 0.0850193\tvalid_1's rmse: 0.181812\n",
      "[14000]\ttraining's rmse: 0.0846515\tvalid_1's rmse: 0.181803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14100]\ttraining's rmse: 0.0842953\tvalid_1's rmse: 0.181799\n",
      "[14200]\ttraining's rmse: 0.0839307\tvalid_1's rmse: 0.181789\n",
      "[14300]\ttraining's rmse: 0.0835604\tvalid_1's rmse: 0.18178\n",
      "[14400]\ttraining's rmse: 0.0831995\tvalid_1's rmse: 0.181771\n",
      "[14500]\ttraining's rmse: 0.0828483\tvalid_1's rmse: 0.181762\n",
      "[14600]\ttraining's rmse: 0.0825063\tvalid_1's rmse: 0.181758\n",
      "[14700]\ttraining's rmse: 0.0821576\tvalid_1's rmse: 0.181749\n",
      "[14800]\ttraining's rmse: 0.0817961\tvalid_1's rmse: 0.181742\n",
      "[14900]\ttraining's rmse: 0.081442\tvalid_1's rmse: 0.181729\n",
      "[15000]\ttraining's rmse: 0.0810992\tvalid_1's rmse: 0.18172\n",
      "[15100]\ttraining's rmse: 0.080749\tvalid_1's rmse: 0.181715\n",
      "[15200]\ttraining's rmse: 0.0804126\tvalid_1's rmse: 0.181705\n",
      "[15300]\ttraining's rmse: 0.0800722\tvalid_1's rmse: 0.181697\n",
      "[15400]\ttraining's rmse: 0.0797339\tvalid_1's rmse: 0.181692\n",
      "[15500]\ttraining's rmse: 0.0793959\tvalid_1's rmse: 0.181685\n",
      "[15600]\ttraining's rmse: 0.079065\tvalid_1's rmse: 0.181676\n",
      "[15700]\ttraining's rmse: 0.0787208\tvalid_1's rmse: 0.181663\n",
      "[15800]\ttraining's rmse: 0.0783893\tvalid_1's rmse: 0.181656\n",
      "[15900]\ttraining's rmse: 0.0780547\tvalid_1's rmse: 0.181646\n",
      "[16000]\ttraining's rmse: 0.0777181\tvalid_1's rmse: 0.181638\n",
      "[16100]\ttraining's rmse: 0.0773934\tvalid_1's rmse: 0.181629\n",
      "[16200]\ttraining's rmse: 0.0770715\tvalid_1's rmse: 0.181625\n",
      "[16300]\ttraining's rmse: 0.0767376\tvalid_1's rmse: 0.181617\n",
      "[16400]\ttraining's rmse: 0.0764175\tvalid_1's rmse: 0.181609\n",
      "[16500]\ttraining's rmse: 0.0760999\tvalid_1's rmse: 0.181607\n",
      "[16600]\ttraining's rmse: 0.0757882\tvalid_1's rmse: 0.181605\n",
      "Early stopping, best iteration is:\n",
      "[16526]\ttraining's rmse: 0.0760169\tvalid_1's rmse: 0.181601\n",
      "0 82.1891909099 126.477143031\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355437\tvalid_1's rmse: 0.360399\n",
      "[200]\ttraining's rmse: 0.257715\tvalid_1's rmse: 0.263104\n",
      "[300]\ttraining's rmse: 0.22575\tvalid_1's rmse: 0.231772\n",
      "[400]\ttraining's rmse: 0.210917\tvalid_1's rmse: 0.217916\n",
      "[500]\ttraining's rmse: 0.202078\tvalid_1's rmse: 0.21026\n",
      "[600]\ttraining's rmse: 0.195562\tvalid_1's rmse: 0.205126\n",
      "[700]\ttraining's rmse: 0.190521\tvalid_1's rmse: 0.201513\n",
      "[800]\ttraining's rmse: 0.186373\tvalid_1's rmse: 0.198778\n",
      "[900]\ttraining's rmse: 0.182851\tvalid_1's rmse: 0.196606\n",
      "[1000]\ttraining's rmse: 0.179851\tvalid_1's rmse: 0.194946\n",
      "[1100]\ttraining's rmse: 0.177179\tvalid_1's rmse: 0.193588\n",
      "[1200]\ttraining's rmse: 0.174831\tvalid_1's rmse: 0.192504\n",
      "[1300]\ttraining's rmse: 0.17267\tvalid_1's rmse: 0.191587\n",
      "[1400]\ttraining's rmse: 0.170684\tvalid_1's rmse: 0.190847\n",
      "[1500]\ttraining's rmse: 0.168807\tvalid_1's rmse: 0.190195\n",
      "[1600]\ttraining's rmse: 0.167062\tvalid_1's rmse: 0.189609\n",
      "[1700]\ttraining's rmse: 0.165434\tvalid_1's rmse: 0.189117\n",
      "[1800]\ttraining's rmse: 0.163922\tvalid_1's rmse: 0.188711\n",
      "[1900]\ttraining's rmse: 0.162463\tvalid_1's rmse: 0.188331\n",
      "[2000]\ttraining's rmse: 0.161092\tvalid_1's rmse: 0.188014\n",
      "[2100]\ttraining's rmse: 0.159784\tvalid_1's rmse: 0.187748\n",
      "[2200]\ttraining's rmse: 0.158474\tvalid_1's rmse: 0.1875\n",
      "[2300]\ttraining's rmse: 0.157244\tvalid_1's rmse: 0.187254\n",
      "[2400]\ttraining's rmse: 0.156034\tvalid_1's rmse: 0.187049\n",
      "[2500]\ttraining's rmse: 0.154847\tvalid_1's rmse: 0.186848\n",
      "[2600]\ttraining's rmse: 0.15372\tvalid_1's rmse: 0.186649\n",
      "[2700]\ttraining's rmse: 0.152636\tvalid_1's rmse: 0.186466\n",
      "[2800]\ttraining's rmse: 0.151585\tvalid_1's rmse: 0.186309\n",
      "[2900]\ttraining's rmse: 0.150537\tvalid_1's rmse: 0.186142\n",
      "[3000]\ttraining's rmse: 0.149523\tvalid_1's rmse: 0.185989\n",
      "[3100]\ttraining's rmse: 0.148505\tvalid_1's rmse: 0.185851\n",
      "[3200]\ttraining's rmse: 0.147535\tvalid_1's rmse: 0.185735\n",
      "[3300]\ttraining's rmse: 0.14656\tvalid_1's rmse: 0.185588\n",
      "[3400]\ttraining's rmse: 0.145602\tvalid_1's rmse: 0.185459\n",
      "[3500]\ttraining's rmse: 0.144664\tvalid_1's rmse: 0.185336\n",
      "[3600]\ttraining's rmse: 0.143742\tvalid_1's rmse: 0.185198\n",
      "[3700]\ttraining's rmse: 0.142839\tvalid_1's rmse: 0.185085\n",
      "[3800]\ttraining's rmse: 0.141954\tvalid_1's rmse: 0.184975\n",
      "[3900]\ttraining's rmse: 0.141073\tvalid_1's rmse: 0.184879\n",
      "[4000]\ttraining's rmse: 0.140177\tvalid_1's rmse: 0.184769\n",
      "[4100]\ttraining's rmse: 0.1393\tvalid_1's rmse: 0.184659\n",
      "[4200]\ttraining's rmse: 0.138447\tvalid_1's rmse: 0.184543\n",
      "[4300]\ttraining's rmse: 0.137639\tvalid_1's rmse: 0.184455\n",
      "[4400]\ttraining's rmse: 0.1368\tvalid_1's rmse: 0.184338\n",
      "[4500]\ttraining's rmse: 0.136\tvalid_1's rmse: 0.184249\n",
      "[4600]\ttraining's rmse: 0.135198\tvalid_1's rmse: 0.184174\n",
      "[4700]\ttraining's rmse: 0.134387\tvalid_1's rmse: 0.184093\n",
      "[4800]\ttraining's rmse: 0.133593\tvalid_1's rmse: 0.184003\n",
      "[4900]\ttraining's rmse: 0.132816\tvalid_1's rmse: 0.183911\n",
      "[5000]\ttraining's rmse: 0.132068\tvalid_1's rmse: 0.183844\n",
      "[5100]\ttraining's rmse: 0.13129\tvalid_1's rmse: 0.183778\n",
      "[5200]\ttraining's rmse: 0.130564\tvalid_1's rmse: 0.183701\n",
      "[5300]\ttraining's rmse: 0.129822\tvalid_1's rmse: 0.183625\n",
      "[5400]\ttraining's rmse: 0.129083\tvalid_1's rmse: 0.183543\n",
      "[5500]\ttraining's rmse: 0.128362\tvalid_1's rmse: 0.183489\n",
      "[5600]\ttraining's rmse: 0.127634\tvalid_1's rmse: 0.183426\n",
      "[5700]\ttraining's rmse: 0.12693\tvalid_1's rmse: 0.183366\n",
      "[5800]\ttraining's rmse: 0.126231\tvalid_1's rmse: 0.183307\n",
      "[5900]\ttraining's rmse: 0.125543\tvalid_1's rmse: 0.183239\n",
      "[6000]\ttraining's rmse: 0.124864\tvalid_1's rmse: 0.183174\n",
      "[6100]\ttraining's rmse: 0.124189\tvalid_1's rmse: 0.183127\n",
      "[6200]\ttraining's rmse: 0.123525\tvalid_1's rmse: 0.183069\n",
      "[6300]\ttraining's rmse: 0.122843\tvalid_1's rmse: 0.18303\n",
      "[6400]\ttraining's rmse: 0.122177\tvalid_1's rmse: 0.182964\n",
      "[6500]\ttraining's rmse: 0.121515\tvalid_1's rmse: 0.182923\n",
      "[6600]\ttraining's rmse: 0.120863\tvalid_1's rmse: 0.18287\n",
      "[6700]\ttraining's rmse: 0.12022\tvalid_1's rmse: 0.18282\n",
      "[6800]\ttraining's rmse: 0.119589\tvalid_1's rmse: 0.18278\n",
      "[6900]\ttraining's rmse: 0.118962\tvalid_1's rmse: 0.182735\n",
      "[7000]\ttraining's rmse: 0.118347\tvalid_1's rmse: 0.182706\n",
      "[7100]\ttraining's rmse: 0.117731\tvalid_1's rmse: 0.182669\n",
      "[7200]\ttraining's rmse: 0.117134\tvalid_1's rmse: 0.182612\n",
      "[7300]\ttraining's rmse: 0.11653\tvalid_1's rmse: 0.182568\n",
      "[7400]\ttraining's rmse: 0.11592\tvalid_1's rmse: 0.182514\n",
      "[7500]\ttraining's rmse: 0.115337\tvalid_1's rmse: 0.182477\n",
      "[7600]\ttraining's rmse: 0.114735\tvalid_1's rmse: 0.182442\n",
      "[7700]\ttraining's rmse: 0.114151\tvalid_1's rmse: 0.182402\n",
      "[7800]\ttraining's rmse: 0.113568\tvalid_1's rmse: 0.182369\n",
      "[7900]\ttraining's rmse: 0.112999\tvalid_1's rmse: 0.182337\n",
      "[8000]\ttraining's rmse: 0.112433\tvalid_1's rmse: 0.182307\n",
      "[8100]\ttraining's rmse: 0.111887\tvalid_1's rmse: 0.182278\n",
      "[8200]\ttraining's rmse: 0.111305\tvalid_1's rmse: 0.18224\n",
      "[8300]\ttraining's rmse: 0.110735\tvalid_1's rmse: 0.182207\n",
      "[8400]\ttraining's rmse: 0.110183\tvalid_1's rmse: 0.182174\n",
      "[8500]\ttraining's rmse: 0.109643\tvalid_1's rmse: 0.182131\n",
      "[8600]\ttraining's rmse: 0.109109\tvalid_1's rmse: 0.182094\n",
      "[8700]\ttraining's rmse: 0.108582\tvalid_1's rmse: 0.182052\n",
      "[8800]\ttraining's rmse: 0.108037\tvalid_1's rmse: 0.182012\n",
      "[8900]\ttraining's rmse: 0.107519\tvalid_1's rmse: 0.181995\n",
      "[9000]\ttraining's rmse: 0.106997\tvalid_1's rmse: 0.181971\n",
      "[9100]\ttraining's rmse: 0.106499\tvalid_1's rmse: 0.181962\n",
      "[9200]\ttraining's rmse: 0.105985\tvalid_1's rmse: 0.181937\n",
      "[9300]\ttraining's rmse: 0.105477\tvalid_1's rmse: 0.181922\n",
      "[9400]\ttraining's rmse: 0.104988\tvalid_1's rmse: 0.181901\n",
      "[9500]\ttraining's rmse: 0.104478\tvalid_1's rmse: 0.181883\n",
      "[9600]\ttraining's rmse: 0.103978\tvalid_1's rmse: 0.181856\n",
      "[9700]\ttraining's rmse: 0.103501\tvalid_1's rmse: 0.181838\n",
      "[9800]\ttraining's rmse: 0.103004\tvalid_1's rmse: 0.181811\n",
      "[9900]\ttraining's rmse: 0.102512\tvalid_1's rmse: 0.181794\n",
      "[10000]\ttraining's rmse: 0.102022\tvalid_1's rmse: 0.181777\n",
      "[10100]\ttraining's rmse: 0.101535\tvalid_1's rmse: 0.181758\n",
      "[10200]\ttraining's rmse: 0.101044\tvalid_1's rmse: 0.181732\n",
      "[10300]\ttraining's rmse: 0.100572\tvalid_1's rmse: 0.181707\n",
      "[10400]\ttraining's rmse: 0.10011\tvalid_1's rmse: 0.181689\n",
      "[10500]\ttraining's rmse: 0.0996268\tvalid_1's rmse: 0.181663\n",
      "[10600]\ttraining's rmse: 0.09917\tvalid_1's rmse: 0.181653\n",
      "[10700]\ttraining's rmse: 0.098724\tvalid_1's rmse: 0.181641\n",
      "[10800]\ttraining's rmse: 0.0982643\tvalid_1's rmse: 0.181621\n",
      "[10900]\ttraining's rmse: 0.0978135\tvalid_1's rmse: 0.181602\n",
      "[11000]\ttraining's rmse: 0.0973592\tvalid_1's rmse: 0.181585\n",
      "[11100]\ttraining's rmse: 0.0969158\tvalid_1's rmse: 0.181571\n",
      "[11200]\ttraining's rmse: 0.096475\tvalid_1's rmse: 0.18155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11300]\ttraining's rmse: 0.0960406\tvalid_1's rmse: 0.181529\n",
      "[11400]\ttraining's rmse: 0.0956128\tvalid_1's rmse: 0.181526\n",
      "[11500]\ttraining's rmse: 0.0951655\tvalid_1's rmse: 0.181511\n",
      "[11600]\ttraining's rmse: 0.0947379\tvalid_1's rmse: 0.181492\n",
      "[11700]\ttraining's rmse: 0.0943172\tvalid_1's rmse: 0.181479\n",
      "[11800]\ttraining's rmse: 0.0938895\tvalid_1's rmse: 0.181459\n",
      "[11900]\ttraining's rmse: 0.0934617\tvalid_1's rmse: 0.181444\n",
      "[12000]\ttraining's rmse: 0.0930553\tvalid_1's rmse: 0.181429\n",
      "[12100]\ttraining's rmse: 0.0926528\tvalid_1's rmse: 0.18142\n",
      "[12200]\ttraining's rmse: 0.0922343\tvalid_1's rmse: 0.181401\n",
      "[12300]\ttraining's rmse: 0.0918253\tvalid_1's rmse: 0.181382\n",
      "[12400]\ttraining's rmse: 0.0914135\tvalid_1's rmse: 0.181364\n",
      "[12500]\ttraining's rmse: 0.0910123\tvalid_1's rmse: 0.181348\n",
      "[12600]\ttraining's rmse: 0.0905994\tvalid_1's rmse: 0.181334\n",
      "[12700]\ttraining's rmse: 0.0901971\tvalid_1's rmse: 0.181313\n",
      "[12800]\ttraining's rmse: 0.0897998\tvalid_1's rmse: 0.181291\n",
      "[12900]\ttraining's rmse: 0.0894124\tvalid_1's rmse: 0.181282\n",
      "[13000]\ttraining's rmse: 0.0890138\tvalid_1's rmse: 0.181267\n",
      "[13100]\ttraining's rmse: 0.0886222\tvalid_1's rmse: 0.181254\n",
      "[13200]\ttraining's rmse: 0.0882367\tvalid_1's rmse: 0.181237\n",
      "[13300]\ttraining's rmse: 0.0878563\tvalid_1's rmse: 0.181225\n",
      "[13400]\ttraining's rmse: 0.0874713\tvalid_1's rmse: 0.181221\n",
      "[13500]\ttraining's rmse: 0.0870745\tvalid_1's rmse: 0.181219\n",
      "[13600]\ttraining's rmse: 0.086683\tvalid_1's rmse: 0.181204\n",
      "[13700]\ttraining's rmse: 0.0863001\tvalid_1's rmse: 0.181187\n",
      "[13800]\ttraining's rmse: 0.0859211\tvalid_1's rmse: 0.18118\n",
      "[13900]\ttraining's rmse: 0.0855526\tvalid_1's rmse: 0.18117\n",
      "[14000]\ttraining's rmse: 0.0851883\tvalid_1's rmse: 0.181159\n",
      "[14100]\ttraining's rmse: 0.0848261\tvalid_1's rmse: 0.181147\n",
      "[14200]\ttraining's rmse: 0.0844603\tvalid_1's rmse: 0.181132\n",
      "[14300]\ttraining's rmse: 0.0841012\tvalid_1's rmse: 0.181118\n",
      "[14400]\ttraining's rmse: 0.0837475\tvalid_1's rmse: 0.181106\n",
      "[14500]\ttraining's rmse: 0.0833949\tvalid_1's rmse: 0.181101\n",
      "[14600]\ttraining's rmse: 0.0830383\tvalid_1's rmse: 0.181092\n",
      "[14700]\ttraining's rmse: 0.0826732\tvalid_1's rmse: 0.181084\n",
      "[14800]\ttraining's rmse: 0.0823232\tvalid_1's rmse: 0.181075\n",
      "[14900]\ttraining's rmse: 0.0819828\tvalid_1's rmse: 0.18107\n",
      "[15000]\ttraining's rmse: 0.081638\tvalid_1's rmse: 0.181065\n",
      "[15100]\ttraining's rmse: 0.0812803\tvalid_1's rmse: 0.181053\n",
      "[15200]\ttraining's rmse: 0.0809352\tvalid_1's rmse: 0.181042\n",
      "[15300]\ttraining's rmse: 0.0805896\tvalid_1's rmse: 0.181041\n",
      "[15400]\ttraining's rmse: 0.0802521\tvalid_1's rmse: 0.181036\n",
      "[15500]\ttraining's rmse: 0.0799158\tvalid_1's rmse: 0.181031\n",
      "[15600]\ttraining's rmse: 0.0795738\tvalid_1's rmse: 0.181022\n",
      "[15700]\ttraining's rmse: 0.0792479\tvalid_1's rmse: 0.181009\n",
      "[15800]\ttraining's rmse: 0.0789196\tvalid_1's rmse: 0.180995\n",
      "[15900]\ttraining's rmse: 0.0785936\tvalid_1's rmse: 0.180986\n",
      "[16000]\ttraining's rmse: 0.0782666\tvalid_1's rmse: 0.180974\n",
      "[16100]\ttraining's rmse: 0.077938\tvalid_1's rmse: 0.180962\n",
      "Early stopping, best iteration is:\n",
      "[16072]\ttraining's rmse: 0.078027\tvalid_1's rmse: 0.180959\n",
      "1 75.6074181927 1664.02228293\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355903\tvalid_1's rmse: 0.359319\n",
      "[200]\ttraining's rmse: 0.258455\tvalid_1's rmse: 0.26346\n",
      "[300]\ttraining's rmse: 0.22624\tvalid_1's rmse: 0.232407\n",
      "[400]\ttraining's rmse: 0.211813\tvalid_1's rmse: 0.219062\n",
      "[500]\ttraining's rmse: 0.202949\tvalid_1's rmse: 0.211375\n",
      "[600]\ttraining's rmse: 0.196423\tvalid_1's rmse: 0.205958\n",
      "[700]\ttraining's rmse: 0.191353\tvalid_1's rmse: 0.20207\n",
      "[800]\ttraining's rmse: 0.187218\tvalid_1's rmse: 0.199079\n",
      "[900]\ttraining's rmse: 0.183703\tvalid_1's rmse: 0.196771\n",
      "[1000]\ttraining's rmse: 0.180631\tvalid_1's rmse: 0.195005\n",
      "[1100]\ttraining's rmse: 0.177953\tvalid_1's rmse: 0.193565\n",
      "[1200]\ttraining's rmse: 0.175545\tvalid_1's rmse: 0.192424\n",
      "[1300]\ttraining's rmse: 0.173379\tvalid_1's rmse: 0.191517\n",
      "[1400]\ttraining's rmse: 0.171391\tvalid_1's rmse: 0.19076\n",
      "[1500]\ttraining's rmse: 0.169515\tvalid_1's rmse: 0.190108\n",
      "[1600]\ttraining's rmse: 0.167796\tvalid_1's rmse: 0.189535\n",
      "[1700]\ttraining's rmse: 0.166157\tvalid_1's rmse: 0.189035\n",
      "[1800]\ttraining's rmse: 0.164564\tvalid_1's rmse: 0.188574\n",
      "[1900]\ttraining's rmse: 0.163048\tvalid_1's rmse: 0.188164\n",
      "[2000]\ttraining's rmse: 0.161631\tvalid_1's rmse: 0.187822\n",
      "[2100]\ttraining's rmse: 0.160239\tvalid_1's rmse: 0.18747\n",
      "[2200]\ttraining's rmse: 0.158922\tvalid_1's rmse: 0.187154\n",
      "[2300]\ttraining's rmse: 0.157642\tvalid_1's rmse: 0.186869\n",
      "[2400]\ttraining's rmse: 0.156388\tvalid_1's rmse: 0.186611\n",
      "[2500]\ttraining's rmse: 0.155195\tvalid_1's rmse: 0.186399\n",
      "[2600]\ttraining's rmse: 0.154068\tvalid_1's rmse: 0.186195\n",
      "[2700]\ttraining's rmse: 0.15294\tvalid_1's rmse: 0.186014\n",
      "[2800]\ttraining's rmse: 0.151831\tvalid_1's rmse: 0.185818\n",
      "[2900]\ttraining's rmse: 0.150751\tvalid_1's rmse: 0.185633\n",
      "[3000]\ttraining's rmse: 0.149715\tvalid_1's rmse: 0.185514\n",
      "[3100]\ttraining's rmse: 0.148711\tvalid_1's rmse: 0.18536\n",
      "[3200]\ttraining's rmse: 0.147722\tvalid_1's rmse: 0.185239\n",
      "[3300]\ttraining's rmse: 0.146719\tvalid_1's rmse: 0.185105\n",
      "[3400]\ttraining's rmse: 0.145759\tvalid_1's rmse: 0.184984\n",
      "[3500]\ttraining's rmse: 0.144813\tvalid_1's rmse: 0.184845\n",
      "[3600]\ttraining's rmse: 0.14389\tvalid_1's rmse: 0.184727\n",
      "[3700]\ttraining's rmse: 0.142965\tvalid_1's rmse: 0.184619\n",
      "[3800]\ttraining's rmse: 0.142072\tvalid_1's rmse: 0.184511\n",
      "[3900]\ttraining's rmse: 0.141177\tvalid_1's rmse: 0.184401\n",
      "[4000]\ttraining's rmse: 0.140293\tvalid_1's rmse: 0.184297\n",
      "[4100]\ttraining's rmse: 0.139434\tvalid_1's rmse: 0.184207\n",
      "[4200]\ttraining's rmse: 0.138583\tvalid_1's rmse: 0.184114\n",
      "[4300]\ttraining's rmse: 0.137762\tvalid_1's rmse: 0.184044\n",
      "[4400]\ttraining's rmse: 0.136957\tvalid_1's rmse: 0.183972\n",
      "[4500]\ttraining's rmse: 0.136155\tvalid_1's rmse: 0.183903\n",
      "[4600]\ttraining's rmse: 0.135367\tvalid_1's rmse: 0.183826\n",
      "[4700]\ttraining's rmse: 0.134594\tvalid_1's rmse: 0.183765\n",
      "[4800]\ttraining's rmse: 0.133823\tvalid_1's rmse: 0.183687\n",
      "[4900]\ttraining's rmse: 0.133058\tvalid_1's rmse: 0.183647\n",
      "[5000]\ttraining's rmse: 0.132273\tvalid_1's rmse: 0.183588\n",
      "[5100]\ttraining's rmse: 0.131522\tvalid_1's rmse: 0.183509\n",
      "[5200]\ttraining's rmse: 0.130782\tvalid_1's rmse: 0.183446\n",
      "[5300]\ttraining's rmse: 0.130062\tvalid_1's rmse: 0.183377\n",
      "[5400]\ttraining's rmse: 0.129339\tvalid_1's rmse: 0.183309\n",
      "[5500]\ttraining's rmse: 0.128622\tvalid_1's rmse: 0.183245\n",
      "[5600]\ttraining's rmse: 0.127913\tvalid_1's rmse: 0.183192\n",
      "[5700]\ttraining's rmse: 0.127208\tvalid_1's rmse: 0.183135\n",
      "[5800]\ttraining's rmse: 0.126518\tvalid_1's rmse: 0.183079\n",
      "[5900]\ttraining's rmse: 0.125845\tvalid_1's rmse: 0.183029\n",
      "[6000]\ttraining's rmse: 0.125177\tvalid_1's rmse: 0.182972\n",
      "[6100]\ttraining's rmse: 0.124503\tvalid_1's rmse: 0.182926\n",
      "[6200]\ttraining's rmse: 0.123831\tvalid_1's rmse: 0.182882\n",
      "[6300]\ttraining's rmse: 0.123186\tvalid_1's rmse: 0.182833\n",
      "[6400]\ttraining's rmse: 0.122554\tvalid_1's rmse: 0.182778\n",
      "[6500]\ttraining's rmse: 0.121921\tvalid_1's rmse: 0.182735\n",
      "[6600]\ttraining's rmse: 0.121284\tvalid_1's rmse: 0.182689\n",
      "[6700]\ttraining's rmse: 0.120661\tvalid_1's rmse: 0.182656\n",
      "[6800]\ttraining's rmse: 0.120031\tvalid_1's rmse: 0.182617\n",
      "[6900]\ttraining's rmse: 0.119432\tvalid_1's rmse: 0.182587\n",
      "[7000]\ttraining's rmse: 0.118815\tvalid_1's rmse: 0.182533\n",
      "[7100]\ttraining's rmse: 0.118224\tvalid_1's rmse: 0.182498\n",
      "[7200]\ttraining's rmse: 0.117606\tvalid_1's rmse: 0.182449\n",
      "[7300]\ttraining's rmse: 0.117018\tvalid_1's rmse: 0.18242\n",
      "[7400]\ttraining's rmse: 0.116437\tvalid_1's rmse: 0.18239\n",
      "[7500]\ttraining's rmse: 0.115862\tvalid_1's rmse: 0.182355\n",
      "[7600]\ttraining's rmse: 0.115277\tvalid_1's rmse: 0.18232\n",
      "[7700]\ttraining's rmse: 0.114707\tvalid_1's rmse: 0.18227\n",
      "[7800]\ttraining's rmse: 0.114143\tvalid_1's rmse: 0.182228\n",
      "[7900]\ttraining's rmse: 0.113568\tvalid_1's rmse: 0.18219\n",
      "[8000]\ttraining's rmse: 0.11302\tvalid_1's rmse: 0.182149\n",
      "[8100]\ttraining's rmse: 0.112461\tvalid_1's rmse: 0.182119\n",
      "[8200]\ttraining's rmse: 0.111918\tvalid_1's rmse: 0.182088\n",
      "[8300]\ttraining's rmse: 0.111382\tvalid_1's rmse: 0.182075\n",
      "[8400]\ttraining's rmse: 0.110835\tvalid_1's rmse: 0.182041\n",
      "[8500]\ttraining's rmse: 0.110313\tvalid_1's rmse: 0.182014\n",
      "[8600]\ttraining's rmse: 0.109774\tvalid_1's rmse: 0.181973\n",
      "[8700]\ttraining's rmse: 0.109244\tvalid_1's rmse: 0.181953\n",
      "[8800]\ttraining's rmse: 0.108708\tvalid_1's rmse: 0.181921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8900]\ttraining's rmse: 0.108184\tvalid_1's rmse: 0.181899\n",
      "[9000]\ttraining's rmse: 0.107655\tvalid_1's rmse: 0.181874\n",
      "[9100]\ttraining's rmse: 0.107139\tvalid_1's rmse: 0.181843\n",
      "[9200]\ttraining's rmse: 0.106643\tvalid_1's rmse: 0.181825\n",
      "[9300]\ttraining's rmse: 0.106132\tvalid_1's rmse: 0.181803\n",
      "[9400]\ttraining's rmse: 0.105633\tvalid_1's rmse: 0.181789\n",
      "[9500]\ttraining's rmse: 0.105148\tvalid_1's rmse: 0.181771\n",
      "[9600]\ttraining's rmse: 0.104652\tvalid_1's rmse: 0.181758\n",
      "[9700]\ttraining's rmse: 0.104164\tvalid_1's rmse: 0.181738\n",
      "[9800]\ttraining's rmse: 0.103669\tvalid_1's rmse: 0.181713\n",
      "[9900]\ttraining's rmse: 0.103182\tvalid_1's rmse: 0.181682\n",
      "[10000]\ttraining's rmse: 0.102696\tvalid_1's rmse: 0.181657\n",
      "[10100]\ttraining's rmse: 0.102215\tvalid_1's rmse: 0.181629\n",
      "[10200]\ttraining's rmse: 0.101726\tvalid_1's rmse: 0.181616\n",
      "[10300]\ttraining's rmse: 0.101236\tvalid_1's rmse: 0.181589\n",
      "[10400]\ttraining's rmse: 0.100763\tvalid_1's rmse: 0.181567\n",
      "[10500]\ttraining's rmse: 0.100293\tvalid_1's rmse: 0.181549\n",
      "[10600]\ttraining's rmse: 0.0998362\tvalid_1's rmse: 0.181521\n",
      "[10700]\ttraining's rmse: 0.0993796\tvalid_1's rmse: 0.181504\n",
      "[10800]\ttraining's rmse: 0.0989309\tvalid_1's rmse: 0.181499\n",
      "[10900]\ttraining's rmse: 0.0984798\tvalid_1's rmse: 0.181481\n",
      "[11000]\ttraining's rmse: 0.0980337\tvalid_1's rmse: 0.181468\n",
      "[11100]\ttraining's rmse: 0.0975764\tvalid_1's rmse: 0.181442\n",
      "[11200]\ttraining's rmse: 0.0971349\tvalid_1's rmse: 0.181421\n",
      "[11300]\ttraining's rmse: 0.0966871\tvalid_1's rmse: 0.181398\n",
      "[11400]\ttraining's rmse: 0.0962475\tvalid_1's rmse: 0.181373\n",
      "[11500]\ttraining's rmse: 0.0958006\tvalid_1's rmse: 0.181354\n",
      "[11600]\ttraining's rmse: 0.0953674\tvalid_1's rmse: 0.181331\n",
      "[11700]\ttraining's rmse: 0.0949414\tvalid_1's rmse: 0.181319\n",
      "[11800]\ttraining's rmse: 0.0945168\tvalid_1's rmse: 0.181295\n",
      "[11900]\ttraining's rmse: 0.0940762\tvalid_1's rmse: 0.181272\n",
      "[12000]\ttraining's rmse: 0.0936622\tvalid_1's rmse: 0.181258\n",
      "[12100]\ttraining's rmse: 0.0932549\tvalid_1's rmse: 0.181236\n",
      "[12200]\ttraining's rmse: 0.0928438\tvalid_1's rmse: 0.181211\n",
      "[12300]\ttraining's rmse: 0.0924337\tvalid_1's rmse: 0.181187\n",
      "[12400]\ttraining's rmse: 0.0920123\tvalid_1's rmse: 0.181157\n",
      "[12500]\ttraining's rmse: 0.0916045\tvalid_1's rmse: 0.181146\n",
      "[12600]\ttraining's rmse: 0.091188\tvalid_1's rmse: 0.181128\n",
      "[12700]\ttraining's rmse: 0.0907754\tvalid_1's rmse: 0.181105\n",
      "[12800]\ttraining's rmse: 0.0903641\tvalid_1's rmse: 0.181089\n",
      "[12900]\ttraining's rmse: 0.0899671\tvalid_1's rmse: 0.181079\n",
      "[13000]\ttraining's rmse: 0.0895714\tvalid_1's rmse: 0.181061\n",
      "[13100]\ttraining's rmse: 0.0891813\tvalid_1's rmse: 0.181045\n",
      "[13200]\ttraining's rmse: 0.0887908\tvalid_1's rmse: 0.181028\n",
      "[13300]\ttraining's rmse: 0.0884038\tvalid_1's rmse: 0.181015\n",
      "[13400]\ttraining's rmse: 0.0880146\tvalid_1's rmse: 0.180999\n",
      "[13500]\ttraining's rmse: 0.087625\tvalid_1's rmse: 0.180984\n",
      "[13600]\ttraining's rmse: 0.0872422\tvalid_1's rmse: 0.180973\n",
      "[13700]\ttraining's rmse: 0.0868597\tvalid_1's rmse: 0.180957\n",
      "[13800]\ttraining's rmse: 0.086487\tvalid_1's rmse: 0.180947\n",
      "[13900]\ttraining's rmse: 0.0860989\tvalid_1's rmse: 0.180933\n",
      "[14000]\ttraining's rmse: 0.0857325\tvalid_1's rmse: 0.180924\n",
      "[14100]\ttraining's rmse: 0.0853503\tvalid_1's rmse: 0.180917\n",
      "[14200]\ttraining's rmse: 0.0849785\tvalid_1's rmse: 0.180898\n",
      "[14300]\ttraining's rmse: 0.0846092\tvalid_1's rmse: 0.180892\n",
      "[14400]\ttraining's rmse: 0.0842419\tvalid_1's rmse: 0.180884\n",
      "[14500]\ttraining's rmse: 0.0838724\tvalid_1's rmse: 0.180874\n",
      "[14600]\ttraining's rmse: 0.0835068\tvalid_1's rmse: 0.180865\n",
      "[14700]\ttraining's rmse: 0.0831539\tvalid_1's rmse: 0.180852\n",
      "[14800]\ttraining's rmse: 0.0827943\tvalid_1's rmse: 0.18084\n",
      "[14900]\ttraining's rmse: 0.0824365\tvalid_1's rmse: 0.180827\n",
      "[15000]\ttraining's rmse: 0.0820787\tvalid_1's rmse: 0.180811\n",
      "[15100]\ttraining's rmse: 0.0817248\tvalid_1's rmse: 0.180795\n",
      "[15200]\ttraining's rmse: 0.0813816\tvalid_1's rmse: 0.180789\n",
      "[15300]\ttraining's rmse: 0.0810253\tvalid_1's rmse: 0.180765\n",
      "[15400]\ttraining's rmse: 0.0806781\tvalid_1's rmse: 0.180754\n",
      "[15500]\ttraining's rmse: 0.0803347\tvalid_1's rmse: 0.180749\n",
      "[15600]\ttraining's rmse: 0.0799963\tvalid_1's rmse: 0.180728\n",
      "[15700]\ttraining's rmse: 0.0796535\tvalid_1's rmse: 0.18071\n",
      "[15800]\ttraining's rmse: 0.0793128\tvalid_1's rmse: 0.180689\n",
      "[15900]\ttraining's rmse: 0.0789663\tvalid_1's rmse: 0.180681\n",
      "[16000]\ttraining's rmse: 0.0786451\tvalid_1's rmse: 0.180668\n",
      "[16100]\ttraining's rmse: 0.078316\tvalid_1's rmse: 0.180661\n",
      "[16200]\ttraining's rmse: 0.0779853\tvalid_1's rmse: 0.180644\n",
      "[16300]\ttraining's rmse: 0.0776528\tvalid_1's rmse: 0.180636\n",
      "[16400]\ttraining's rmse: 0.0773319\tvalid_1's rmse: 0.180624\n",
      "[16500]\ttraining's rmse: 0.0770136\tvalid_1's rmse: 0.180611\n",
      "[16600]\ttraining's rmse: 0.0766923\tvalid_1's rmse: 0.180606\n",
      "[16700]\ttraining's rmse: 0.0763673\tvalid_1's rmse: 0.180593\n",
      "[16800]\ttraining's rmse: 0.0760526\tvalid_1's rmse: 0.180583\n",
      "[16900]\ttraining's rmse: 0.0757352\tvalid_1's rmse: 0.180572\n",
      "[17000]\ttraining's rmse: 0.0754135\tvalid_1's rmse: 0.180561\n",
      "[17100]\ttraining's rmse: 0.0751038\tvalid_1's rmse: 0.180546\n",
      "[17200]\ttraining's rmse: 0.0748088\tvalid_1's rmse: 0.180534\n",
      "[17300]\ttraining's rmse: 0.0745113\tvalid_1's rmse: 0.180526\n",
      "[17400]\ttraining's rmse: 0.0742103\tvalid_1's rmse: 0.180519\n",
      "[17500]\ttraining's rmse: 0.0739022\tvalid_1's rmse: 0.180513\n",
      "[17600]\ttraining's rmse: 0.0735922\tvalid_1's rmse: 0.180504\n",
      "[17700]\ttraining's rmse: 0.0732885\tvalid_1's rmse: 0.180492\n",
      "[17800]\ttraining's rmse: 0.0729865\tvalid_1's rmse: 0.180487\n",
      "[17900]\ttraining's rmse: 0.0726867\tvalid_1's rmse: 0.180483\n",
      "[18000]\ttraining's rmse: 0.0723843\tvalid_1's rmse: 0.180481\n",
      "[18100]\ttraining's rmse: 0.0720916\tvalid_1's rmse: 0.180471\n",
      "[18200]\ttraining's rmse: 0.0717944\tvalid_1's rmse: 0.180472\n",
      "Early stopping, best iteration is:\n",
      "[18136]\ttraining's rmse: 0.0719864\tvalid_1's rmse: 0.180469\n",
      "2 77.1473331113 200.202173976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 4\n",
      "60.0417278383\n",
      "175.392258539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:11<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356827\tvalid_1's rmse: 0.354964\n",
      "[200]\ttraining's rmse: 0.258875\tvalid_1's rmse: 0.259867\n",
      "[300]\ttraining's rmse: 0.226326\tvalid_1's rmse: 0.229568\n",
      "[400]\ttraining's rmse: 0.211483\tvalid_1's rmse: 0.216576\n",
      "[500]\ttraining's rmse: 0.202434\tvalid_1's rmse: 0.209355\n",
      "[600]\ttraining's rmse: 0.195895\tvalid_1's rmse: 0.204567\n",
      "[700]\ttraining's rmse: 0.190764\tvalid_1's rmse: 0.201012\n",
      "[800]\ttraining's rmse: 0.186611\tvalid_1's rmse: 0.198382\n",
      "[900]\ttraining's rmse: 0.183061\tvalid_1's rmse: 0.196331\n",
      "[1000]\ttraining's rmse: 0.18\tvalid_1's rmse: 0.194711\n",
      "[1100]\ttraining's rmse: 0.177291\tvalid_1's rmse: 0.193416\n",
      "[1200]\ttraining's rmse: 0.174861\tvalid_1's rmse: 0.192347\n",
      "[1300]\ttraining's rmse: 0.172661\tvalid_1's rmse: 0.191511\n",
      "[1400]\ttraining's rmse: 0.170649\tvalid_1's rmse: 0.190793\n",
      "[1500]\ttraining's rmse: 0.168775\tvalid_1's rmse: 0.190224\n",
      "[1600]\ttraining's rmse: 0.167009\tvalid_1's rmse: 0.189645\n",
      "[1700]\ttraining's rmse: 0.165373\tvalid_1's rmse: 0.189153\n",
      "[1800]\ttraining's rmse: 0.163853\tvalid_1's rmse: 0.18873\n",
      "[1900]\ttraining's rmse: 0.162351\tvalid_1's rmse: 0.188347\n",
      "[2000]\ttraining's rmse: 0.160912\tvalid_1's rmse: 0.187993\n",
      "[2100]\ttraining's rmse: 0.159523\tvalid_1's rmse: 0.187682\n",
      "[2200]\ttraining's rmse: 0.158186\tvalid_1's rmse: 0.187369\n",
      "[2300]\ttraining's rmse: 0.156899\tvalid_1's rmse: 0.187082\n",
      "[2400]\ttraining's rmse: 0.155658\tvalid_1's rmse: 0.186834\n",
      "[2500]\ttraining's rmse: 0.154462\tvalid_1's rmse: 0.18659\n",
      "[2600]\ttraining's rmse: 0.153328\tvalid_1's rmse: 0.186402\n",
      "[2700]\ttraining's rmse: 0.152207\tvalid_1's rmse: 0.186182\n",
      "[2800]\ttraining's rmse: 0.151141\tvalid_1's rmse: 0.186039\n",
      "[2900]\ttraining's rmse: 0.150082\tvalid_1's rmse: 0.185868\n",
      "[3000]\ttraining's rmse: 0.149047\tvalid_1's rmse: 0.18571\n",
      "[3100]\ttraining's rmse: 0.148018\tvalid_1's rmse: 0.18556\n",
      "[3200]\ttraining's rmse: 0.147037\tvalid_1's rmse: 0.185408\n",
      "[3300]\ttraining's rmse: 0.146051\tvalid_1's rmse: 0.185259\n",
      "[3400]\ttraining's rmse: 0.145097\tvalid_1's rmse: 0.185131\n",
      "[3500]\ttraining's rmse: 0.144152\tvalid_1's rmse: 0.185006\n",
      "[3600]\ttraining's rmse: 0.143228\tvalid_1's rmse: 0.184887\n",
      "[3700]\ttraining's rmse: 0.142326\tvalid_1's rmse: 0.18478\n",
      "[3800]\ttraining's rmse: 0.141403\tvalid_1's rmse: 0.184647\n",
      "[3900]\ttraining's rmse: 0.140525\tvalid_1's rmse: 0.184545\n",
      "[4000]\ttraining's rmse: 0.139621\tvalid_1's rmse: 0.184417\n",
      "[4100]\ttraining's rmse: 0.138723\tvalid_1's rmse: 0.184319\n",
      "[4200]\ttraining's rmse: 0.137869\tvalid_1's rmse: 0.184219\n",
      "[4300]\ttraining's rmse: 0.137028\tvalid_1's rmse: 0.184114\n",
      "[4400]\ttraining's rmse: 0.136207\tvalid_1's rmse: 0.184041\n",
      "[4500]\ttraining's rmse: 0.135361\tvalid_1's rmse: 0.183953\n",
      "[4600]\ttraining's rmse: 0.134559\tvalid_1's rmse: 0.183866\n",
      "[4700]\ttraining's rmse: 0.133754\tvalid_1's rmse: 0.183794\n",
      "[4800]\ttraining's rmse: 0.132952\tvalid_1's rmse: 0.183685\n",
      "[4900]\ttraining's rmse: 0.132161\tvalid_1's rmse: 0.183611\n",
      "[5000]\ttraining's rmse: 0.131385\tvalid_1's rmse: 0.18354\n",
      "[5100]\ttraining's rmse: 0.130644\tvalid_1's rmse: 0.183481\n",
      "[5200]\ttraining's rmse: 0.12991\tvalid_1's rmse: 0.183422\n",
      "[5300]\ttraining's rmse: 0.129167\tvalid_1's rmse: 0.18337\n",
      "[5400]\ttraining's rmse: 0.128422\tvalid_1's rmse: 0.183294\n",
      "[5500]\ttraining's rmse: 0.127685\tvalid_1's rmse: 0.18323\n",
      "[5600]\ttraining's rmse: 0.126962\tvalid_1's rmse: 0.183159\n",
      "[5700]\ttraining's rmse: 0.126249\tvalid_1's rmse: 0.183106\n",
      "[5800]\ttraining's rmse: 0.125571\tvalid_1's rmse: 0.183062\n",
      "[5900]\ttraining's rmse: 0.124871\tvalid_1's rmse: 0.183004\n",
      "[6000]\ttraining's rmse: 0.124179\tvalid_1's rmse: 0.182931\n",
      "[6100]\ttraining's rmse: 0.123494\tvalid_1's rmse: 0.182878\n",
      "[6200]\ttraining's rmse: 0.122827\tvalid_1's rmse: 0.182818\n",
      "[6300]\ttraining's rmse: 0.122153\tvalid_1's rmse: 0.182771\n",
      "[6400]\ttraining's rmse: 0.121469\tvalid_1's rmse: 0.182721\n",
      "[6500]\ttraining's rmse: 0.120827\tvalid_1's rmse: 0.182664\n",
      "[6600]\ttraining's rmse: 0.120156\tvalid_1's rmse: 0.182611\n",
      "[6700]\ttraining's rmse: 0.119527\tvalid_1's rmse: 0.182571\n",
      "[6800]\ttraining's rmse: 0.118883\tvalid_1's rmse: 0.18253\n",
      "[6900]\ttraining's rmse: 0.118259\tvalid_1's rmse: 0.182478\n",
      "[7000]\ttraining's rmse: 0.11764\tvalid_1's rmse: 0.182451\n",
      "[7100]\ttraining's rmse: 0.117022\tvalid_1's rmse: 0.182418\n",
      "[7200]\ttraining's rmse: 0.116423\tvalid_1's rmse: 0.182383\n",
      "[7300]\ttraining's rmse: 0.115839\tvalid_1's rmse: 0.182359\n",
      "[7400]\ttraining's rmse: 0.115249\tvalid_1's rmse: 0.182321\n",
      "[7500]\ttraining's rmse: 0.114666\tvalid_1's rmse: 0.182288\n",
      "[7600]\ttraining's rmse: 0.114067\tvalid_1's rmse: 0.182247\n",
      "[7700]\ttraining's rmse: 0.113495\tvalid_1's rmse: 0.182225\n",
      "[7800]\ttraining's rmse: 0.112928\tvalid_1's rmse: 0.182191\n",
      "[7900]\ttraining's rmse: 0.11237\tvalid_1's rmse: 0.182158\n",
      "[8000]\ttraining's rmse: 0.111821\tvalid_1's rmse: 0.182132\n",
      "[8100]\ttraining's rmse: 0.111245\tvalid_1's rmse: 0.182093\n",
      "[8200]\ttraining's rmse: 0.11072\tvalid_1's rmse: 0.182069\n",
      "[8300]\ttraining's rmse: 0.110171\tvalid_1's rmse: 0.182034\n",
      "[8400]\ttraining's rmse: 0.109626\tvalid_1's rmse: 0.182012\n",
      "[8500]\ttraining's rmse: 0.109086\tvalid_1's rmse: 0.18199\n",
      "[8600]\ttraining's rmse: 0.108565\tvalid_1's rmse: 0.181969\n",
      "[8700]\ttraining's rmse: 0.108053\tvalid_1's rmse: 0.18194\n",
      "[8800]\ttraining's rmse: 0.107528\tvalid_1's rmse: 0.181919\n",
      "[8900]\ttraining's rmse: 0.107\tvalid_1's rmse: 0.181902\n",
      "[9000]\ttraining's rmse: 0.106481\tvalid_1's rmse: 0.18188\n",
      "[9100]\ttraining's rmse: 0.105969\tvalid_1's rmse: 0.181857\n",
      "[9200]\ttraining's rmse: 0.105469\tvalid_1's rmse: 0.181837\n",
      "[9300]\ttraining's rmse: 0.104959\tvalid_1's rmse: 0.181815\n",
      "[9400]\ttraining's rmse: 0.104441\tvalid_1's rmse: 0.181779\n",
      "[9500]\ttraining's rmse: 0.103944\tvalid_1's rmse: 0.18176\n",
      "[9600]\ttraining's rmse: 0.103446\tvalid_1's rmse: 0.181737\n",
      "[9700]\ttraining's rmse: 0.102953\tvalid_1's rmse: 0.181725\n",
      "[9800]\ttraining's rmse: 0.102469\tvalid_1's rmse: 0.18171\n",
      "[9900]\ttraining's rmse: 0.101985\tvalid_1's rmse: 0.181685\n",
      "[10000]\ttraining's rmse: 0.101502\tvalid_1's rmse: 0.181657\n",
      "[10100]\ttraining's rmse: 0.101024\tvalid_1's rmse: 0.181647\n",
      "[10200]\ttraining's rmse: 0.100549\tvalid_1's rmse: 0.181627\n",
      "[10300]\ttraining's rmse: 0.100084\tvalid_1's rmse: 0.181614\n",
      "[10400]\ttraining's rmse: 0.0996267\tvalid_1's rmse: 0.181595\n",
      "[10500]\ttraining's rmse: 0.0991565\tvalid_1's rmse: 0.181583\n",
      "[10600]\ttraining's rmse: 0.098701\tvalid_1's rmse: 0.181569\n",
      "[10700]\ttraining's rmse: 0.0982225\tvalid_1's rmse: 0.18154\n",
      "[10800]\ttraining's rmse: 0.0977753\tvalid_1's rmse: 0.181524\n",
      "[10900]\ttraining's rmse: 0.0973153\tvalid_1's rmse: 0.181502\n",
      "[11000]\ttraining's rmse: 0.0968823\tvalid_1's rmse: 0.181489\n",
      "[11100]\ttraining's rmse: 0.0964296\tvalid_1's rmse: 0.181477\n",
      "[11200]\ttraining's rmse: 0.0960078\tvalid_1's rmse: 0.181458\n",
      "[11300]\ttraining's rmse: 0.0955752\tvalid_1's rmse: 0.181446\n",
      "[11400]\ttraining's rmse: 0.0951512\tvalid_1's rmse: 0.18144\n",
      "[11500]\ttraining's rmse: 0.0947252\tvalid_1's rmse: 0.181438\n",
      "[11600]\ttraining's rmse: 0.0942891\tvalid_1's rmse: 0.181429\n",
      "[11700]\ttraining's rmse: 0.0938768\tvalid_1's rmse: 0.181415\n",
      "[11800]\ttraining's rmse: 0.0934651\tvalid_1's rmse: 0.181406\n",
      "[11900]\ttraining's rmse: 0.0930288\tvalid_1's rmse: 0.181396\n",
      "[12000]\ttraining's rmse: 0.0926048\tvalid_1's rmse: 0.18138\n",
      "[12100]\ttraining's rmse: 0.0921961\tvalid_1's rmse: 0.181366\n",
      "[12200]\ttraining's rmse: 0.0917787\tvalid_1's rmse: 0.181358\n",
      "[12300]\ttraining's rmse: 0.0913698\tvalid_1's rmse: 0.181346\n",
      "[12400]\ttraining's rmse: 0.0909467\tvalid_1's rmse: 0.181338\n",
      "[12500]\ttraining's rmse: 0.0905421\tvalid_1's rmse: 0.181319\n",
      "[12600]\ttraining's rmse: 0.0901393\tvalid_1's rmse: 0.181307\n",
      "[12700]\ttraining's rmse: 0.0897358\tvalid_1's rmse: 0.181292\n",
      "[12800]\ttraining's rmse: 0.0893438\tvalid_1's rmse: 0.181287\n",
      "[12900]\ttraining's rmse: 0.0889628\tvalid_1's rmse: 0.181278\n",
      "[13000]\ttraining's rmse: 0.0885679\tvalid_1's rmse: 0.181258\n",
      "[13100]\ttraining's rmse: 0.0881693\tvalid_1's rmse: 0.181253\n",
      "[13200]\ttraining's rmse: 0.0877946\tvalid_1's rmse: 0.181243\n",
      "[13300]\ttraining's rmse: 0.0874107\tvalid_1's rmse: 0.181239\n",
      "[13400]\ttraining's rmse: 0.0870342\tvalid_1's rmse: 0.181223\n",
      "[13500]\ttraining's rmse: 0.086661\tvalid_1's rmse: 0.181215\n",
      "[13600]\ttraining's rmse: 0.0862766\tvalid_1's rmse: 0.181206\n",
      "[13700]\ttraining's rmse: 0.0859079\tvalid_1's rmse: 0.181195\n",
      "[13800]\ttraining's rmse: 0.0855273\tvalid_1's rmse: 0.181188\n",
      "[13900]\ttraining's rmse: 0.0851622\tvalid_1's rmse: 0.181174\n",
      "[14000]\ttraining's rmse: 0.0847887\tvalid_1's rmse: 0.181165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14100]\ttraining's rmse: 0.0844212\tvalid_1's rmse: 0.181148\n",
      "[14200]\ttraining's rmse: 0.0840622\tvalid_1's rmse: 0.181137\n",
      "[14300]\ttraining's rmse: 0.0837019\tvalid_1's rmse: 0.181122\n",
      "[14400]\ttraining's rmse: 0.0833398\tvalid_1's rmse: 0.181111\n",
      "[14500]\ttraining's rmse: 0.0829884\tvalid_1's rmse: 0.181108\n",
      "[14600]\ttraining's rmse: 0.0826359\tvalid_1's rmse: 0.181095\n",
      "[14700]\ttraining's rmse: 0.0822869\tvalid_1's rmse: 0.181082\n",
      "[14800]\ttraining's rmse: 0.081949\tvalid_1's rmse: 0.181073\n",
      "[14900]\ttraining's rmse: 0.0816067\tvalid_1's rmse: 0.181064\n",
      "[15000]\ttraining's rmse: 0.0812473\tvalid_1's rmse: 0.181056\n",
      "[15100]\ttraining's rmse: 0.0809012\tvalid_1's rmse: 0.181046\n",
      "[15200]\ttraining's rmse: 0.0805514\tvalid_1's rmse: 0.181041\n",
      "[15300]\ttraining's rmse: 0.0802047\tvalid_1's rmse: 0.181035\n",
      "[15400]\ttraining's rmse: 0.0798637\tvalid_1's rmse: 0.181034\n",
      "[15500]\ttraining's rmse: 0.0795292\tvalid_1's rmse: 0.181021\n",
      "[15600]\ttraining's rmse: 0.0791994\tvalid_1's rmse: 0.181017\n",
      "[15700]\ttraining's rmse: 0.078865\tvalid_1's rmse: 0.181006\n",
      "[15800]\ttraining's rmse: 0.0785349\tvalid_1's rmse: 0.180997\n",
      "[15900]\ttraining's rmse: 0.0781974\tvalid_1's rmse: 0.180986\n",
      "[16000]\ttraining's rmse: 0.0778693\tvalid_1's rmse: 0.180975\n",
      "[16100]\ttraining's rmse: 0.0775354\tvalid_1's rmse: 0.180958\n",
      "[16200]\ttraining's rmse: 0.0772225\tvalid_1's rmse: 0.180957\n",
      "[16300]\ttraining's rmse: 0.07689\tvalid_1's rmse: 0.180948\n",
      "[16400]\ttraining's rmse: 0.0765745\tvalid_1's rmse: 0.18094\n",
      "[16500]\ttraining's rmse: 0.0762567\tvalid_1's rmse: 0.180931\n",
      "[16600]\ttraining's rmse: 0.0759296\tvalid_1's rmse: 0.180929\n",
      "[16700]\ttraining's rmse: 0.0756051\tvalid_1's rmse: 0.180919\n",
      "[16800]\ttraining's rmse: 0.0752972\tvalid_1's rmse: 0.180911\n",
      "[16900]\ttraining's rmse: 0.0749957\tvalid_1's rmse: 0.180903\n",
      "[17000]\ttraining's rmse: 0.0746811\tvalid_1's rmse: 0.180899\n",
      "[17100]\ttraining's rmse: 0.0743819\tvalid_1's rmse: 0.180888\n",
      "[17200]\ttraining's rmse: 0.0740881\tvalid_1's rmse: 0.180882\n",
      "[17300]\ttraining's rmse: 0.0737827\tvalid_1's rmse: 0.180876\n",
      "[17400]\ttraining's rmse: 0.0734793\tvalid_1's rmse: 0.180873\n",
      "[17500]\ttraining's rmse: 0.0731764\tvalid_1's rmse: 0.180869\n",
      "[17600]\ttraining's rmse: 0.0728829\tvalid_1's rmse: 0.180861\n",
      "[17700]\ttraining's rmse: 0.072573\tvalid_1's rmse: 0.180854\n",
      "[17800]\ttraining's rmse: 0.0722724\tvalid_1's rmse: 0.180848\n",
      "[17900]\ttraining's rmse: 0.071977\tvalid_1's rmse: 0.18084\n",
      "[18000]\ttraining's rmse: 0.0716816\tvalid_1's rmse: 0.180835\n",
      "[18100]\ttraining's rmse: 0.0713882\tvalid_1's rmse: 0.180827\n",
      "[18200]\ttraining's rmse: 0.0710973\tvalid_1's rmse: 0.18082\n",
      "[18300]\ttraining's rmse: 0.0708112\tvalid_1's rmse: 0.180811\n",
      "[18400]\ttraining's rmse: 0.0705207\tvalid_1's rmse: 0.180807\n",
      "[18500]\ttraining's rmse: 0.0702375\tvalid_1's rmse: 0.1808\n",
      "[18600]\ttraining's rmse: 0.0699531\tvalid_1's rmse: 0.180796\n",
      "[18700]\ttraining's rmse: 0.0696777\tvalid_1's rmse: 0.180793\n",
      "[18800]\ttraining's rmse: 0.0693952\tvalid_1's rmse: 0.180786\n",
      "[18900]\ttraining's rmse: 0.0691182\tvalid_1's rmse: 0.18078\n",
      "[19000]\ttraining's rmse: 0.0688213\tvalid_1's rmse: 0.180768\n",
      "[19100]\ttraining's rmse: 0.0685393\tvalid_1's rmse: 0.180762\n",
      "[19200]\ttraining's rmse: 0.0682647\tvalid_1's rmse: 0.180755\n",
      "[19300]\ttraining's rmse: 0.0679894\tvalid_1's rmse: 0.180749\n",
      "[19400]\ttraining's rmse: 0.0677138\tvalid_1's rmse: 0.180738\n",
      "[19500]\ttraining's rmse: 0.067441\tvalid_1's rmse: 0.180735\n",
      "[19600]\ttraining's rmse: 0.0671738\tvalid_1's rmse: 0.180735\n",
      "Early stopping, best iteration is:\n",
      "[19517]\ttraining's rmse: 0.0673978\tvalid_1's rmse: 0.180733\n",
      "0 86.8622917828 128.719776488\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355265\tvalid_1's rmse: 0.360181\n",
      "[200]\ttraining's rmse: 0.257846\tvalid_1's rmse: 0.26344\n",
      "[300]\ttraining's rmse: 0.225584\tvalid_1's rmse: 0.231957\n",
      "[400]\ttraining's rmse: 0.210926\tvalid_1's rmse: 0.218398\n",
      "[500]\ttraining's rmse: 0.202024\tvalid_1's rmse: 0.210817\n",
      "[600]\ttraining's rmse: 0.195551\tvalid_1's rmse: 0.205609\n",
      "[700]\ttraining's rmse: 0.190536\tvalid_1's rmse: 0.201988\n",
      "[800]\ttraining's rmse: 0.186423\tvalid_1's rmse: 0.199272\n",
      "[900]\ttraining's rmse: 0.182918\tvalid_1's rmse: 0.197131\n",
      "[1000]\ttraining's rmse: 0.179916\tvalid_1's rmse: 0.195514\n",
      "[1100]\ttraining's rmse: 0.1773\tvalid_1's rmse: 0.194214\n",
      "[1200]\ttraining's rmse: 0.174915\tvalid_1's rmse: 0.193182\n",
      "[1300]\ttraining's rmse: 0.172708\tvalid_1's rmse: 0.192298\n",
      "[1400]\ttraining's rmse: 0.170671\tvalid_1's rmse: 0.191561\n",
      "[1500]\ttraining's rmse: 0.168802\tvalid_1's rmse: 0.190924\n",
      "[1600]\ttraining's rmse: 0.167096\tvalid_1's rmse: 0.190383\n",
      "[1700]\ttraining's rmse: 0.165508\tvalid_1's rmse: 0.189935\n",
      "[1800]\ttraining's rmse: 0.163993\tvalid_1's rmse: 0.189495\n",
      "[1900]\ttraining's rmse: 0.162543\tvalid_1's rmse: 0.189138\n",
      "[2000]\ttraining's rmse: 0.161151\tvalid_1's rmse: 0.188814\n",
      "[2100]\ttraining's rmse: 0.15983\tvalid_1's rmse: 0.188513\n",
      "[2200]\ttraining's rmse: 0.158573\tvalid_1's rmse: 0.188246\n",
      "[2300]\ttraining's rmse: 0.157314\tvalid_1's rmse: 0.187976\n",
      "[2400]\ttraining's rmse: 0.15609\tvalid_1's rmse: 0.187684\n",
      "[2500]\ttraining's rmse: 0.154908\tvalid_1's rmse: 0.187447\n",
      "[2600]\ttraining's rmse: 0.153749\tvalid_1's rmse: 0.187224\n",
      "[2700]\ttraining's rmse: 0.152626\tvalid_1's rmse: 0.186993\n",
      "[2800]\ttraining's rmse: 0.151525\tvalid_1's rmse: 0.186803\n",
      "[2900]\ttraining's rmse: 0.150439\tvalid_1's rmse: 0.1866\n",
      "[3000]\ttraining's rmse: 0.149391\tvalid_1's rmse: 0.186429\n",
      "[3100]\ttraining's rmse: 0.148375\tvalid_1's rmse: 0.186265\n",
      "[3200]\ttraining's rmse: 0.147372\tvalid_1's rmse: 0.186132\n",
      "[3300]\ttraining's rmse: 0.146406\tvalid_1's rmse: 0.185983\n",
      "[3400]\ttraining's rmse: 0.145426\tvalid_1's rmse: 0.18585\n",
      "[3500]\ttraining's rmse: 0.144467\tvalid_1's rmse: 0.18572\n",
      "[3600]\ttraining's rmse: 0.143519\tvalid_1's rmse: 0.18557\n",
      "[3700]\ttraining's rmse: 0.142577\tvalid_1's rmse: 0.185438\n",
      "[3800]\ttraining's rmse: 0.141669\tvalid_1's rmse: 0.185326\n",
      "[3900]\ttraining's rmse: 0.140771\tvalid_1's rmse: 0.185218\n",
      "[4000]\ttraining's rmse: 0.139895\tvalid_1's rmse: 0.185089\n",
      "[4100]\ttraining's rmse: 0.139034\tvalid_1's rmse: 0.18499\n",
      "[4200]\ttraining's rmse: 0.138185\tvalid_1's rmse: 0.184907\n",
      "[4300]\ttraining's rmse: 0.137348\tvalid_1's rmse: 0.184804\n",
      "[4400]\ttraining's rmse: 0.136531\tvalid_1's rmse: 0.184711\n",
      "[4500]\ttraining's rmse: 0.135689\tvalid_1's rmse: 0.184609\n",
      "[4600]\ttraining's rmse: 0.134899\tvalid_1's rmse: 0.184519\n",
      "[4700]\ttraining's rmse: 0.134091\tvalid_1's rmse: 0.184437\n",
      "[4800]\ttraining's rmse: 0.133309\tvalid_1's rmse: 0.184336\n",
      "[4900]\ttraining's rmse: 0.13254\tvalid_1's rmse: 0.184247\n",
      "[5000]\ttraining's rmse: 0.131783\tvalid_1's rmse: 0.184163\n",
      "[5100]\ttraining's rmse: 0.131018\tvalid_1's rmse: 0.184075\n",
      "[5200]\ttraining's rmse: 0.130268\tvalid_1's rmse: 0.18398\n",
      "[5300]\ttraining's rmse: 0.129529\tvalid_1's rmse: 0.183918\n",
      "[5400]\ttraining's rmse: 0.128798\tvalid_1's rmse: 0.18384\n",
      "[5500]\ttraining's rmse: 0.128088\tvalid_1's rmse: 0.18376\n",
      "[5600]\ttraining's rmse: 0.12738\tvalid_1's rmse: 0.18371\n",
      "[5700]\ttraining's rmse: 0.126683\tvalid_1's rmse: 0.183643\n",
      "[5800]\ttraining's rmse: 0.125984\tvalid_1's rmse: 0.183596\n",
      "[5900]\ttraining's rmse: 0.125296\tvalid_1's rmse: 0.18354\n",
      "[6000]\ttraining's rmse: 0.124614\tvalid_1's rmse: 0.183486\n",
      "[6100]\ttraining's rmse: 0.123924\tvalid_1's rmse: 0.183447\n",
      "[6200]\ttraining's rmse: 0.123274\tvalid_1's rmse: 0.183399\n",
      "[6300]\ttraining's rmse: 0.122609\tvalid_1's rmse: 0.183338\n",
      "[6400]\ttraining's rmse: 0.121983\tvalid_1's rmse: 0.1833\n",
      "[6500]\ttraining's rmse: 0.121341\tvalid_1's rmse: 0.183241\n",
      "[6600]\ttraining's rmse: 0.120714\tvalid_1's rmse: 0.183187\n",
      "[6700]\ttraining's rmse: 0.120085\tvalid_1's rmse: 0.183151\n",
      "[6800]\ttraining's rmse: 0.119473\tvalid_1's rmse: 0.183109\n",
      "[6900]\ttraining's rmse: 0.118861\tvalid_1's rmse: 0.183057\n",
      "[7000]\ttraining's rmse: 0.118254\tvalid_1's rmse: 0.18303\n",
      "[7100]\ttraining's rmse: 0.117656\tvalid_1's rmse: 0.182983\n",
      "[7200]\ttraining's rmse: 0.117059\tvalid_1's rmse: 0.182947\n",
      "[7300]\ttraining's rmse: 0.116472\tvalid_1's rmse: 0.182916\n",
      "[7400]\ttraining's rmse: 0.1159\tvalid_1's rmse: 0.182875\n",
      "[7500]\ttraining's rmse: 0.115329\tvalid_1's rmse: 0.182836\n",
      "[7600]\ttraining's rmse: 0.114746\tvalid_1's rmse: 0.182798\n",
      "[7700]\ttraining's rmse: 0.114167\tvalid_1's rmse: 0.18277\n",
      "[7800]\ttraining's rmse: 0.113608\tvalid_1's rmse: 0.182739\n",
      "[7900]\ttraining's rmse: 0.113054\tvalid_1's rmse: 0.182697\n",
      "[8000]\ttraining's rmse: 0.112506\tvalid_1's rmse: 0.18267\n",
      "[8100]\ttraining's rmse: 0.111959\tvalid_1's rmse: 0.182639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8200]\ttraining's rmse: 0.111417\tvalid_1's rmse: 0.182609\n",
      "[8300]\ttraining's rmse: 0.110869\tvalid_1's rmse: 0.182562\n",
      "[8400]\ttraining's rmse: 0.110332\tvalid_1's rmse: 0.182532\n",
      "[8500]\ttraining's rmse: 0.109812\tvalid_1's rmse: 0.182493\n",
      "[8600]\ttraining's rmse: 0.109278\tvalid_1's rmse: 0.182461\n",
      "[8700]\ttraining's rmse: 0.108756\tvalid_1's rmse: 0.182431\n",
      "[8800]\ttraining's rmse: 0.10824\tvalid_1's rmse: 0.182404\n",
      "[8900]\ttraining's rmse: 0.10771\tvalid_1's rmse: 0.182376\n",
      "[9000]\ttraining's rmse: 0.107196\tvalid_1's rmse: 0.182353\n",
      "[9100]\ttraining's rmse: 0.10668\tvalid_1's rmse: 0.182322\n",
      "[9200]\ttraining's rmse: 0.106169\tvalid_1's rmse: 0.182298\n",
      "[9300]\ttraining's rmse: 0.105683\tvalid_1's rmse: 0.182267\n",
      "[9400]\ttraining's rmse: 0.105199\tvalid_1's rmse: 0.182241\n",
      "[9500]\ttraining's rmse: 0.104704\tvalid_1's rmse: 0.182221\n",
      "[9600]\ttraining's rmse: 0.104196\tvalid_1's rmse: 0.1822\n",
      "[9700]\ttraining's rmse: 0.103706\tvalid_1's rmse: 0.182179\n",
      "[9800]\ttraining's rmse: 0.103231\tvalid_1's rmse: 0.182157\n",
      "[9900]\ttraining's rmse: 0.102754\tvalid_1's rmse: 0.182136\n",
      "[10000]\ttraining's rmse: 0.102288\tvalid_1's rmse: 0.182106\n",
      "[10100]\ttraining's rmse: 0.101819\tvalid_1's rmse: 0.182073\n",
      "[10200]\ttraining's rmse: 0.101349\tvalid_1's rmse: 0.182049\n",
      "[10300]\ttraining's rmse: 0.10089\tvalid_1's rmse: 0.182029\n",
      "[10400]\ttraining's rmse: 0.100423\tvalid_1's rmse: 0.182012\n",
      "[10500]\ttraining's rmse: 0.099956\tvalid_1's rmse: 0.181983\n",
      "[10600]\ttraining's rmse: 0.0994849\tvalid_1's rmse: 0.181956\n",
      "[10700]\ttraining's rmse: 0.0990348\tvalid_1's rmse: 0.181939\n",
      "[10800]\ttraining's rmse: 0.0985759\tvalid_1's rmse: 0.18192\n",
      "[10900]\ttraining's rmse: 0.0981275\tvalid_1's rmse: 0.181903\n",
      "[11000]\ttraining's rmse: 0.097676\tvalid_1's rmse: 0.181884\n",
      "[11100]\ttraining's rmse: 0.0972256\tvalid_1's rmse: 0.181866\n",
      "[11200]\ttraining's rmse: 0.0967865\tvalid_1's rmse: 0.181852\n",
      "[11300]\ttraining's rmse: 0.0963397\tvalid_1's rmse: 0.181826\n",
      "[11400]\ttraining's rmse: 0.0958977\tvalid_1's rmse: 0.181802\n",
      "[11500]\ttraining's rmse: 0.095463\tvalid_1's rmse: 0.181798\n",
      "[11600]\ttraining's rmse: 0.0950255\tvalid_1's rmse: 0.181773\n",
      "[11700]\ttraining's rmse: 0.0945896\tvalid_1's rmse: 0.181756\n",
      "[11800]\ttraining's rmse: 0.0941727\tvalid_1's rmse: 0.181737\n",
      "[11900]\ttraining's rmse: 0.0937422\tvalid_1's rmse: 0.181715\n",
      "[12000]\ttraining's rmse: 0.0933215\tvalid_1's rmse: 0.181701\n",
      "[12100]\ttraining's rmse: 0.0929089\tvalid_1's rmse: 0.181678\n",
      "[12200]\ttraining's rmse: 0.0924884\tvalid_1's rmse: 0.181666\n",
      "[12300]\ttraining's rmse: 0.0920623\tvalid_1's rmse: 0.181637\n",
      "[12400]\ttraining's rmse: 0.0916513\tvalid_1's rmse: 0.181626\n",
      "[12500]\ttraining's rmse: 0.0912418\tvalid_1's rmse: 0.181603\n",
      "[12600]\ttraining's rmse: 0.0908357\tvalid_1's rmse: 0.181593\n",
      "[12700]\ttraining's rmse: 0.0904284\tvalid_1's rmse: 0.181584\n",
      "[12800]\ttraining's rmse: 0.0900241\tvalid_1's rmse: 0.181576\n",
      "[12900]\ttraining's rmse: 0.0896239\tvalid_1's rmse: 0.181561\n",
      "[13000]\ttraining's rmse: 0.0892296\tvalid_1's rmse: 0.18154\n",
      "[13100]\ttraining's rmse: 0.0888395\tvalid_1's rmse: 0.181535\n",
      "[13200]\ttraining's rmse: 0.0884484\tvalid_1's rmse: 0.181529\n",
      "[13300]\ttraining's rmse: 0.0880462\tvalid_1's rmse: 0.181522\n",
      "[13400]\ttraining's rmse: 0.0876465\tvalid_1's rmse: 0.181509\n",
      "[13500]\ttraining's rmse: 0.0872732\tvalid_1's rmse: 0.1815\n",
      "[13600]\ttraining's rmse: 0.0868902\tvalid_1's rmse: 0.181486\n",
      "[13700]\ttraining's rmse: 0.0865075\tvalid_1's rmse: 0.181479\n",
      "[13800]\ttraining's rmse: 0.0861341\tvalid_1's rmse: 0.18147\n",
      "[13900]\ttraining's rmse: 0.0857636\tvalid_1's rmse: 0.181462\n",
      "[14000]\ttraining's rmse: 0.0853894\tvalid_1's rmse: 0.181452\n",
      "[14100]\ttraining's rmse: 0.0850257\tvalid_1's rmse: 0.181439\n",
      "[14200]\ttraining's rmse: 0.0846563\tvalid_1's rmse: 0.181436\n",
      "[14300]\ttraining's rmse: 0.0842946\tvalid_1's rmse: 0.181424\n",
      "[14400]\ttraining's rmse: 0.0839404\tvalid_1's rmse: 0.181417\n",
      "[14500]\ttraining's rmse: 0.0835715\tvalid_1's rmse: 0.181403\n",
      "[14600]\ttraining's rmse: 0.0832016\tvalid_1's rmse: 0.181386\n",
      "[14700]\ttraining's rmse: 0.082839\tvalid_1's rmse: 0.181377\n",
      "[14800]\ttraining's rmse: 0.0824923\tvalid_1's rmse: 0.18137\n",
      "[14900]\ttraining's rmse: 0.0821443\tvalid_1's rmse: 0.181362\n",
      "[15000]\ttraining's rmse: 0.0817931\tvalid_1's rmse: 0.181364\n",
      "Early stopping, best iteration is:\n",
      "[14930]\ttraining's rmse: 0.0820401\tvalid_1's rmse: 0.181362\n",
      "1 75.833212165 3515.18952674\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355936\tvalid_1's rmse: 0.359505\n",
      "[200]\ttraining's rmse: 0.258412\tvalid_1's rmse: 0.263599\n",
      "[300]\ttraining's rmse: 0.226186\tvalid_1's rmse: 0.232468\n",
      "[400]\ttraining's rmse: 0.211591\tvalid_1's rmse: 0.218936\n",
      "[500]\ttraining's rmse: 0.202799\tvalid_1's rmse: 0.211248\n",
      "[600]\ttraining's rmse: 0.196475\tvalid_1's rmse: 0.205938\n",
      "[700]\ttraining's rmse: 0.191459\tvalid_1's rmse: 0.202075\n",
      "[800]\ttraining's rmse: 0.187339\tvalid_1's rmse: 0.199127\n",
      "[900]\ttraining's rmse: 0.183856\tvalid_1's rmse: 0.196873\n",
      "[1000]\ttraining's rmse: 0.180782\tvalid_1's rmse: 0.195047\n",
      "[1100]\ttraining's rmse: 0.178138\tvalid_1's rmse: 0.19368\n",
      "[1200]\ttraining's rmse: 0.175714\tvalid_1's rmse: 0.192487\n",
      "[1300]\ttraining's rmse: 0.173561\tvalid_1's rmse: 0.19157\n",
      "[1400]\ttraining's rmse: 0.171549\tvalid_1's rmse: 0.19077\n",
      "[1500]\ttraining's rmse: 0.169708\tvalid_1's rmse: 0.190129\n",
      "[1600]\ttraining's rmse: 0.167969\tvalid_1's rmse: 0.18956\n",
      "[1700]\ttraining's rmse: 0.166355\tvalid_1's rmse: 0.189036\n",
      "[1800]\ttraining's rmse: 0.164806\tvalid_1's rmse: 0.18857\n",
      "[1900]\ttraining's rmse: 0.163324\tvalid_1's rmse: 0.188127\n",
      "[2000]\ttraining's rmse: 0.161912\tvalid_1's rmse: 0.187746\n",
      "[2100]\ttraining's rmse: 0.160518\tvalid_1's rmse: 0.187398\n",
      "[2200]\ttraining's rmse: 0.159198\tvalid_1's rmse: 0.187073\n",
      "[2300]\ttraining's rmse: 0.157927\tvalid_1's rmse: 0.186794\n",
      "[2400]\ttraining's rmse: 0.156692\tvalid_1's rmse: 0.186525\n",
      "[2500]\ttraining's rmse: 0.155527\tvalid_1's rmse: 0.186321\n",
      "[2600]\ttraining's rmse: 0.15437\tvalid_1's rmse: 0.186126\n",
      "[2700]\ttraining's rmse: 0.153239\tvalid_1's rmse: 0.185937\n",
      "[2800]\ttraining's rmse: 0.152163\tvalid_1's rmse: 0.185779\n",
      "[2900]\ttraining's rmse: 0.151107\tvalid_1's rmse: 0.185604\n",
      "[3000]\ttraining's rmse: 0.150052\tvalid_1's rmse: 0.185441\n",
      "[3100]\ttraining's rmse: 0.148995\tvalid_1's rmse: 0.185267\n",
      "[3200]\ttraining's rmse: 0.14798\tvalid_1's rmse: 0.185119\n",
      "[3300]\ttraining's rmse: 0.146953\tvalid_1's rmse: 0.184947\n",
      "[3400]\ttraining's rmse: 0.145992\tvalid_1's rmse: 0.184828\n",
      "[3500]\ttraining's rmse: 0.145015\tvalid_1's rmse: 0.184684\n",
      "[3600]\ttraining's rmse: 0.14408\tvalid_1's rmse: 0.184548\n",
      "[3700]\ttraining's rmse: 0.143173\tvalid_1's rmse: 0.184434\n",
      "[3800]\ttraining's rmse: 0.142263\tvalid_1's rmse: 0.184321\n",
      "[3900]\ttraining's rmse: 0.141373\tvalid_1's rmse: 0.184215\n",
      "[4000]\ttraining's rmse: 0.140494\tvalid_1's rmse: 0.184123\n",
      "[4100]\ttraining's rmse: 0.139634\tvalid_1's rmse: 0.184036\n",
      "[4200]\ttraining's rmse: 0.138775\tvalid_1's rmse: 0.18392\n",
      "[4300]\ttraining's rmse: 0.137926\tvalid_1's rmse: 0.183838\n",
      "[4400]\ttraining's rmse: 0.137104\tvalid_1's rmse: 0.183745\n",
      "[4500]\ttraining's rmse: 0.136302\tvalid_1's rmse: 0.183669\n",
      "[4600]\ttraining's rmse: 0.135505\tvalid_1's rmse: 0.183592\n",
      "[4700]\ttraining's rmse: 0.134711\tvalid_1's rmse: 0.183536\n",
      "[4800]\ttraining's rmse: 0.133943\tvalid_1's rmse: 0.183488\n",
      "[4900]\ttraining's rmse: 0.133181\tvalid_1's rmse: 0.18342\n",
      "[5000]\ttraining's rmse: 0.132431\tvalid_1's rmse: 0.183359\n",
      "[5100]\ttraining's rmse: 0.131696\tvalid_1's rmse: 0.183294\n",
      "[5200]\ttraining's rmse: 0.130944\tvalid_1's rmse: 0.183234\n",
      "[5300]\ttraining's rmse: 0.1302\tvalid_1's rmse: 0.183174\n",
      "[5400]\ttraining's rmse: 0.129488\tvalid_1's rmse: 0.183102\n",
      "[5500]\ttraining's rmse: 0.128773\tvalid_1's rmse: 0.183038\n",
      "[5600]\ttraining's rmse: 0.128069\tvalid_1's rmse: 0.182967\n",
      "[5700]\ttraining's rmse: 0.127359\tvalid_1's rmse: 0.182923\n",
      "[5800]\ttraining's rmse: 0.12667\tvalid_1's rmse: 0.182884\n",
      "[5900]\ttraining's rmse: 0.125992\tvalid_1's rmse: 0.18285\n",
      "[6000]\ttraining's rmse: 0.125312\tvalid_1's rmse: 0.18279\n",
      "[6100]\ttraining's rmse: 0.124647\tvalid_1's rmse: 0.182745\n",
      "[6200]\ttraining's rmse: 0.123998\tvalid_1's rmse: 0.182708\n",
      "[6300]\ttraining's rmse: 0.123327\tvalid_1's rmse: 0.182668\n",
      "[6400]\ttraining's rmse: 0.122672\tvalid_1's rmse: 0.182628\n",
      "[6500]\ttraining's rmse: 0.122026\tvalid_1's rmse: 0.182583\n",
      "[6600]\ttraining's rmse: 0.121381\tvalid_1's rmse: 0.182539\n",
      "[6700]\ttraining's rmse: 0.120759\tvalid_1's rmse: 0.182503\n",
      "[6800]\ttraining's rmse: 0.120113\tvalid_1's rmse: 0.182461\n",
      "[6900]\ttraining's rmse: 0.119489\tvalid_1's rmse: 0.182419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7000]\ttraining's rmse: 0.118855\tvalid_1's rmse: 0.182384\n",
      "[7100]\ttraining's rmse: 0.118238\tvalid_1's rmse: 0.182342\n",
      "[7200]\ttraining's rmse: 0.117622\tvalid_1's rmse: 0.182311\n",
      "[7300]\ttraining's rmse: 0.117027\tvalid_1's rmse: 0.182269\n",
      "[7400]\ttraining's rmse: 0.116423\tvalid_1's rmse: 0.182238\n",
      "[7500]\ttraining's rmse: 0.115857\tvalid_1's rmse: 0.182205\n",
      "[7600]\ttraining's rmse: 0.115253\tvalid_1's rmse: 0.182169\n",
      "[7700]\ttraining's rmse: 0.114677\tvalid_1's rmse: 0.18213\n",
      "[7800]\ttraining's rmse: 0.114092\tvalid_1's rmse: 0.182116\n",
      "[7900]\ttraining's rmse: 0.113517\tvalid_1's rmse: 0.182077\n",
      "[8000]\ttraining's rmse: 0.112971\tvalid_1's rmse: 0.182049\n",
      "[8100]\ttraining's rmse: 0.112414\tvalid_1's rmse: 0.182018\n",
      "[8200]\ttraining's rmse: 0.111872\tvalid_1's rmse: 0.181984\n",
      "[8300]\ttraining's rmse: 0.111332\tvalid_1's rmse: 0.181967\n",
      "[8400]\ttraining's rmse: 0.110783\tvalid_1's rmse: 0.181934\n",
      "[8500]\ttraining's rmse: 0.11025\tvalid_1's rmse: 0.181914\n",
      "[8600]\ttraining's rmse: 0.109704\tvalid_1's rmse: 0.181888\n",
      "[8700]\ttraining's rmse: 0.10917\tvalid_1's rmse: 0.181855\n",
      "[8800]\ttraining's rmse: 0.108655\tvalid_1's rmse: 0.181835\n",
      "[8900]\ttraining's rmse: 0.108133\tvalid_1's rmse: 0.181814\n",
      "[9000]\ttraining's rmse: 0.107591\tvalid_1's rmse: 0.181779\n",
      "[9100]\ttraining's rmse: 0.107093\tvalid_1's rmse: 0.181759\n",
      "[9200]\ttraining's rmse: 0.106561\tvalid_1's rmse: 0.181729\n",
      "[9300]\ttraining's rmse: 0.106048\tvalid_1's rmse: 0.181706\n",
      "[9400]\ttraining's rmse: 0.105545\tvalid_1's rmse: 0.181681\n",
      "[9500]\ttraining's rmse: 0.105035\tvalid_1's rmse: 0.181648\n",
      "[9600]\ttraining's rmse: 0.104529\tvalid_1's rmse: 0.181621\n",
      "[9700]\ttraining's rmse: 0.104029\tvalid_1's rmse: 0.181598\n",
      "[9800]\ttraining's rmse: 0.103544\tvalid_1's rmse: 0.181574\n",
      "[9900]\ttraining's rmse: 0.103063\tvalid_1's rmse: 0.181552\n",
      "[10000]\ttraining's rmse: 0.102574\tvalid_1's rmse: 0.18152\n",
      "[10100]\ttraining's rmse: 0.102091\tvalid_1's rmse: 0.181502\n",
      "[10200]\ttraining's rmse: 0.101615\tvalid_1's rmse: 0.18148\n",
      "[10300]\ttraining's rmse: 0.101139\tvalid_1's rmse: 0.181456\n",
      "[10400]\ttraining's rmse: 0.100668\tvalid_1's rmse: 0.181441\n",
      "[10500]\ttraining's rmse: 0.100203\tvalid_1's rmse: 0.181419\n",
      "[10600]\ttraining's rmse: 0.0997431\tvalid_1's rmse: 0.181401\n",
      "[10700]\ttraining's rmse: 0.0992718\tvalid_1's rmse: 0.181383\n",
      "[10800]\ttraining's rmse: 0.0988214\tvalid_1's rmse: 0.181379\n",
      "[10900]\ttraining's rmse: 0.0983862\tvalid_1's rmse: 0.181368\n",
      "[11000]\ttraining's rmse: 0.0979327\tvalid_1's rmse: 0.181342\n",
      "[11100]\ttraining's rmse: 0.0974945\tvalid_1's rmse: 0.181329\n",
      "[11200]\ttraining's rmse: 0.0970449\tvalid_1's rmse: 0.181306\n",
      "[11300]\ttraining's rmse: 0.0966094\tvalid_1's rmse: 0.18129\n",
      "[11400]\ttraining's rmse: 0.096179\tvalid_1's rmse: 0.181272\n",
      "[11500]\ttraining's rmse: 0.0957521\tvalid_1's rmse: 0.18126\n",
      "[11600]\ttraining's rmse: 0.0953208\tvalid_1's rmse: 0.18125\n",
      "[11700]\ttraining's rmse: 0.094889\tvalid_1's rmse: 0.181225\n",
      "[11800]\ttraining's rmse: 0.0944615\tvalid_1's rmse: 0.181212\n",
      "[11900]\ttraining's rmse: 0.0940419\tvalid_1's rmse: 0.1812\n",
      "[12000]\ttraining's rmse: 0.0936264\tvalid_1's rmse: 0.181189\n",
      "[12100]\ttraining's rmse: 0.0932004\tvalid_1's rmse: 0.181171\n",
      "[12200]\ttraining's rmse: 0.0927837\tvalid_1's rmse: 0.181152\n",
      "[12300]\ttraining's rmse: 0.0923528\tvalid_1's rmse: 0.181147\n",
      "[12400]\ttraining's rmse: 0.091948\tvalid_1's rmse: 0.181128\n",
      "[12500]\ttraining's rmse: 0.0915455\tvalid_1's rmse: 0.181117\n",
      "[12600]\ttraining's rmse: 0.0911526\tvalid_1's rmse: 0.181102\n",
      "[12700]\ttraining's rmse: 0.0907522\tvalid_1's rmse: 0.181089\n",
      "[12800]\ttraining's rmse: 0.0903528\tvalid_1's rmse: 0.181079\n",
      "[12900]\ttraining's rmse: 0.089953\tvalid_1's rmse: 0.181062\n",
      "[13000]\ttraining's rmse: 0.0895426\tvalid_1's rmse: 0.181039\n",
      "[13100]\ttraining's rmse: 0.0891446\tvalid_1's rmse: 0.181023\n",
      "[13200]\ttraining's rmse: 0.0887578\tvalid_1's rmse: 0.181015\n",
      "[13300]\ttraining's rmse: 0.0883677\tvalid_1's rmse: 0.180997\n",
      "[13400]\ttraining's rmse: 0.0879799\tvalid_1's rmse: 0.180986\n",
      "[13500]\ttraining's rmse: 0.0875971\tvalid_1's rmse: 0.180974\n",
      "[13600]\ttraining's rmse: 0.0872258\tvalid_1's rmse: 0.180953\n",
      "[13700]\ttraining's rmse: 0.0868553\tvalid_1's rmse: 0.18094\n",
      "[13800]\ttraining's rmse: 0.0864757\tvalid_1's rmse: 0.180925\n",
      "[13900]\ttraining's rmse: 0.0861091\tvalid_1's rmse: 0.1809\n",
      "[14000]\ttraining's rmse: 0.0857343\tvalid_1's rmse: 0.180875\n",
      "[14100]\ttraining's rmse: 0.0853547\tvalid_1's rmse: 0.180862\n",
      "[14200]\ttraining's rmse: 0.0849868\tvalid_1's rmse: 0.180853\n",
      "[14300]\ttraining's rmse: 0.0846205\tvalid_1's rmse: 0.180833\n",
      "[14400]\ttraining's rmse: 0.0842637\tvalid_1's rmse: 0.180816\n",
      "[14500]\ttraining's rmse: 0.0839035\tvalid_1's rmse: 0.180809\n",
      "[14600]\ttraining's rmse: 0.0835439\tvalid_1's rmse: 0.180806\n",
      "[14700]\ttraining's rmse: 0.0831932\tvalid_1's rmse: 0.180798\n",
      "[14800]\ttraining's rmse: 0.0828407\tvalid_1's rmse: 0.180781\n",
      "[14900]\ttraining's rmse: 0.0824837\tvalid_1's rmse: 0.180766\n",
      "[15000]\ttraining's rmse: 0.0821286\tvalid_1's rmse: 0.180749\n",
      "[15100]\ttraining's rmse: 0.0817686\tvalid_1's rmse: 0.180734\n",
      "[15200]\ttraining's rmse: 0.0814082\tvalid_1's rmse: 0.180725\n",
      "[15300]\ttraining's rmse: 0.0810665\tvalid_1's rmse: 0.180719\n",
      "[15400]\ttraining's rmse: 0.0807118\tvalid_1's rmse: 0.180714\n",
      "[15500]\ttraining's rmse: 0.0803727\tvalid_1's rmse: 0.180711\n",
      "[15600]\ttraining's rmse: 0.0800295\tvalid_1's rmse: 0.180706\n",
      "[15700]\ttraining's rmse: 0.0796935\tvalid_1's rmse: 0.180702\n",
      "[15800]\ttraining's rmse: 0.0793637\tvalid_1's rmse: 0.18069\n",
      "[15900]\ttraining's rmse: 0.0790315\tvalid_1's rmse: 0.180678\n",
      "[16000]\ttraining's rmse: 0.0787094\tvalid_1's rmse: 0.180672\n",
      "[16100]\ttraining's rmse: 0.0783815\tvalid_1's rmse: 0.180667\n",
      "[16200]\ttraining's rmse: 0.0780347\tvalid_1's rmse: 0.180651\n",
      "[16300]\ttraining's rmse: 0.0777164\tvalid_1's rmse: 0.180646\n",
      "[16400]\ttraining's rmse: 0.0773923\tvalid_1's rmse: 0.180632\n",
      "[16500]\ttraining's rmse: 0.077063\tvalid_1's rmse: 0.180624\n",
      "[16600]\ttraining's rmse: 0.0767443\tvalid_1's rmse: 0.180619\n",
      "[16700]\ttraining's rmse: 0.0764283\tvalid_1's rmse: 0.180612\n",
      "[16800]\ttraining's rmse: 0.0761031\tvalid_1's rmse: 0.18061\n",
      "[16900]\ttraining's rmse: 0.0757769\tvalid_1's rmse: 0.180605\n",
      "[17000]\ttraining's rmse: 0.075454\tvalid_1's rmse: 0.180589\n",
      "[17100]\ttraining's rmse: 0.0751475\tvalid_1's rmse: 0.180586\n",
      "[17200]\ttraining's rmse: 0.0748376\tvalid_1's rmse: 0.180577\n",
      "[17300]\ttraining's rmse: 0.0745249\tvalid_1's rmse: 0.180574\n",
      "[17400]\ttraining's rmse: 0.074214\tvalid_1's rmse: 0.18057\n",
      "[17500]\ttraining's rmse: 0.0739137\tvalid_1's rmse: 0.180564\n",
      "[17600]\ttraining's rmse: 0.0736137\tvalid_1's rmse: 0.180562\n",
      "[17700]\ttraining's rmse: 0.0733194\tvalid_1's rmse: 0.180558\n",
      "[17800]\ttraining's rmse: 0.0730211\tvalid_1's rmse: 0.180553\n",
      "[17900]\ttraining's rmse: 0.0727188\tvalid_1's rmse: 0.180544\n",
      "[18000]\ttraining's rmse: 0.0724269\tvalid_1's rmse: 0.180537\n",
      "[18100]\ttraining's rmse: 0.0721274\tvalid_1's rmse: 0.180531\n",
      "[18200]\ttraining's rmse: 0.0718249\tvalid_1's rmse: 0.180527\n",
      "[18300]\ttraining's rmse: 0.0715364\tvalid_1's rmse: 0.180521\n",
      "[18400]\ttraining's rmse: 0.0712357\tvalid_1's rmse: 0.180514\n",
      "[18500]\ttraining's rmse: 0.0709445\tvalid_1's rmse: 0.180502\n",
      "[18600]\ttraining's rmse: 0.0706565\tvalid_1's rmse: 0.180494\n",
      "[18700]\ttraining's rmse: 0.0703664\tvalid_1's rmse: 0.180486\n",
      "[18800]\ttraining's rmse: 0.070087\tvalid_1's rmse: 0.180481\n",
      "[18900]\ttraining's rmse: 0.0698131\tvalid_1's rmse: 0.180481\n",
      "[19000]\ttraining's rmse: 0.0695262\tvalid_1's rmse: 0.180476\n",
      "[19100]\ttraining's rmse: 0.0692437\tvalid_1's rmse: 0.180472\n",
      "[19200]\ttraining's rmse: 0.0689602\tvalid_1's rmse: 0.180471\n",
      "[19300]\ttraining's rmse: 0.0686908\tvalid_1's rmse: 0.18046\n",
      "[19400]\ttraining's rmse: 0.0684221\tvalid_1's rmse: 0.180451\n",
      "[19500]\ttraining's rmse: 0.0681381\tvalid_1's rmse: 0.180447\n",
      "[19600]\ttraining's rmse: 0.067868\tvalid_1's rmse: 0.180443\n",
      "[19700]\ttraining's rmse: 0.0675855\tvalid_1's rmse: 0.180441\n",
      "[19800]\ttraining's rmse: 0.0673097\tvalid_1's rmse: 0.180439\n",
      "Early stopping, best iteration is:\n",
      "[19717]\ttraining's rmse: 0.0675393\tvalid_1's rmse: 0.180437\n",
      "2 74.5449704739 167.131797521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 5\n",
      "59.9002970579\n",
      "186.845310706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:13<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356272\tvalid_1's rmse: 0.354344\n",
      "[200]\ttraining's rmse: 0.258493\tvalid_1's rmse: 0.259571\n",
      "[300]\ttraining's rmse: 0.225983\tvalid_1's rmse: 0.229462\n",
      "[400]\ttraining's rmse: 0.211071\tvalid_1's rmse: 0.21654\n",
      "[500]\ttraining's rmse: 0.202078\tvalid_1's rmse: 0.209274\n",
      "[600]\ttraining's rmse: 0.195497\tvalid_1's rmse: 0.204314\n",
      "[700]\ttraining's rmse: 0.190442\tvalid_1's rmse: 0.200909\n",
      "[800]\ttraining's rmse: 0.186271\tvalid_1's rmse: 0.198352\n",
      "[900]\ttraining's rmse: 0.182763\tvalid_1's rmse: 0.196289\n",
      "[1000]\ttraining's rmse: 0.179707\tvalid_1's rmse: 0.194683\n",
      "[1100]\ttraining's rmse: 0.176996\tvalid_1's rmse: 0.193288\n",
      "[1200]\ttraining's rmse: 0.17458\tvalid_1's rmse: 0.192212\n",
      "[1300]\ttraining's rmse: 0.172412\tvalid_1's rmse: 0.191349\n",
      "[1400]\ttraining's rmse: 0.170395\tvalid_1's rmse: 0.190607\n",
      "[1500]\ttraining's rmse: 0.168529\tvalid_1's rmse: 0.189948\n",
      "[1600]\ttraining's rmse: 0.166777\tvalid_1's rmse: 0.189428\n",
      "[1700]\ttraining's rmse: 0.165127\tvalid_1's rmse: 0.188903\n",
      "[1800]\ttraining's rmse: 0.163581\tvalid_1's rmse: 0.188494\n",
      "[1900]\ttraining's rmse: 0.162109\tvalid_1's rmse: 0.188105\n",
      "[2000]\ttraining's rmse: 0.160716\tvalid_1's rmse: 0.18774\n",
      "[2100]\ttraining's rmse: 0.15935\tvalid_1's rmse: 0.187394\n",
      "[2200]\ttraining's rmse: 0.158014\tvalid_1's rmse: 0.187097\n",
      "[2300]\ttraining's rmse: 0.156726\tvalid_1's rmse: 0.186787\n",
      "[2400]\ttraining's rmse: 0.155501\tvalid_1's rmse: 0.186511\n",
      "[2500]\ttraining's rmse: 0.154309\tvalid_1's rmse: 0.186247\n",
      "[2600]\ttraining's rmse: 0.153148\tvalid_1's rmse: 0.18603\n",
      "[2700]\ttraining's rmse: 0.152036\tvalid_1's rmse: 0.185817\n",
      "[2800]\ttraining's rmse: 0.150936\tvalid_1's rmse: 0.185609\n",
      "[2900]\ttraining's rmse: 0.149884\tvalid_1's rmse: 0.185429\n",
      "[3000]\ttraining's rmse: 0.148822\tvalid_1's rmse: 0.185253\n",
      "[3100]\ttraining's rmse: 0.147792\tvalid_1's rmse: 0.185086\n",
      "[3200]\ttraining's rmse: 0.146794\tvalid_1's rmse: 0.184931\n",
      "[3300]\ttraining's rmse: 0.145816\tvalid_1's rmse: 0.18478\n",
      "[3400]\ttraining's rmse: 0.14486\tvalid_1's rmse: 0.184647\n",
      "[3500]\ttraining's rmse: 0.143919\tvalid_1's rmse: 0.184544\n",
      "[3600]\ttraining's rmse: 0.142996\tvalid_1's rmse: 0.184421\n",
      "[3700]\ttraining's rmse: 0.142073\tvalid_1's rmse: 0.184321\n",
      "[3800]\ttraining's rmse: 0.141175\tvalid_1's rmse: 0.184205\n",
      "[3900]\ttraining's rmse: 0.140283\tvalid_1's rmse: 0.184086\n",
      "[4000]\ttraining's rmse: 0.139419\tvalid_1's rmse: 0.18396\n",
      "[4100]\ttraining's rmse: 0.138591\tvalid_1's rmse: 0.183867\n",
      "[4200]\ttraining's rmse: 0.137736\tvalid_1's rmse: 0.183767\n",
      "[4300]\ttraining's rmse: 0.136901\tvalid_1's rmse: 0.18368\n",
      "[4400]\ttraining's rmse: 0.136071\tvalid_1's rmse: 0.183604\n",
      "[4500]\ttraining's rmse: 0.135249\tvalid_1's rmse: 0.183516\n",
      "[4600]\ttraining's rmse: 0.134444\tvalid_1's rmse: 0.183407\n",
      "[4700]\ttraining's rmse: 0.133645\tvalid_1's rmse: 0.183333\n",
      "[4800]\ttraining's rmse: 0.132874\tvalid_1's rmse: 0.183246\n",
      "[4900]\ttraining's rmse: 0.132097\tvalid_1's rmse: 0.183159\n",
      "[5000]\ttraining's rmse: 0.131315\tvalid_1's rmse: 0.183069\n",
      "[5100]\ttraining's rmse: 0.130577\tvalid_1's rmse: 0.183008\n",
      "[5200]\ttraining's rmse: 0.129843\tvalid_1's rmse: 0.182937\n",
      "[5300]\ttraining's rmse: 0.129103\tvalid_1's rmse: 0.182866\n",
      "[5400]\ttraining's rmse: 0.128377\tvalid_1's rmse: 0.182823\n",
      "[5500]\ttraining's rmse: 0.127659\tvalid_1's rmse: 0.182757\n",
      "[5600]\ttraining's rmse: 0.126937\tvalid_1's rmse: 0.182686\n",
      "[5700]\ttraining's rmse: 0.126251\tvalid_1's rmse: 0.182648\n",
      "[5800]\ttraining's rmse: 0.125549\tvalid_1's rmse: 0.182591\n",
      "[5900]\ttraining's rmse: 0.124867\tvalid_1's rmse: 0.182539\n",
      "[6000]\ttraining's rmse: 0.124175\tvalid_1's rmse: 0.182481\n",
      "[6100]\ttraining's rmse: 0.123496\tvalid_1's rmse: 0.182421\n",
      "[6200]\ttraining's rmse: 0.122819\tvalid_1's rmse: 0.182382\n",
      "[6300]\ttraining's rmse: 0.122157\tvalid_1's rmse: 0.182336\n",
      "[6400]\ttraining's rmse: 0.121487\tvalid_1's rmse: 0.182282\n",
      "[6500]\ttraining's rmse: 0.120839\tvalid_1's rmse: 0.18225\n",
      "[6600]\ttraining's rmse: 0.12023\tvalid_1's rmse: 0.182225\n",
      "[6700]\ttraining's rmse: 0.119599\tvalid_1's rmse: 0.182172\n",
      "[6800]\ttraining's rmse: 0.118993\tvalid_1's rmse: 0.18214\n",
      "[6900]\ttraining's rmse: 0.118371\tvalid_1's rmse: 0.182115\n",
      "[7000]\ttraining's rmse: 0.117763\tvalid_1's rmse: 0.182074\n",
      "[7100]\ttraining's rmse: 0.117149\tvalid_1's rmse: 0.182035\n",
      "[7200]\ttraining's rmse: 0.116568\tvalid_1's rmse: 0.181999\n",
      "[7300]\ttraining's rmse: 0.115974\tvalid_1's rmse: 0.181972\n",
      "[7400]\ttraining's rmse: 0.115383\tvalid_1's rmse: 0.181941\n",
      "[7500]\ttraining's rmse: 0.114791\tvalid_1's rmse: 0.181912\n",
      "[7600]\ttraining's rmse: 0.114204\tvalid_1's rmse: 0.181886\n",
      "[7700]\ttraining's rmse: 0.113637\tvalid_1's rmse: 0.181863\n",
      "[7800]\ttraining's rmse: 0.113052\tvalid_1's rmse: 0.181828\n",
      "[7900]\ttraining's rmse: 0.112492\tvalid_1's rmse: 0.181794\n",
      "[8000]\ttraining's rmse: 0.111925\tvalid_1's rmse: 0.181765\n",
      "[8100]\ttraining's rmse: 0.111367\tvalid_1's rmse: 0.181746\n",
      "[8200]\ttraining's rmse: 0.110808\tvalid_1's rmse: 0.181712\n",
      "[8300]\ttraining's rmse: 0.110259\tvalid_1's rmse: 0.181695\n",
      "[8400]\ttraining's rmse: 0.109736\tvalid_1's rmse: 0.181665\n",
      "[8500]\ttraining's rmse: 0.109191\tvalid_1's rmse: 0.181633\n",
      "[8600]\ttraining's rmse: 0.108663\tvalid_1's rmse: 0.181605\n",
      "[8700]\ttraining's rmse: 0.108141\tvalid_1's rmse: 0.181585\n",
      "[8800]\ttraining's rmse: 0.107621\tvalid_1's rmse: 0.181567\n",
      "[8900]\ttraining's rmse: 0.107104\tvalid_1's rmse: 0.181561\n",
      "[9000]\ttraining's rmse: 0.106587\tvalid_1's rmse: 0.181544\n",
      "[9100]\ttraining's rmse: 0.106061\tvalid_1's rmse: 0.181508\n",
      "[9200]\ttraining's rmse: 0.10556\tvalid_1's rmse: 0.181484\n",
      "[9300]\ttraining's rmse: 0.105035\tvalid_1's rmse: 0.181454\n",
      "[9400]\ttraining's rmse: 0.104527\tvalid_1's rmse: 0.181439\n",
      "[9500]\ttraining's rmse: 0.104027\tvalid_1's rmse: 0.181427\n",
      "[9600]\ttraining's rmse: 0.103533\tvalid_1's rmse: 0.181406\n",
      "[9700]\ttraining's rmse: 0.103036\tvalid_1's rmse: 0.181385\n",
      "[9800]\ttraining's rmse: 0.102543\tvalid_1's rmse: 0.181369\n",
      "[9900]\ttraining's rmse: 0.102069\tvalid_1's rmse: 0.181353\n",
      "[10000]\ttraining's rmse: 0.101579\tvalid_1's rmse: 0.181334\n",
      "[10100]\ttraining's rmse: 0.101105\tvalid_1's rmse: 0.181318\n",
      "[10200]\ttraining's rmse: 0.100633\tvalid_1's rmse: 0.181295\n",
      "[10300]\ttraining's rmse: 0.100165\tvalid_1's rmse: 0.181281\n",
      "[10400]\ttraining's rmse: 0.0996914\tvalid_1's rmse: 0.181263\n",
      "[10500]\ttraining's rmse: 0.099246\tvalid_1's rmse: 0.181254\n",
      "[10600]\ttraining's rmse: 0.0987825\tvalid_1's rmse: 0.181239\n",
      "[10700]\ttraining's rmse: 0.0983425\tvalid_1's rmse: 0.181217\n",
      "[10800]\ttraining's rmse: 0.0979036\tvalid_1's rmse: 0.181206\n",
      "[10900]\ttraining's rmse: 0.0974467\tvalid_1's rmse: 0.181193\n",
      "[11000]\ttraining's rmse: 0.0970002\tvalid_1's rmse: 0.181172\n",
      "[11100]\ttraining's rmse: 0.0965695\tvalid_1's rmse: 0.18116\n",
      "[11200]\ttraining's rmse: 0.0961245\tvalid_1's rmse: 0.181146\n",
      "[11300]\ttraining's rmse: 0.0956806\tvalid_1's rmse: 0.181129\n",
      "[11400]\ttraining's rmse: 0.0952416\tvalid_1's rmse: 0.18111\n",
      "[11500]\ttraining's rmse: 0.0948226\tvalid_1's rmse: 0.181099\n",
      "[11600]\ttraining's rmse: 0.0944011\tvalid_1's rmse: 0.181089\n",
      "[11700]\ttraining's rmse: 0.0939816\tvalid_1's rmse: 0.181076\n",
      "[11800]\ttraining's rmse: 0.0935597\tvalid_1's rmse: 0.181057\n",
      "[11900]\ttraining's rmse: 0.0931376\tvalid_1's rmse: 0.181036\n",
      "[12000]\ttraining's rmse: 0.0927205\tvalid_1's rmse: 0.181033\n",
      "[12100]\ttraining's rmse: 0.0923187\tvalid_1's rmse: 0.18102\n",
      "[12200]\ttraining's rmse: 0.0919043\tvalid_1's rmse: 0.181002\n",
      "[12300]\ttraining's rmse: 0.0914965\tvalid_1's rmse: 0.18099\n",
      "[12400]\ttraining's rmse: 0.0910875\tvalid_1's rmse: 0.180985\n",
      "[12500]\ttraining's rmse: 0.0906982\tvalid_1's rmse: 0.180965\n",
      "[12600]\ttraining's rmse: 0.0903062\tvalid_1's rmse: 0.180952\n",
      "[12700]\ttraining's rmse: 0.0899059\tvalid_1's rmse: 0.180939\n",
      "[12800]\ttraining's rmse: 0.0894958\tvalid_1's rmse: 0.180931\n",
      "[12900]\ttraining's rmse: 0.0891066\tvalid_1's rmse: 0.180923\n",
      "[13000]\ttraining's rmse: 0.088721\tvalid_1's rmse: 0.18091\n",
      "[13100]\ttraining's rmse: 0.0883348\tvalid_1's rmse: 0.180906\n",
      "[13200]\ttraining's rmse: 0.0879341\tvalid_1's rmse: 0.180885\n",
      "[13300]\ttraining's rmse: 0.0875446\tvalid_1's rmse: 0.180881\n",
      "[13400]\ttraining's rmse: 0.087154\tvalid_1's rmse: 0.180872\n",
      "[13500]\ttraining's rmse: 0.0867688\tvalid_1's rmse: 0.180866\n",
      "[13600]\ttraining's rmse: 0.0863906\tvalid_1's rmse: 0.180857\n",
      "[13700]\ttraining's rmse: 0.0860145\tvalid_1's rmse: 0.180848\n",
      "[13800]\ttraining's rmse: 0.0856373\tvalid_1's rmse: 0.180844\n",
      "[13900]\ttraining's rmse: 0.0852675\tvalid_1's rmse: 0.180829\n",
      "[14000]\ttraining's rmse: 0.084895\tvalid_1's rmse: 0.180821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14100]\ttraining's rmse: 0.0845224\tvalid_1's rmse: 0.180818\n",
      "[14200]\ttraining's rmse: 0.0841548\tvalid_1's rmse: 0.180811\n",
      "Early stopping, best iteration is:\n",
      "[14166]\ttraining's rmse: 0.0842745\tvalid_1's rmse: 0.180805\n",
      "0 80.3454658941 134.716123047\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355424\tvalid_1's rmse: 0.360351\n",
      "[200]\ttraining's rmse: 0.258056\tvalid_1's rmse: 0.26344\n",
      "[300]\ttraining's rmse: 0.22605\tvalid_1's rmse: 0.232268\n",
      "[400]\ttraining's rmse: 0.2111\tvalid_1's rmse: 0.218395\n",
      "[500]\ttraining's rmse: 0.202224\tvalid_1's rmse: 0.210719\n",
      "[600]\ttraining's rmse: 0.195706\tvalid_1's rmse: 0.2055\n",
      "[700]\ttraining's rmse: 0.190614\tvalid_1's rmse: 0.20177\n",
      "[800]\ttraining's rmse: 0.186377\tvalid_1's rmse: 0.198934\n",
      "[900]\ttraining's rmse: 0.182846\tvalid_1's rmse: 0.196783\n",
      "[1000]\ttraining's rmse: 0.179796\tvalid_1's rmse: 0.195059\n",
      "[1100]\ttraining's rmse: 0.177147\tvalid_1's rmse: 0.193678\n",
      "[1200]\ttraining's rmse: 0.174755\tvalid_1's rmse: 0.192578\n",
      "[1300]\ttraining's rmse: 0.172607\tvalid_1's rmse: 0.191623\n",
      "[1400]\ttraining's rmse: 0.170644\tvalid_1's rmse: 0.190838\n",
      "[1500]\ttraining's rmse: 0.168824\tvalid_1's rmse: 0.190202\n",
      "[1600]\ttraining's rmse: 0.167115\tvalid_1's rmse: 0.189651\n",
      "[1700]\ttraining's rmse: 0.16552\tvalid_1's rmse: 0.189166\n",
      "[1800]\ttraining's rmse: 0.163999\tvalid_1's rmse: 0.188751\n",
      "[1900]\ttraining's rmse: 0.162566\tvalid_1's rmse: 0.188374\n",
      "[2000]\ttraining's rmse: 0.161191\tvalid_1's rmse: 0.188037\n",
      "[2100]\ttraining's rmse: 0.159866\tvalid_1's rmse: 0.187714\n",
      "[2200]\ttraining's rmse: 0.15863\tvalid_1's rmse: 0.187432\n",
      "[2300]\ttraining's rmse: 0.157383\tvalid_1's rmse: 0.187168\n",
      "[2400]\ttraining's rmse: 0.156176\tvalid_1's rmse: 0.186929\n",
      "[2500]\ttraining's rmse: 0.155018\tvalid_1's rmse: 0.18671\n",
      "[2600]\ttraining's rmse: 0.153896\tvalid_1's rmse: 0.186517\n",
      "[2700]\ttraining's rmse: 0.152748\tvalid_1's rmse: 0.186308\n",
      "[2800]\ttraining's rmse: 0.151669\tvalid_1's rmse: 0.186145\n",
      "[2900]\ttraining's rmse: 0.150601\tvalid_1's rmse: 0.185981\n",
      "[3000]\ttraining's rmse: 0.149567\tvalid_1's rmse: 0.185793\n",
      "[3100]\ttraining's rmse: 0.148548\tvalid_1's rmse: 0.185646\n",
      "[3200]\ttraining's rmse: 0.147546\tvalid_1's rmse: 0.185492\n",
      "[3300]\ttraining's rmse: 0.146577\tvalid_1's rmse: 0.185345\n",
      "[3400]\ttraining's rmse: 0.145624\tvalid_1's rmse: 0.185206\n",
      "[3500]\ttraining's rmse: 0.144693\tvalid_1's rmse: 0.18508\n",
      "[3600]\ttraining's rmse: 0.143783\tvalid_1's rmse: 0.184954\n",
      "[3700]\ttraining's rmse: 0.142887\tvalid_1's rmse: 0.184858\n",
      "[3800]\ttraining's rmse: 0.141988\tvalid_1's rmse: 0.184755\n",
      "[3900]\ttraining's rmse: 0.141088\tvalid_1's rmse: 0.184638\n",
      "[4000]\ttraining's rmse: 0.140233\tvalid_1's rmse: 0.184561\n",
      "[4100]\ttraining's rmse: 0.13938\tvalid_1's rmse: 0.184466\n",
      "[4200]\ttraining's rmse: 0.138534\tvalid_1's rmse: 0.184371\n",
      "[4300]\ttraining's rmse: 0.137706\tvalid_1's rmse: 0.184273\n",
      "[4400]\ttraining's rmse: 0.136882\tvalid_1's rmse: 0.184184\n",
      "[4500]\ttraining's rmse: 0.136075\tvalid_1's rmse: 0.184102\n",
      "[4600]\ttraining's rmse: 0.135279\tvalid_1's rmse: 0.18403\n",
      "[4700]\ttraining's rmse: 0.134468\tvalid_1's rmse: 0.183934\n",
      "[4800]\ttraining's rmse: 0.133688\tvalid_1's rmse: 0.183847\n",
      "[4900]\ttraining's rmse: 0.132933\tvalid_1's rmse: 0.183766\n",
      "[5000]\ttraining's rmse: 0.132181\tvalid_1's rmse: 0.183715\n",
      "[5100]\ttraining's rmse: 0.131432\tvalid_1's rmse: 0.183626\n",
      "[5200]\ttraining's rmse: 0.130672\tvalid_1's rmse: 0.183557\n",
      "[5300]\ttraining's rmse: 0.129947\tvalid_1's rmse: 0.183506\n",
      "[5400]\ttraining's rmse: 0.129234\tvalid_1's rmse: 0.183453\n",
      "[5500]\ttraining's rmse: 0.128542\tvalid_1's rmse: 0.183396\n",
      "[5600]\ttraining's rmse: 0.127817\tvalid_1's rmse: 0.183336\n",
      "[5700]\ttraining's rmse: 0.12712\tvalid_1's rmse: 0.183286\n",
      "[5800]\ttraining's rmse: 0.126426\tvalid_1's rmse: 0.183227\n",
      "[5900]\ttraining's rmse: 0.125749\tvalid_1's rmse: 0.183183\n",
      "[6000]\ttraining's rmse: 0.12507\tvalid_1's rmse: 0.183137\n",
      "[6100]\ttraining's rmse: 0.124382\tvalid_1's rmse: 0.183096\n",
      "[6200]\ttraining's rmse: 0.123721\tvalid_1's rmse: 0.183048\n",
      "[6300]\ttraining's rmse: 0.123032\tvalid_1's rmse: 0.182997\n",
      "[6400]\ttraining's rmse: 0.122381\tvalid_1's rmse: 0.182951\n",
      "[6500]\ttraining's rmse: 0.121734\tvalid_1's rmse: 0.182914\n",
      "[6600]\ttraining's rmse: 0.12109\tvalid_1's rmse: 0.182874\n",
      "[6700]\ttraining's rmse: 0.120456\tvalid_1's rmse: 0.182828\n",
      "[6800]\ttraining's rmse: 0.119824\tvalid_1's rmse: 0.182792\n",
      "[6900]\ttraining's rmse: 0.119201\tvalid_1's rmse: 0.182741\n",
      "[7000]\ttraining's rmse: 0.118583\tvalid_1's rmse: 0.182708\n",
      "[7100]\ttraining's rmse: 0.117987\tvalid_1's rmse: 0.182688\n",
      "[7200]\ttraining's rmse: 0.117359\tvalid_1's rmse: 0.18265\n",
      "[7300]\ttraining's rmse: 0.116753\tvalid_1's rmse: 0.182612\n",
      "[7400]\ttraining's rmse: 0.116164\tvalid_1's rmse: 0.18258\n",
      "[7500]\ttraining's rmse: 0.11557\tvalid_1's rmse: 0.182546\n",
      "[7600]\ttraining's rmse: 0.114961\tvalid_1's rmse: 0.182511\n",
      "[7700]\ttraining's rmse: 0.11438\tvalid_1's rmse: 0.182466\n",
      "[7800]\ttraining's rmse: 0.113799\tvalid_1's rmse: 0.182441\n",
      "[7900]\ttraining's rmse: 0.113241\tvalid_1's rmse: 0.182412\n",
      "[8000]\ttraining's rmse: 0.112679\tvalid_1's rmse: 0.182389\n",
      "[8100]\ttraining's rmse: 0.112117\tvalid_1's rmse: 0.182357\n",
      "[8200]\ttraining's rmse: 0.111572\tvalid_1's rmse: 0.182326\n",
      "[8300]\ttraining's rmse: 0.111006\tvalid_1's rmse: 0.182295\n",
      "[8400]\ttraining's rmse: 0.110467\tvalid_1's rmse: 0.182268\n",
      "[8500]\ttraining's rmse: 0.109922\tvalid_1's rmse: 0.182237\n",
      "[8600]\ttraining's rmse: 0.109364\tvalid_1's rmse: 0.182211\n",
      "[8700]\ttraining's rmse: 0.10885\tvalid_1's rmse: 0.182177\n",
      "[8800]\ttraining's rmse: 0.10832\tvalid_1's rmse: 0.182159\n",
      "[8900]\ttraining's rmse: 0.107803\tvalid_1's rmse: 0.182134\n",
      "[9000]\ttraining's rmse: 0.1073\tvalid_1's rmse: 0.182111\n",
      "[9100]\ttraining's rmse: 0.106799\tvalid_1's rmse: 0.182088\n",
      "[9200]\ttraining's rmse: 0.10629\tvalid_1's rmse: 0.18207\n",
      "[9300]\ttraining's rmse: 0.105772\tvalid_1's rmse: 0.182058\n",
      "[9400]\ttraining's rmse: 0.105276\tvalid_1's rmse: 0.182038\n",
      "[9500]\ttraining's rmse: 0.104785\tvalid_1's rmse: 0.182014\n",
      "[9600]\ttraining's rmse: 0.104278\tvalid_1's rmse: 0.181992\n",
      "[9700]\ttraining's rmse: 0.103767\tvalid_1's rmse: 0.181956\n",
      "[9800]\ttraining's rmse: 0.103262\tvalid_1's rmse: 0.181926\n",
      "[9900]\ttraining's rmse: 0.102784\tvalid_1's rmse: 0.181909\n",
      "[10000]\ttraining's rmse: 0.102293\tvalid_1's rmse: 0.181884\n",
      "[10100]\ttraining's rmse: 0.101819\tvalid_1's rmse: 0.181861\n",
      "[10200]\ttraining's rmse: 0.101345\tvalid_1's rmse: 0.181848\n",
      "[10300]\ttraining's rmse: 0.100878\tvalid_1's rmse: 0.181827\n",
      "[10400]\ttraining's rmse: 0.100428\tvalid_1's rmse: 0.181815\n",
      "[10500]\ttraining's rmse: 0.0999497\tvalid_1's rmse: 0.181801\n",
      "[10600]\ttraining's rmse: 0.0994842\tvalid_1's rmse: 0.181782\n",
      "[10700]\ttraining's rmse: 0.0990404\tvalid_1's rmse: 0.181771\n",
      "[10800]\ttraining's rmse: 0.0985813\tvalid_1's rmse: 0.181755\n",
      "[10900]\ttraining's rmse: 0.0981389\tvalid_1's rmse: 0.181732\n",
      "[11000]\ttraining's rmse: 0.097684\tvalid_1's rmse: 0.181716\n",
      "[11100]\ttraining's rmse: 0.0972292\tvalid_1's rmse: 0.181701\n",
      "[11200]\ttraining's rmse: 0.0967775\tvalid_1's rmse: 0.181683\n",
      "[11300]\ttraining's rmse: 0.0963338\tvalid_1's rmse: 0.181664\n",
      "[11400]\ttraining's rmse: 0.0958961\tvalid_1's rmse: 0.181649\n",
      "[11500]\ttraining's rmse: 0.0954743\tvalid_1's rmse: 0.181631\n",
      "[11600]\ttraining's rmse: 0.0950361\tvalid_1's rmse: 0.18161\n",
      "[11700]\ttraining's rmse: 0.0946104\tvalid_1's rmse: 0.181594\n",
      "[11800]\ttraining's rmse: 0.094178\tvalid_1's rmse: 0.181587\n",
      "[11900]\ttraining's rmse: 0.0937652\tvalid_1's rmse: 0.181575\n",
      "[12000]\ttraining's rmse: 0.0933533\tvalid_1's rmse: 0.181552\n",
      "[12100]\ttraining's rmse: 0.0929439\tvalid_1's rmse: 0.181536\n",
      "[12200]\ttraining's rmse: 0.0925355\tvalid_1's rmse: 0.181523\n",
      "[12300]\ttraining's rmse: 0.0921215\tvalid_1's rmse: 0.181511\n",
      "[12400]\ttraining's rmse: 0.0917289\tvalid_1's rmse: 0.181495\n",
      "[12500]\ttraining's rmse: 0.091314\tvalid_1's rmse: 0.18149\n",
      "[12600]\ttraining's rmse: 0.0909084\tvalid_1's rmse: 0.181476\n",
      "[12700]\ttraining's rmse: 0.0904996\tvalid_1's rmse: 0.181466\n",
      "[12800]\ttraining's rmse: 0.090106\tvalid_1's rmse: 0.181452\n",
      "[12900]\ttraining's rmse: 0.0897047\tvalid_1's rmse: 0.181433\n",
      "[13000]\ttraining's rmse: 0.0892956\tvalid_1's rmse: 0.181421\n",
      "[13100]\ttraining's rmse: 0.0889191\tvalid_1's rmse: 0.181413\n",
      "[13200]\ttraining's rmse: 0.0885325\tvalid_1's rmse: 0.181404\n",
      "[13300]\ttraining's rmse: 0.0881491\tvalid_1's rmse: 0.181398\n",
      "[13400]\ttraining's rmse: 0.087752\tvalid_1's rmse: 0.181391\n",
      "[13500]\ttraining's rmse: 0.0873638\tvalid_1's rmse: 0.181379\n",
      "[13600]\ttraining's rmse: 0.0869812\tvalid_1's rmse: 0.181373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13700]\ttraining's rmse: 0.0865997\tvalid_1's rmse: 0.18137\n",
      "[13800]\ttraining's rmse: 0.0862217\tvalid_1's rmse: 0.181362\n",
      "[13900]\ttraining's rmse: 0.0858488\tvalid_1's rmse: 0.181355\n",
      "[14000]\ttraining's rmse: 0.0854783\tvalid_1's rmse: 0.18135\n",
      "[14100]\ttraining's rmse: 0.0851049\tvalid_1's rmse: 0.181349\n",
      "[14200]\ttraining's rmse: 0.0847334\tvalid_1's rmse: 0.181334\n",
      "[14300]\ttraining's rmse: 0.0843718\tvalid_1's rmse: 0.181329\n",
      "[14400]\ttraining's rmse: 0.0840192\tvalid_1's rmse: 0.181324\n",
      "[14500]\ttraining's rmse: 0.0836626\tvalid_1's rmse: 0.181315\n",
      "[14600]\ttraining's rmse: 0.0832981\tvalid_1's rmse: 0.181309\n",
      "[14700]\ttraining's rmse: 0.0829346\tvalid_1's rmse: 0.181295\n",
      "[14800]\ttraining's rmse: 0.0825823\tvalid_1's rmse: 0.181277\n",
      "[14900]\ttraining's rmse: 0.0822381\tvalid_1's rmse: 0.181267\n",
      "[15000]\ttraining's rmse: 0.0818965\tvalid_1's rmse: 0.181261\n",
      "[15100]\ttraining's rmse: 0.0815427\tvalid_1's rmse: 0.181255\n",
      "[15200]\ttraining's rmse: 0.0811975\tvalid_1's rmse: 0.181244\n",
      "[15300]\ttraining's rmse: 0.0808579\tvalid_1's rmse: 0.181236\n",
      "[15400]\ttraining's rmse: 0.080518\tvalid_1's rmse: 0.181224\n",
      "[15500]\ttraining's rmse: 0.0801786\tvalid_1's rmse: 0.181214\n",
      "[15600]\ttraining's rmse: 0.0798364\tvalid_1's rmse: 0.181207\n",
      "[15700]\ttraining's rmse: 0.0795038\tvalid_1's rmse: 0.181199\n",
      "[15800]\ttraining's rmse: 0.0791687\tvalid_1's rmse: 0.181194\n",
      "[15900]\ttraining's rmse: 0.0788361\tvalid_1's rmse: 0.181184\n",
      "[16000]\ttraining's rmse: 0.0785071\tvalid_1's rmse: 0.18117\n",
      "[16100]\ttraining's rmse: 0.0781867\tvalid_1's rmse: 0.181162\n",
      "[16200]\ttraining's rmse: 0.0778632\tvalid_1's rmse: 0.181155\n",
      "[16300]\ttraining's rmse: 0.0775417\tvalid_1's rmse: 0.18115\n",
      "[16400]\ttraining's rmse: 0.0772147\tvalid_1's rmse: 0.181143\n",
      "[16500]\ttraining's rmse: 0.076887\tvalid_1's rmse: 0.18114\n",
      "[16600]\ttraining's rmse: 0.0765612\tvalid_1's rmse: 0.181133\n",
      "[16700]\ttraining's rmse: 0.0762387\tvalid_1's rmse: 0.181123\n",
      "[16800]\ttraining's rmse: 0.0759164\tvalid_1's rmse: 0.181119\n",
      "[16900]\ttraining's rmse: 0.0755884\tvalid_1's rmse: 0.18111\n",
      "[17000]\ttraining's rmse: 0.0752649\tvalid_1's rmse: 0.181105\n",
      "[17100]\ttraining's rmse: 0.0749444\tvalid_1's rmse: 0.181099\n",
      "[17200]\ttraining's rmse: 0.0746343\tvalid_1's rmse: 0.181098\n",
      "[17300]\ttraining's rmse: 0.0743155\tvalid_1's rmse: 0.181092\n",
      "[17400]\ttraining's rmse: 0.0740063\tvalid_1's rmse: 0.181081\n",
      "[17500]\ttraining's rmse: 0.0737034\tvalid_1's rmse: 0.181076\n",
      "Early stopping, best iteration is:\n",
      "[17466]\ttraining's rmse: 0.0737993\tvalid_1's rmse: 0.181073\n",
      "1 77.2835885981 1763.49777693\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356018\tvalid_1's rmse: 0.359562\n",
      "[200]\ttraining's rmse: 0.258472\tvalid_1's rmse: 0.263735\n",
      "[300]\ttraining's rmse: 0.226302\tvalid_1's rmse: 0.23262\n",
      "[400]\ttraining's rmse: 0.211766\tvalid_1's rmse: 0.219171\n",
      "[500]\ttraining's rmse: 0.202946\tvalid_1's rmse: 0.211443\n",
      "[600]\ttraining's rmse: 0.196509\tvalid_1's rmse: 0.206102\n",
      "[700]\ttraining's rmse: 0.191396\tvalid_1's rmse: 0.202126\n",
      "[800]\ttraining's rmse: 0.187256\tvalid_1's rmse: 0.199137\n",
      "[900]\ttraining's rmse: 0.18369\tvalid_1's rmse: 0.196814\n",
      "[1000]\ttraining's rmse: 0.180612\tvalid_1's rmse: 0.194958\n",
      "[1100]\ttraining's rmse: 0.177921\tvalid_1's rmse: 0.193523\n",
      "[1200]\ttraining's rmse: 0.17551\tvalid_1's rmse: 0.192348\n",
      "[1300]\ttraining's rmse: 0.173334\tvalid_1's rmse: 0.191435\n",
      "[1400]\ttraining's rmse: 0.171309\tvalid_1's rmse: 0.190667\n",
      "[1500]\ttraining's rmse: 0.169491\tvalid_1's rmse: 0.190084\n",
      "[1600]\ttraining's rmse: 0.167802\tvalid_1's rmse: 0.189547\n",
      "[1700]\ttraining's rmse: 0.1662\tvalid_1's rmse: 0.189048\n",
      "[1800]\ttraining's rmse: 0.164699\tvalid_1's rmse: 0.18863\n",
      "[1900]\ttraining's rmse: 0.163237\tvalid_1's rmse: 0.188233\n",
      "[2000]\ttraining's rmse: 0.161839\tvalid_1's rmse: 0.187905\n",
      "[2100]\ttraining's rmse: 0.160479\tvalid_1's rmse: 0.187614\n",
      "[2200]\ttraining's rmse: 0.159176\tvalid_1's rmse: 0.187337\n",
      "[2300]\ttraining's rmse: 0.157904\tvalid_1's rmse: 0.187064\n",
      "[2400]\ttraining's rmse: 0.156658\tvalid_1's rmse: 0.186779\n",
      "[2500]\ttraining's rmse: 0.155448\tvalid_1's rmse: 0.186553\n",
      "[2600]\ttraining's rmse: 0.154295\tvalid_1's rmse: 0.186331\n",
      "[2700]\ttraining's rmse: 0.153165\tvalid_1's rmse: 0.186173\n",
      "[2800]\ttraining's rmse: 0.152053\tvalid_1's rmse: 0.185977\n",
      "[2900]\ttraining's rmse: 0.150982\tvalid_1's rmse: 0.185812\n",
      "[3000]\ttraining's rmse: 0.149927\tvalid_1's rmse: 0.185639\n",
      "[3100]\ttraining's rmse: 0.148899\tvalid_1's rmse: 0.185481\n",
      "[3200]\ttraining's rmse: 0.147894\tvalid_1's rmse: 0.185356\n",
      "[3300]\ttraining's rmse: 0.14688\tvalid_1's rmse: 0.185212\n",
      "[3400]\ttraining's rmse: 0.145893\tvalid_1's rmse: 0.185051\n",
      "[3500]\ttraining's rmse: 0.14497\tvalid_1's rmse: 0.184923\n",
      "[3600]\ttraining's rmse: 0.144034\tvalid_1's rmse: 0.184792\n",
      "[3700]\ttraining's rmse: 0.143098\tvalid_1's rmse: 0.184639\n",
      "[3800]\ttraining's rmse: 0.142194\tvalid_1's rmse: 0.184547\n",
      "[3900]\ttraining's rmse: 0.141301\tvalid_1's rmse: 0.184448\n",
      "[4000]\ttraining's rmse: 0.140439\tvalid_1's rmse: 0.184358\n",
      "[4100]\ttraining's rmse: 0.139562\tvalid_1's rmse: 0.184265\n",
      "[4200]\ttraining's rmse: 0.13873\tvalid_1's rmse: 0.184188\n",
      "[4300]\ttraining's rmse: 0.137886\tvalid_1's rmse: 0.184095\n",
      "[4400]\ttraining's rmse: 0.137068\tvalid_1's rmse: 0.184011\n",
      "[4500]\ttraining's rmse: 0.136235\tvalid_1's rmse: 0.183922\n",
      "[4600]\ttraining's rmse: 0.135443\tvalid_1's rmse: 0.183856\n",
      "[4700]\ttraining's rmse: 0.13464\tvalid_1's rmse: 0.183775\n",
      "[4800]\ttraining's rmse: 0.133861\tvalid_1's rmse: 0.183705\n",
      "[4900]\ttraining's rmse: 0.133081\tvalid_1's rmse: 0.183624\n",
      "[5000]\ttraining's rmse: 0.132336\tvalid_1's rmse: 0.183575\n",
      "[5100]\ttraining's rmse: 0.131595\tvalid_1's rmse: 0.183521\n",
      "[5200]\ttraining's rmse: 0.130859\tvalid_1's rmse: 0.183468\n",
      "[5300]\ttraining's rmse: 0.130122\tvalid_1's rmse: 0.183407\n",
      "[5400]\ttraining's rmse: 0.129405\tvalid_1's rmse: 0.183325\n",
      "[5500]\ttraining's rmse: 0.128692\tvalid_1's rmse: 0.183271\n",
      "[5600]\ttraining's rmse: 0.127997\tvalid_1's rmse: 0.183219\n",
      "[5700]\ttraining's rmse: 0.127301\tvalid_1's rmse: 0.183152\n",
      "[5800]\ttraining's rmse: 0.126626\tvalid_1's rmse: 0.183098\n",
      "[5900]\ttraining's rmse: 0.125909\tvalid_1's rmse: 0.183027\n",
      "[6000]\ttraining's rmse: 0.125239\tvalid_1's rmse: 0.182977\n",
      "[6100]\ttraining's rmse: 0.124558\tvalid_1's rmse: 0.182922\n",
      "[6200]\ttraining's rmse: 0.123887\tvalid_1's rmse: 0.182878\n",
      "[6300]\ttraining's rmse: 0.123244\tvalid_1's rmse: 0.182845\n",
      "[6400]\ttraining's rmse: 0.122601\tvalid_1's rmse: 0.182793\n",
      "[6500]\ttraining's rmse: 0.121955\tvalid_1's rmse: 0.182742\n",
      "[6600]\ttraining's rmse: 0.121315\tvalid_1's rmse: 0.182702\n",
      "[6700]\ttraining's rmse: 0.120671\tvalid_1's rmse: 0.182652\n",
      "[6800]\ttraining's rmse: 0.120057\tvalid_1's rmse: 0.182614\n",
      "[6900]\ttraining's rmse: 0.119447\tvalid_1's rmse: 0.182563\n",
      "[7000]\ttraining's rmse: 0.118834\tvalid_1's rmse: 0.182522\n",
      "[7100]\ttraining's rmse: 0.118231\tvalid_1's rmse: 0.182491\n",
      "[7200]\ttraining's rmse: 0.117606\tvalid_1's rmse: 0.182438\n",
      "[7300]\ttraining's rmse: 0.117013\tvalid_1's rmse: 0.182411\n",
      "[7400]\ttraining's rmse: 0.116435\tvalid_1's rmse: 0.182377\n",
      "[7500]\ttraining's rmse: 0.115835\tvalid_1's rmse: 0.182337\n",
      "[7600]\ttraining's rmse: 0.115262\tvalid_1's rmse: 0.182293\n",
      "[7700]\ttraining's rmse: 0.114683\tvalid_1's rmse: 0.182258\n",
      "[7800]\ttraining's rmse: 0.114109\tvalid_1's rmse: 0.182225\n",
      "[7900]\ttraining's rmse: 0.11354\tvalid_1's rmse: 0.182175\n",
      "[8000]\ttraining's rmse: 0.112987\tvalid_1's rmse: 0.182149\n",
      "[8100]\ttraining's rmse: 0.112433\tvalid_1's rmse: 0.18213\n",
      "[8200]\ttraining's rmse: 0.11187\tvalid_1's rmse: 0.182085\n",
      "[8300]\ttraining's rmse: 0.111311\tvalid_1's rmse: 0.182046\n",
      "[8400]\ttraining's rmse: 0.11077\tvalid_1's rmse: 0.182017\n",
      "[8500]\ttraining's rmse: 0.110239\tvalid_1's rmse: 0.181996\n",
      "[8600]\ttraining's rmse: 0.109689\tvalid_1's rmse: 0.181962\n",
      "[8700]\ttraining's rmse: 0.109143\tvalid_1's rmse: 0.181939\n",
      "[8800]\ttraining's rmse: 0.108622\tvalid_1's rmse: 0.181923\n",
      "[8900]\ttraining's rmse: 0.10809\tvalid_1's rmse: 0.181897\n",
      "[9000]\ttraining's rmse: 0.107579\tvalid_1's rmse: 0.18188\n",
      "[9100]\ttraining's rmse: 0.107056\tvalid_1's rmse: 0.181851\n",
      "[9200]\ttraining's rmse: 0.106554\tvalid_1's rmse: 0.181827\n",
      "[9300]\ttraining's rmse: 0.106042\tvalid_1's rmse: 0.181796\n",
      "[9400]\ttraining's rmse: 0.105524\tvalid_1's rmse: 0.18177\n",
      "[9500]\ttraining's rmse: 0.105011\tvalid_1's rmse: 0.181735\n",
      "[9600]\ttraining's rmse: 0.104506\tvalid_1's rmse: 0.181717\n",
      "[9700]\ttraining's rmse: 0.104022\tvalid_1's rmse: 0.181698\n",
      "[9800]\ttraining's rmse: 0.103533\tvalid_1's rmse: 0.181686\n",
      "[9900]\ttraining's rmse: 0.103055\tvalid_1's rmse: 0.181664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\ttraining's rmse: 0.102574\tvalid_1's rmse: 0.181641\n",
      "[10100]\ttraining's rmse: 0.102103\tvalid_1's rmse: 0.181611\n",
      "[10200]\ttraining's rmse: 0.101626\tvalid_1's rmse: 0.181593\n",
      "[10300]\ttraining's rmse: 0.10116\tvalid_1's rmse: 0.181575\n",
      "[10400]\ttraining's rmse: 0.100706\tvalid_1's rmse: 0.181556\n",
      "[10500]\ttraining's rmse: 0.100248\tvalid_1's rmse: 0.181532\n",
      "[10600]\ttraining's rmse: 0.0997889\tvalid_1's rmse: 0.181512\n",
      "[10700]\ttraining's rmse: 0.0993238\tvalid_1's rmse: 0.181495\n",
      "[10800]\ttraining's rmse: 0.0988736\tvalid_1's rmse: 0.181471\n",
      "[10900]\ttraining's rmse: 0.0984225\tvalid_1's rmse: 0.18146\n",
      "[11000]\ttraining's rmse: 0.0979706\tvalid_1's rmse: 0.181433\n",
      "[11100]\ttraining's rmse: 0.0975283\tvalid_1's rmse: 0.181416\n",
      "[11200]\ttraining's rmse: 0.097072\tvalid_1's rmse: 0.181389\n",
      "[11300]\ttraining's rmse: 0.0966418\tvalid_1's rmse: 0.181377\n",
      "[11400]\ttraining's rmse: 0.0962116\tvalid_1's rmse: 0.181354\n",
      "[11500]\ttraining's rmse: 0.0957733\tvalid_1's rmse: 0.181341\n",
      "[11600]\ttraining's rmse: 0.0953482\tvalid_1's rmse: 0.18132\n",
      "[11700]\ttraining's rmse: 0.0949143\tvalid_1's rmse: 0.181301\n",
      "[11800]\ttraining's rmse: 0.0944846\tvalid_1's rmse: 0.181284\n",
      "[11900]\ttraining's rmse: 0.094051\tvalid_1's rmse: 0.181268\n",
      "[12000]\ttraining's rmse: 0.0936525\tvalid_1's rmse: 0.181252\n",
      "[12100]\ttraining's rmse: 0.0932397\tvalid_1's rmse: 0.181221\n",
      "[12200]\ttraining's rmse: 0.0928361\tvalid_1's rmse: 0.181205\n",
      "[12300]\ttraining's rmse: 0.092424\tvalid_1's rmse: 0.181197\n",
      "[12400]\ttraining's rmse: 0.0920141\tvalid_1's rmse: 0.181177\n",
      "[12500]\ttraining's rmse: 0.0915973\tvalid_1's rmse: 0.181159\n",
      "[12600]\ttraining's rmse: 0.0911952\tvalid_1's rmse: 0.181143\n",
      "[12700]\ttraining's rmse: 0.0907761\tvalid_1's rmse: 0.181126\n",
      "[12800]\ttraining's rmse: 0.0903859\tvalid_1's rmse: 0.181125\n",
      "[12900]\ttraining's rmse: 0.089985\tvalid_1's rmse: 0.181108\n",
      "[13000]\ttraining's rmse: 0.0895835\tvalid_1's rmse: 0.18109\n",
      "[13100]\ttraining's rmse: 0.0892034\tvalid_1's rmse: 0.181075\n",
      "[13200]\ttraining's rmse: 0.0888162\tvalid_1's rmse: 0.181066\n",
      "[13300]\ttraining's rmse: 0.0884253\tvalid_1's rmse: 0.181055\n",
      "[13400]\ttraining's rmse: 0.0880437\tvalid_1's rmse: 0.181044\n",
      "[13500]\ttraining's rmse: 0.0876407\tvalid_1's rmse: 0.181031\n",
      "[13600]\ttraining's rmse: 0.0872468\tvalid_1's rmse: 0.181018\n",
      "[13700]\ttraining's rmse: 0.0868733\tvalid_1's rmse: 0.181002\n",
      "[13800]\ttraining's rmse: 0.0864873\tvalid_1's rmse: 0.180994\n",
      "[13900]\ttraining's rmse: 0.086107\tvalid_1's rmse: 0.180976\n",
      "[14000]\ttraining's rmse: 0.0857424\tvalid_1's rmse: 0.180967\n",
      "[14100]\ttraining's rmse: 0.085373\tvalid_1's rmse: 0.18095\n",
      "[14200]\ttraining's rmse: 0.0850046\tvalid_1's rmse: 0.180942\n",
      "[14300]\ttraining's rmse: 0.0846387\tvalid_1's rmse: 0.180932\n",
      "[14400]\ttraining's rmse: 0.0842751\tvalid_1's rmse: 0.180927\n",
      "[14500]\ttraining's rmse: 0.0839194\tvalid_1's rmse: 0.180915\n",
      "[14600]\ttraining's rmse: 0.0835563\tvalid_1's rmse: 0.180912\n",
      "[14700]\ttraining's rmse: 0.0831927\tvalid_1's rmse: 0.180903\n",
      "[14800]\ttraining's rmse: 0.0828233\tvalid_1's rmse: 0.180893\n",
      "[14900]\ttraining's rmse: 0.0824642\tvalid_1's rmse: 0.180877\n",
      "[15000]\ttraining's rmse: 0.0820993\tvalid_1's rmse: 0.180865\n",
      "[15100]\ttraining's rmse: 0.0817458\tvalid_1's rmse: 0.180858\n",
      "[15200]\ttraining's rmse: 0.0813874\tvalid_1's rmse: 0.180856\n",
      "[15300]\ttraining's rmse: 0.0810404\tvalid_1's rmse: 0.180841\n",
      "[15400]\ttraining's rmse: 0.0806885\tvalid_1's rmse: 0.180826\n",
      "[15500]\ttraining's rmse: 0.0803438\tvalid_1's rmse: 0.180817\n",
      "[15600]\ttraining's rmse: 0.0800055\tvalid_1's rmse: 0.180814\n",
      "[15700]\ttraining's rmse: 0.0796471\tvalid_1's rmse: 0.180804\n",
      "[15800]\ttraining's rmse: 0.0793153\tvalid_1's rmse: 0.18079\n",
      "[15900]\ttraining's rmse: 0.0789791\tvalid_1's rmse: 0.180777\n",
      "[16000]\ttraining's rmse: 0.0786462\tvalid_1's rmse: 0.180774\n",
      "[16100]\ttraining's rmse: 0.0783124\tvalid_1's rmse: 0.18077\n",
      "Early stopping, best iteration is:\n",
      "[16046]\ttraining's rmse: 0.078498\tvalid_1's rmse: 0.180768\n",
      "2 75.0513776269 179.704812522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 6\n",
      "60.5063751466\n",
      "147.028554936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [11:12<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3075 (78851, 3075)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.356301\tvalid_1's rmse: 0.354681\n",
      "[200]\ttraining's rmse: 0.258305\tvalid_1's rmse: 0.259727\n",
      "[300]\ttraining's rmse: 0.225932\tvalid_1's rmse: 0.229302\n",
      "[400]\ttraining's rmse: 0.211144\tvalid_1's rmse: 0.216427\n",
      "[500]\ttraining's rmse: 0.202214\tvalid_1's rmse: 0.209212\n",
      "[600]\ttraining's rmse: 0.19566\tvalid_1's rmse: 0.204303\n",
      "[700]\ttraining's rmse: 0.190618\tvalid_1's rmse: 0.200802\n",
      "[800]\ttraining's rmse: 0.186517\tvalid_1's rmse: 0.198165\n",
      "[900]\ttraining's rmse: 0.182987\tvalid_1's rmse: 0.196083\n",
      "[1000]\ttraining's rmse: 0.179952\tvalid_1's rmse: 0.194388\n",
      "[1100]\ttraining's rmse: 0.177295\tvalid_1's rmse: 0.193122\n",
      "[1200]\ttraining's rmse: 0.174889\tvalid_1's rmse: 0.192082\n",
      "[1300]\ttraining's rmse: 0.172704\tvalid_1's rmse: 0.191194\n",
      "[1400]\ttraining's rmse: 0.170709\tvalid_1's rmse: 0.190503\n",
      "[1500]\ttraining's rmse: 0.168844\tvalid_1's rmse: 0.189853\n",
      "[1600]\ttraining's rmse: 0.167107\tvalid_1's rmse: 0.189322\n",
      "[1700]\ttraining's rmse: 0.165478\tvalid_1's rmse: 0.188844\n",
      "[1800]\ttraining's rmse: 0.163921\tvalid_1's rmse: 0.188417\n",
      "[1900]\ttraining's rmse: 0.16244\tvalid_1's rmse: 0.188\n",
      "[2000]\ttraining's rmse: 0.160997\tvalid_1's rmse: 0.187646\n",
      "[2100]\ttraining's rmse: 0.159615\tvalid_1's rmse: 0.187292\n",
      "[2200]\ttraining's rmse: 0.158314\tvalid_1's rmse: 0.186987\n",
      "[2300]\ttraining's rmse: 0.157024\tvalid_1's rmse: 0.186721\n",
      "[2400]\ttraining's rmse: 0.155754\tvalid_1's rmse: 0.186418\n",
      "[2500]\ttraining's rmse: 0.15455\tvalid_1's rmse: 0.186178\n",
      "[2600]\ttraining's rmse: 0.153376\tvalid_1's rmse: 0.18595\n",
      "[2700]\ttraining's rmse: 0.152239\tvalid_1's rmse: 0.185744\n",
      "[2800]\ttraining's rmse: 0.151117\tvalid_1's rmse: 0.185549\n",
      "[2900]\ttraining's rmse: 0.150037\tvalid_1's rmse: 0.185376\n",
      "[3000]\ttraining's rmse: 0.148998\tvalid_1's rmse: 0.185227\n",
      "[3100]\ttraining's rmse: 0.147967\tvalid_1's rmse: 0.185042\n",
      "[3200]\ttraining's rmse: 0.146952\tvalid_1's rmse: 0.184877\n",
      "[3300]\ttraining's rmse: 0.14595\tvalid_1's rmse: 0.18474\n",
      "[3400]\ttraining's rmse: 0.144986\tvalid_1's rmse: 0.184607\n",
      "[3500]\ttraining's rmse: 0.143997\tvalid_1's rmse: 0.18446\n",
      "[3600]\ttraining's rmse: 0.14306\tvalid_1's rmse: 0.184329\n",
      "[3700]\ttraining's rmse: 0.142133\tvalid_1's rmse: 0.1842\n",
      "[3800]\ttraining's rmse: 0.141247\tvalid_1's rmse: 0.184082\n",
      "[3900]\ttraining's rmse: 0.140327\tvalid_1's rmse: 0.183948\n",
      "[4000]\ttraining's rmse: 0.139454\tvalid_1's rmse: 0.183842\n",
      "[4100]\ttraining's rmse: 0.138591\tvalid_1's rmse: 0.183757\n",
      "[4200]\ttraining's rmse: 0.137737\tvalid_1's rmse: 0.183628\n",
      "[4300]\ttraining's rmse: 0.136898\tvalid_1's rmse: 0.183528\n",
      "[4400]\ttraining's rmse: 0.136053\tvalid_1's rmse: 0.183431\n",
      "[4500]\ttraining's rmse: 0.135217\tvalid_1's rmse: 0.18333\n",
      "[4600]\ttraining's rmse: 0.134417\tvalid_1's rmse: 0.183248\n",
      "[4700]\ttraining's rmse: 0.133621\tvalid_1's rmse: 0.183167\n",
      "[4800]\ttraining's rmse: 0.132821\tvalid_1's rmse: 0.183086\n",
      "[4900]\ttraining's rmse: 0.132031\tvalid_1's rmse: 0.183006\n",
      "[5000]\ttraining's rmse: 0.131279\tvalid_1's rmse: 0.182938\n",
      "[5100]\ttraining's rmse: 0.130524\tvalid_1's rmse: 0.182885\n",
      "[5200]\ttraining's rmse: 0.129797\tvalid_1's rmse: 0.182816\n",
      "[5300]\ttraining's rmse: 0.129042\tvalid_1's rmse: 0.182758\n",
      "[5400]\ttraining's rmse: 0.128303\tvalid_1's rmse: 0.18269\n",
      "[5500]\ttraining's rmse: 0.127603\tvalid_1's rmse: 0.182619\n",
      "[5600]\ttraining's rmse: 0.126893\tvalid_1's rmse: 0.182551\n",
      "[5700]\ttraining's rmse: 0.126186\tvalid_1's rmse: 0.182471\n",
      "[5800]\ttraining's rmse: 0.125487\tvalid_1's rmse: 0.182413\n",
      "[5900]\ttraining's rmse: 0.124804\tvalid_1's rmse: 0.182355\n",
      "[6000]\ttraining's rmse: 0.124105\tvalid_1's rmse: 0.182284\n",
      "[6100]\ttraining's rmse: 0.12342\tvalid_1's rmse: 0.182224\n",
      "[6200]\ttraining's rmse: 0.122764\tvalid_1's rmse: 0.182172\n",
      "[6300]\ttraining's rmse: 0.122103\tvalid_1's rmse: 0.18213\n",
      "[6400]\ttraining's rmse: 0.121457\tvalid_1's rmse: 0.182097\n",
      "[6500]\ttraining's rmse: 0.12082\tvalid_1's rmse: 0.182055\n",
      "[6600]\ttraining's rmse: 0.120185\tvalid_1's rmse: 0.182\n",
      "[6700]\ttraining's rmse: 0.11956\tvalid_1's rmse: 0.181958\n",
      "[6800]\ttraining's rmse: 0.118901\tvalid_1's rmse: 0.181914\n",
      "[6900]\ttraining's rmse: 0.118281\tvalid_1's rmse: 0.181874\n",
      "[7000]\ttraining's rmse: 0.117668\tvalid_1's rmse: 0.181838\n",
      "[7100]\ttraining's rmse: 0.117061\tvalid_1's rmse: 0.181792\n",
      "[7200]\ttraining's rmse: 0.116459\tvalid_1's rmse: 0.181748\n",
      "[7300]\ttraining's rmse: 0.115858\tvalid_1's rmse: 0.181725\n",
      "[7400]\ttraining's rmse: 0.115282\tvalid_1's rmse: 0.181686\n",
      "[7500]\ttraining's rmse: 0.114713\tvalid_1's rmse: 0.181643\n",
      "[7600]\ttraining's rmse: 0.114135\tvalid_1's rmse: 0.181612\n",
      "[7700]\ttraining's rmse: 0.113548\tvalid_1's rmse: 0.181581\n",
      "[7800]\ttraining's rmse: 0.112985\tvalid_1's rmse: 0.181551\n",
      "[7900]\ttraining's rmse: 0.112412\tvalid_1's rmse: 0.181514\n",
      "[8000]\ttraining's rmse: 0.111874\tvalid_1's rmse: 0.181498\n",
      "[8100]\ttraining's rmse: 0.111326\tvalid_1's rmse: 0.181466\n",
      "[8200]\ttraining's rmse: 0.110786\tvalid_1's rmse: 0.181445\n",
      "[8300]\ttraining's rmse: 0.110242\tvalid_1's rmse: 0.18142\n",
      "[8400]\ttraining's rmse: 0.1097\tvalid_1's rmse: 0.181398\n",
      "[8500]\ttraining's rmse: 0.109174\tvalid_1's rmse: 0.181358\n",
      "[8600]\ttraining's rmse: 0.108654\tvalid_1's rmse: 0.181346\n",
      "[8700]\ttraining's rmse: 0.108131\tvalid_1's rmse: 0.18131\n",
      "[8800]\ttraining's rmse: 0.107595\tvalid_1's rmse: 0.181273\n",
      "[8900]\ttraining's rmse: 0.107092\tvalid_1's rmse: 0.181252\n",
      "[9000]\ttraining's rmse: 0.106562\tvalid_1's rmse: 0.18123\n",
      "[9100]\ttraining's rmse: 0.106063\tvalid_1's rmse: 0.1812\n",
      "[9200]\ttraining's rmse: 0.10553\tvalid_1's rmse: 0.181168\n",
      "[9300]\ttraining's rmse: 0.105017\tvalid_1's rmse: 0.181144\n",
      "[9400]\ttraining's rmse: 0.104523\tvalid_1's rmse: 0.181119\n",
      "[9500]\ttraining's rmse: 0.104025\tvalid_1's rmse: 0.181095\n",
      "[9600]\ttraining's rmse: 0.103534\tvalid_1's rmse: 0.181067\n",
      "[9700]\ttraining's rmse: 0.103039\tvalid_1's rmse: 0.181041\n",
      "[9800]\ttraining's rmse: 0.102545\tvalid_1's rmse: 0.181012\n",
      "[9900]\ttraining's rmse: 0.102063\tvalid_1's rmse: 0.180977\n",
      "[10000]\ttraining's rmse: 0.101577\tvalid_1's rmse: 0.180953\n",
      "[10100]\ttraining's rmse: 0.101101\tvalid_1's rmse: 0.180934\n",
      "[10200]\ttraining's rmse: 0.100618\tvalid_1's rmse: 0.180909\n",
      "[10300]\ttraining's rmse: 0.100153\tvalid_1's rmse: 0.180888\n",
      "[10400]\ttraining's rmse: 0.0996861\tvalid_1's rmse: 0.180869\n",
      "[10500]\ttraining's rmse: 0.0992238\tvalid_1's rmse: 0.180851\n",
      "[10600]\ttraining's rmse: 0.0987606\tvalid_1's rmse: 0.180832\n",
      "[10700]\ttraining's rmse: 0.0983046\tvalid_1's rmse: 0.180816\n",
      "[10800]\ttraining's rmse: 0.0978593\tvalid_1's rmse: 0.180792\n",
      "[10900]\ttraining's rmse: 0.0974101\tvalid_1's rmse: 0.180772\n",
      "[11000]\ttraining's rmse: 0.096972\tvalid_1's rmse: 0.18076\n",
      "[11100]\ttraining's rmse: 0.0965372\tvalid_1's rmse: 0.180738\n",
      "[11200]\ttraining's rmse: 0.0960835\tvalid_1's rmse: 0.180721\n",
      "[11300]\ttraining's rmse: 0.0956519\tvalid_1's rmse: 0.180699\n",
      "[11400]\ttraining's rmse: 0.0952154\tvalid_1's rmse: 0.180683\n",
      "[11500]\ttraining's rmse: 0.0947823\tvalid_1's rmse: 0.180667\n",
      "[11600]\ttraining's rmse: 0.0943677\tvalid_1's rmse: 0.180659\n",
      "[11700]\ttraining's rmse: 0.093943\tvalid_1's rmse: 0.180644\n",
      "[11800]\ttraining's rmse: 0.0935049\tvalid_1's rmse: 0.180628\n",
      "[11900]\ttraining's rmse: 0.0930815\tvalid_1's rmse: 0.180612\n",
      "[12000]\ttraining's rmse: 0.0926677\tvalid_1's rmse: 0.180592\n",
      "[12100]\ttraining's rmse: 0.0922609\tvalid_1's rmse: 0.180576\n",
      "[12200]\ttraining's rmse: 0.0918407\tvalid_1's rmse: 0.180559\n",
      "[12300]\ttraining's rmse: 0.091437\tvalid_1's rmse: 0.180542\n",
      "[12400]\ttraining's rmse: 0.0910377\tvalid_1's rmse: 0.180532\n",
      "[12500]\ttraining's rmse: 0.0906311\tvalid_1's rmse: 0.180518\n",
      "[12600]\ttraining's rmse: 0.0902272\tvalid_1's rmse: 0.180502\n",
      "[12700]\ttraining's rmse: 0.0898354\tvalid_1's rmse: 0.180496\n",
      "[12800]\ttraining's rmse: 0.0894371\tvalid_1's rmse: 0.180481\n",
      "[12900]\ttraining's rmse: 0.0890452\tvalid_1's rmse: 0.180478\n",
      "[13000]\ttraining's rmse: 0.0886439\tvalid_1's rmse: 0.180467\n",
      "[13100]\ttraining's rmse: 0.0882413\tvalid_1's rmse: 0.180465\n",
      "Early stopping, best iteration is:\n",
      "[13024]\ttraining's rmse: 0.0885454\tvalid_1's rmse: 0.180464\n",
      "0 86.8284806672 140.902121053\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.35543\tvalid_1's rmse: 0.360341\n",
      "[200]\ttraining's rmse: 0.257925\tvalid_1's rmse: 0.263496\n",
      "[300]\ttraining's rmse: 0.225734\tvalid_1's rmse: 0.232107\n",
      "[400]\ttraining's rmse: 0.210949\tvalid_1's rmse: 0.218331\n",
      "[500]\ttraining's rmse: 0.202057\tvalid_1's rmse: 0.210595\n",
      "[600]\ttraining's rmse: 0.195579\tvalid_1's rmse: 0.205461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 0.190575\tvalid_1's rmse: 0.201865\n",
      "[800]\ttraining's rmse: 0.186397\tvalid_1's rmse: 0.199099\n",
      "[900]\ttraining's rmse: 0.182913\tvalid_1's rmse: 0.196967\n",
      "[1000]\ttraining's rmse: 0.179876\tvalid_1's rmse: 0.19529\n",
      "[1100]\ttraining's rmse: 0.177204\tvalid_1's rmse: 0.193903\n",
      "[1200]\ttraining's rmse: 0.174817\tvalid_1's rmse: 0.192757\n",
      "[1300]\ttraining's rmse: 0.172641\tvalid_1's rmse: 0.191746\n",
      "[1400]\ttraining's rmse: 0.170677\tvalid_1's rmse: 0.190955\n",
      "[1500]\ttraining's rmse: 0.16881\tvalid_1's rmse: 0.190279\n",
      "[1600]\ttraining's rmse: 0.167072\tvalid_1's rmse: 0.189692\n",
      "[1700]\ttraining's rmse: 0.165449\tvalid_1's rmse: 0.189189\n",
      "[1800]\ttraining's rmse: 0.163919\tvalid_1's rmse: 0.188771\n",
      "[1900]\ttraining's rmse: 0.162512\tvalid_1's rmse: 0.188393\n",
      "[2000]\ttraining's rmse: 0.161129\tvalid_1's rmse: 0.188033\n",
      "[2100]\ttraining's rmse: 0.159801\tvalid_1's rmse: 0.18776\n",
      "[2200]\ttraining's rmse: 0.158545\tvalid_1's rmse: 0.187487\n",
      "[2300]\ttraining's rmse: 0.157313\tvalid_1's rmse: 0.187242\n",
      "[2400]\ttraining's rmse: 0.156098\tvalid_1's rmse: 0.187015\n",
      "[2500]\ttraining's rmse: 0.154949\tvalid_1's rmse: 0.186819\n",
      "[2600]\ttraining's rmse: 0.153832\tvalid_1's rmse: 0.186627\n",
      "[2700]\ttraining's rmse: 0.152726\tvalid_1's rmse: 0.186448\n",
      "[2800]\ttraining's rmse: 0.151644\tvalid_1's rmse: 0.186266\n",
      "[2900]\ttraining's rmse: 0.150598\tvalid_1's rmse: 0.186109\n",
      "[3000]\ttraining's rmse: 0.149562\tvalid_1's rmse: 0.185953\n",
      "[3100]\ttraining's rmse: 0.14855\tvalid_1's rmse: 0.18581\n",
      "[3200]\ttraining's rmse: 0.147571\tvalid_1's rmse: 0.185659\n",
      "[3300]\ttraining's rmse: 0.146613\tvalid_1's rmse: 0.185527\n",
      "[3400]\ttraining's rmse: 0.145663\tvalid_1's rmse: 0.18541\n",
      "[3500]\ttraining's rmse: 0.144738\tvalid_1's rmse: 0.185291\n",
      "[3600]\ttraining's rmse: 0.14381\tvalid_1's rmse: 0.185174\n",
      "[3700]\ttraining's rmse: 0.142899\tvalid_1's rmse: 0.185053\n",
      "[3800]\ttraining's rmse: 0.141985\tvalid_1's rmse: 0.184928\n",
      "[3900]\ttraining's rmse: 0.141102\tvalid_1's rmse: 0.184833\n",
      "[4000]\ttraining's rmse: 0.140235\tvalid_1's rmse: 0.184745\n",
      "[4100]\ttraining's rmse: 0.139382\tvalid_1's rmse: 0.184664\n",
      "[4200]\ttraining's rmse: 0.138547\tvalid_1's rmse: 0.18457\n",
      "[4300]\ttraining's rmse: 0.137725\tvalid_1's rmse: 0.184486\n",
      "[4400]\ttraining's rmse: 0.136898\tvalid_1's rmse: 0.184405\n",
      "[4500]\ttraining's rmse: 0.136084\tvalid_1's rmse: 0.18433\n",
      "[4600]\ttraining's rmse: 0.135307\tvalid_1's rmse: 0.184251\n",
      "[4700]\ttraining's rmse: 0.134512\tvalid_1's rmse: 0.184188\n",
      "[4800]\ttraining's rmse: 0.133717\tvalid_1's rmse: 0.184093\n",
      "[4900]\ttraining's rmse: 0.132954\tvalid_1's rmse: 0.184017\n",
      "[5000]\ttraining's rmse: 0.132222\tvalid_1's rmse: 0.183952\n",
      "[5100]\ttraining's rmse: 0.131467\tvalid_1's rmse: 0.183879\n",
      "[5200]\ttraining's rmse: 0.130731\tvalid_1's rmse: 0.183804\n",
      "[5300]\ttraining's rmse: 0.129997\tvalid_1's rmse: 0.183727\n",
      "[5400]\ttraining's rmse: 0.129279\tvalid_1's rmse: 0.183665\n",
      "[5500]\ttraining's rmse: 0.128561\tvalid_1's rmse: 0.183604\n",
      "[5600]\ttraining's rmse: 0.127857\tvalid_1's rmse: 0.183547\n",
      "[5700]\ttraining's rmse: 0.127153\tvalid_1's rmse: 0.183498\n",
      "[5800]\ttraining's rmse: 0.126454\tvalid_1's rmse: 0.183429\n",
      "[5900]\ttraining's rmse: 0.125758\tvalid_1's rmse: 0.183364\n",
      "[6000]\ttraining's rmse: 0.125081\tvalid_1's rmse: 0.183305\n",
      "[6100]\ttraining's rmse: 0.124424\tvalid_1's rmse: 0.183242\n",
      "[6200]\ttraining's rmse: 0.123765\tvalid_1's rmse: 0.183191\n",
      "[6300]\ttraining's rmse: 0.123088\tvalid_1's rmse: 0.183121\n",
      "[6400]\ttraining's rmse: 0.12244\tvalid_1's rmse: 0.183062\n",
      "[6500]\ttraining's rmse: 0.121796\tvalid_1's rmse: 0.183005\n",
      "[6600]\ttraining's rmse: 0.121154\tvalid_1's rmse: 0.182965\n",
      "[6700]\ttraining's rmse: 0.120527\tvalid_1's rmse: 0.182918\n",
      "[6800]\ttraining's rmse: 0.119919\tvalid_1's rmse: 0.182875\n",
      "[6900]\ttraining's rmse: 0.119298\tvalid_1's rmse: 0.182835\n",
      "[7000]\ttraining's rmse: 0.118698\tvalid_1's rmse: 0.182791\n",
      "[7100]\ttraining's rmse: 0.118103\tvalid_1's rmse: 0.182755\n",
      "[7200]\ttraining's rmse: 0.117499\tvalid_1's rmse: 0.182697\n",
      "[7300]\ttraining's rmse: 0.116895\tvalid_1's rmse: 0.182657\n",
      "[7400]\ttraining's rmse: 0.116304\tvalid_1's rmse: 0.182611\n",
      "[7500]\ttraining's rmse: 0.115716\tvalid_1's rmse: 0.182571\n",
      "[7600]\ttraining's rmse: 0.115148\tvalid_1's rmse: 0.182537\n",
      "[7700]\ttraining's rmse: 0.114576\tvalid_1's rmse: 0.182504\n",
      "[7800]\ttraining's rmse: 0.114002\tvalid_1's rmse: 0.182454\n",
      "[7900]\ttraining's rmse: 0.113443\tvalid_1's rmse: 0.182427\n",
      "[8000]\ttraining's rmse: 0.112878\tvalid_1's rmse: 0.182392\n",
      "[8100]\ttraining's rmse: 0.112337\tvalid_1's rmse: 0.182345\n",
      "[8200]\ttraining's rmse: 0.111778\tvalid_1's rmse: 0.182309\n",
      "[8300]\ttraining's rmse: 0.11124\tvalid_1's rmse: 0.182279\n",
      "[8400]\ttraining's rmse: 0.110698\tvalid_1's rmse: 0.182251\n",
      "[8500]\ttraining's rmse: 0.110155\tvalid_1's rmse: 0.182232\n",
      "[8600]\ttraining's rmse: 0.109635\tvalid_1's rmse: 0.182203\n",
      "[8700]\ttraining's rmse: 0.109094\tvalid_1's rmse: 0.182175\n",
      "[8800]\ttraining's rmse: 0.108558\tvalid_1's rmse: 0.182132\n",
      "[8900]\ttraining's rmse: 0.108037\tvalid_1's rmse: 0.182105\n",
      "[9000]\ttraining's rmse: 0.107489\tvalid_1's rmse: 0.182073\n",
      "[9100]\ttraining's rmse: 0.106974\tvalid_1's rmse: 0.182046\n",
      "[9200]\ttraining's rmse: 0.106461\tvalid_1's rmse: 0.182032\n",
      "[9300]\ttraining's rmse: 0.105967\tvalid_1's rmse: 0.182006\n",
      "[9400]\ttraining's rmse: 0.105456\tvalid_1's rmse: 0.18197\n",
      "[9500]\ttraining's rmse: 0.104942\tvalid_1's rmse: 0.18195\n",
      "[9600]\ttraining's rmse: 0.104436\tvalid_1's rmse: 0.181918\n",
      "[9700]\ttraining's rmse: 0.103944\tvalid_1's rmse: 0.181891\n",
      "[9800]\ttraining's rmse: 0.103461\tvalid_1's rmse: 0.181873\n",
      "[9900]\ttraining's rmse: 0.102974\tvalid_1's rmse: 0.181849\n",
      "[10000]\ttraining's rmse: 0.102494\tvalid_1's rmse: 0.181824\n",
      "[10100]\ttraining's rmse: 0.102009\tvalid_1's rmse: 0.181786\n",
      "[10200]\ttraining's rmse: 0.101547\tvalid_1's rmse: 0.181772\n",
      "[10300]\ttraining's rmse: 0.101086\tvalid_1's rmse: 0.181751\n",
      "[10400]\ttraining's rmse: 0.100616\tvalid_1's rmse: 0.181735\n",
      "[10500]\ttraining's rmse: 0.100157\tvalid_1's rmse: 0.181714\n",
      "[10600]\ttraining's rmse: 0.0996869\tvalid_1's rmse: 0.181698\n",
      "[10700]\ttraining's rmse: 0.0992299\tvalid_1's rmse: 0.181684\n",
      "[10800]\ttraining's rmse: 0.0987653\tvalid_1's rmse: 0.181665\n",
      "[10900]\ttraining's rmse: 0.0983199\tvalid_1's rmse: 0.181649\n",
      "[11000]\ttraining's rmse: 0.0978666\tvalid_1's rmse: 0.181626\n",
      "[11100]\ttraining's rmse: 0.0974218\tvalid_1's rmse: 0.181615\n",
      "[11200]\ttraining's rmse: 0.0969758\tvalid_1's rmse: 0.181598\n",
      "[11300]\ttraining's rmse: 0.0965274\tvalid_1's rmse: 0.181566\n",
      "[11400]\ttraining's rmse: 0.0961081\tvalid_1's rmse: 0.181564\n",
      "[11500]\ttraining's rmse: 0.0956905\tvalid_1's rmse: 0.181554\n",
      "[11600]\ttraining's rmse: 0.0952529\tvalid_1's rmse: 0.181543\n",
      "[11700]\ttraining's rmse: 0.0948334\tvalid_1's rmse: 0.181533\n",
      "[11800]\ttraining's rmse: 0.0944114\tvalid_1's rmse: 0.181518\n",
      "[11900]\ttraining's rmse: 0.0939829\tvalid_1's rmse: 0.181509\n",
      "[12000]\ttraining's rmse: 0.0935638\tvalid_1's rmse: 0.181503\n",
      "[12100]\ttraining's rmse: 0.0931592\tvalid_1's rmse: 0.18149\n",
      "[12200]\ttraining's rmse: 0.0927386\tvalid_1's rmse: 0.181471\n",
      "[12300]\ttraining's rmse: 0.0923253\tvalid_1's rmse: 0.181458\n",
      "[12400]\ttraining's rmse: 0.0919233\tvalid_1's rmse: 0.181444\n",
      "[12500]\ttraining's rmse: 0.091518\tvalid_1's rmse: 0.181423\n",
      "[12600]\ttraining's rmse: 0.0911103\tvalid_1's rmse: 0.181407\n",
      "[12700]\ttraining's rmse: 0.0907196\tvalid_1's rmse: 0.181391\n",
      "[12800]\ttraining's rmse: 0.0903265\tvalid_1's rmse: 0.18138\n",
      "[12900]\ttraining's rmse: 0.0899244\tvalid_1's rmse: 0.18137\n",
      "[13000]\ttraining's rmse: 0.0895323\tvalid_1's rmse: 0.181354\n",
      "[13100]\ttraining's rmse: 0.0891361\tvalid_1's rmse: 0.18134\n",
      "[13200]\ttraining's rmse: 0.0887501\tvalid_1's rmse: 0.181329\n",
      "[13300]\ttraining's rmse: 0.0883581\tvalid_1's rmse: 0.181312\n",
      "[13400]\ttraining's rmse: 0.0879868\tvalid_1's rmse: 0.181305\n",
      "[13500]\ttraining's rmse: 0.087603\tvalid_1's rmse: 0.181293\n",
      "[13600]\ttraining's rmse: 0.0872199\tvalid_1's rmse: 0.181285\n",
      "[13700]\ttraining's rmse: 0.0868469\tvalid_1's rmse: 0.181275\n",
      "[13800]\ttraining's rmse: 0.0864879\tvalid_1's rmse: 0.181264\n",
      "[13900]\ttraining's rmse: 0.086115\tvalid_1's rmse: 0.18125\n",
      "[14000]\ttraining's rmse: 0.0857466\tvalid_1's rmse: 0.181239\n",
      "[14100]\ttraining's rmse: 0.0853791\tvalid_1's rmse: 0.181226\n",
      "[14200]\ttraining's rmse: 0.0850082\tvalid_1's rmse: 0.181212\n",
      "[14300]\ttraining's rmse: 0.084636\tvalid_1's rmse: 0.181194\n",
      "[14400]\ttraining's rmse: 0.0842886\tvalid_1's rmse: 0.181182\n",
      "[14500]\ttraining's rmse: 0.0839391\tvalid_1's rmse: 0.181177\n",
      "[14600]\ttraining's rmse: 0.0835838\tvalid_1's rmse: 0.181177\n",
      "[14700]\ttraining's rmse: 0.0832242\tvalid_1's rmse: 0.18116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14800]\ttraining's rmse: 0.082874\tvalid_1's rmse: 0.181143\n",
      "[14900]\ttraining's rmse: 0.0825218\tvalid_1's rmse: 0.181134\n",
      "[15000]\ttraining's rmse: 0.0821552\tvalid_1's rmse: 0.181116\n",
      "[15100]\ttraining's rmse: 0.0818006\tvalid_1's rmse: 0.181111\n",
      "[15200]\ttraining's rmse: 0.0814498\tvalid_1's rmse: 0.181096\n",
      "[15300]\ttraining's rmse: 0.0810945\tvalid_1's rmse: 0.18108\n",
      "[15400]\ttraining's rmse: 0.0807513\tvalid_1's rmse: 0.181065\n",
      "[15500]\ttraining's rmse: 0.0804191\tvalid_1's rmse: 0.181057\n",
      "[15600]\ttraining's rmse: 0.0800768\tvalid_1's rmse: 0.181045\n",
      "[15700]\ttraining's rmse: 0.0797437\tvalid_1's rmse: 0.181033\n",
      "[15800]\ttraining's rmse: 0.079397\tvalid_1's rmse: 0.181021\n",
      "[15900]\ttraining's rmse: 0.0790705\tvalid_1's rmse: 0.181007\n",
      "[16000]\ttraining's rmse: 0.0787398\tvalid_1's rmse: 0.180995\n",
      "[16100]\ttraining's rmse: 0.0784094\tvalid_1's rmse: 0.180986\n",
      "[16200]\ttraining's rmse: 0.0780756\tvalid_1's rmse: 0.180974\n",
      "[16300]\ttraining's rmse: 0.0777568\tvalid_1's rmse: 0.180975\n",
      "Early stopping, best iteration is:\n",
      "[16213]\ttraining's rmse: 0.0780344\tvalid_1's rmse: 0.180972\n",
      "1 76.5642490561 1903.79413857\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.355767\tvalid_1's rmse: 0.359075\n",
      "[200]\ttraining's rmse: 0.258317\tvalid_1's rmse: 0.263296\n",
      "[300]\ttraining's rmse: 0.225914\tvalid_1's rmse: 0.232048\n",
      "[400]\ttraining's rmse: 0.211331\tvalid_1's rmse: 0.218613\n",
      "[500]\ttraining's rmse: 0.202577\tvalid_1's rmse: 0.211032\n",
      "[600]\ttraining's rmse: 0.196089\tvalid_1's rmse: 0.205845\n",
      "[700]\ttraining's rmse: 0.190988\tvalid_1's rmse: 0.20198\n",
      "[800]\ttraining's rmse: 0.186815\tvalid_1's rmse: 0.199132\n",
      "[900]\ttraining's rmse: 0.183254\tvalid_1's rmse: 0.196896\n",
      "[1000]\ttraining's rmse: 0.180138\tvalid_1's rmse: 0.195152\n",
      "[1100]\ttraining's rmse: 0.177472\tvalid_1's rmse: 0.193798\n",
      "[1200]\ttraining's rmse: 0.175057\tvalid_1's rmse: 0.192678\n",
      "[1300]\ttraining's rmse: 0.172854\tvalid_1's rmse: 0.191751\n",
      "[1400]\ttraining's rmse: 0.170854\tvalid_1's rmse: 0.190974\n",
      "[1500]\ttraining's rmse: 0.169003\tvalid_1's rmse: 0.190294\n",
      "[1600]\ttraining's rmse: 0.167294\tvalid_1's rmse: 0.189764\n",
      "[1700]\ttraining's rmse: 0.165715\tvalid_1's rmse: 0.18931\n",
      "[1800]\ttraining's rmse: 0.164169\tvalid_1's rmse: 0.188902\n",
      "[1900]\ttraining's rmse: 0.162739\tvalid_1's rmse: 0.188557\n",
      "[2000]\ttraining's rmse: 0.161335\tvalid_1's rmse: 0.188232\n",
      "[2100]\ttraining's rmse: 0.159999\tvalid_1's rmse: 0.18793\n",
      "[2200]\ttraining's rmse: 0.158682\tvalid_1's rmse: 0.187645\n",
      "[2300]\ttraining's rmse: 0.157423\tvalid_1's rmse: 0.187371\n",
      "[2400]\ttraining's rmse: 0.156212\tvalid_1's rmse: 0.187125\n",
      "[2500]\ttraining's rmse: 0.155056\tvalid_1's rmse: 0.18688\n",
      "[2600]\ttraining's rmse: 0.153904\tvalid_1's rmse: 0.186654\n",
      "[2700]\ttraining's rmse: 0.152759\tvalid_1's rmse: 0.186436\n",
      "[2800]\ttraining's rmse: 0.151663\tvalid_1's rmse: 0.186232\n",
      "[2900]\ttraining's rmse: 0.150588\tvalid_1's rmse: 0.186038\n",
      "[3000]\ttraining's rmse: 0.149522\tvalid_1's rmse: 0.185886\n",
      "[3100]\ttraining's rmse: 0.148481\tvalid_1's rmse: 0.185748\n",
      "[3200]\ttraining's rmse: 0.147479\tvalid_1's rmse: 0.185595\n",
      "[3300]\ttraining's rmse: 0.146484\tvalid_1's rmse: 0.185466\n",
      "[3400]\ttraining's rmse: 0.145516\tvalid_1's rmse: 0.185328\n",
      "[3500]\ttraining's rmse: 0.144561\tvalid_1's rmse: 0.185178\n",
      "[3600]\ttraining's rmse: 0.143622\tvalid_1's rmse: 0.185039\n",
      "[3700]\ttraining's rmse: 0.142695\tvalid_1's rmse: 0.184918\n",
      "[3800]\ttraining's rmse: 0.141794\tvalid_1's rmse: 0.184777\n",
      "[3900]\ttraining's rmse: 0.140901\tvalid_1's rmse: 0.18467\n",
      "[4000]\ttraining's rmse: 0.140035\tvalid_1's rmse: 0.184571\n",
      "[4100]\ttraining's rmse: 0.139175\tvalid_1's rmse: 0.184468\n",
      "[4200]\ttraining's rmse: 0.138309\tvalid_1's rmse: 0.184373\n",
      "[4300]\ttraining's rmse: 0.137472\tvalid_1's rmse: 0.184273\n",
      "[4400]\ttraining's rmse: 0.13663\tvalid_1's rmse: 0.184178\n",
      "[4500]\ttraining's rmse: 0.135817\tvalid_1's rmse: 0.184089\n",
      "[4600]\ttraining's rmse: 0.135004\tvalid_1's rmse: 0.184007\n",
      "[4700]\ttraining's rmse: 0.134222\tvalid_1's rmse: 0.18396\n",
      "[4800]\ttraining's rmse: 0.133436\tvalid_1's rmse: 0.183885\n",
      "[4900]\ttraining's rmse: 0.132655\tvalid_1's rmse: 0.183789\n",
      "[5000]\ttraining's rmse: 0.131901\tvalid_1's rmse: 0.183725\n",
      "[5100]\ttraining's rmse: 0.131127\tvalid_1's rmse: 0.183647\n",
      "[5200]\ttraining's rmse: 0.130348\tvalid_1's rmse: 0.18356\n",
      "[5300]\ttraining's rmse: 0.129611\tvalid_1's rmse: 0.183487\n",
      "[5400]\ttraining's rmse: 0.128866\tvalid_1's rmse: 0.183426\n",
      "[5500]\ttraining's rmse: 0.128157\tvalid_1's rmse: 0.183362\n",
      "[5600]\ttraining's rmse: 0.127445\tvalid_1's rmse: 0.183286\n",
      "[5700]\ttraining's rmse: 0.126753\tvalid_1's rmse: 0.183217\n",
      "[5800]\ttraining's rmse: 0.12606\tvalid_1's rmse: 0.183143\n",
      "[5900]\ttraining's rmse: 0.125377\tvalid_1's rmse: 0.183092\n",
      "[6000]\ttraining's rmse: 0.124685\tvalid_1's rmse: 0.183023\n",
      "[6100]\ttraining's rmse: 0.124025\tvalid_1's rmse: 0.182964\n",
      "[6200]\ttraining's rmse: 0.123379\tvalid_1's rmse: 0.182925\n",
      "[6300]\ttraining's rmse: 0.122703\tvalid_1's rmse: 0.182873\n",
      "[6400]\ttraining's rmse: 0.122036\tvalid_1's rmse: 0.182826\n",
      "[6500]\ttraining's rmse: 0.121387\tvalid_1's rmse: 0.182777\n",
      "[6600]\ttraining's rmse: 0.120739\tvalid_1's rmse: 0.182721\n",
      "[6700]\ttraining's rmse: 0.120123\tvalid_1's rmse: 0.182682\n",
      "[6800]\ttraining's rmse: 0.119496\tvalid_1's rmse: 0.18263\n",
      "[6900]\ttraining's rmse: 0.118884\tvalid_1's rmse: 0.182586\n",
      "[7000]\ttraining's rmse: 0.118264\tvalid_1's rmse: 0.182532\n",
      "[7100]\ttraining's rmse: 0.117644\tvalid_1's rmse: 0.18248\n",
      "[7200]\ttraining's rmse: 0.117031\tvalid_1's rmse: 0.182438\n",
      "[7300]\ttraining's rmse: 0.116446\tvalid_1's rmse: 0.182382\n",
      "[7400]\ttraining's rmse: 0.115852\tvalid_1's rmse: 0.182341\n",
      "[7500]\ttraining's rmse: 0.115265\tvalid_1's rmse: 0.182294\n",
      "[7600]\ttraining's rmse: 0.114683\tvalid_1's rmse: 0.182255\n",
      "[7700]\ttraining's rmse: 0.114096\tvalid_1's rmse: 0.182213\n",
      "[7800]\ttraining's rmse: 0.113544\tvalid_1's rmse: 0.182186\n",
      "[7900]\ttraining's rmse: 0.112963\tvalid_1's rmse: 0.182154\n",
      "[8000]\ttraining's rmse: 0.112406\tvalid_1's rmse: 0.182111\n",
      "[8100]\ttraining's rmse: 0.111834\tvalid_1's rmse: 0.182077\n",
      "[8200]\ttraining's rmse: 0.11129\tvalid_1's rmse: 0.182056\n",
      "[8300]\ttraining's rmse: 0.110725\tvalid_1's rmse: 0.182028\n",
      "[8400]\ttraining's rmse: 0.110175\tvalid_1's rmse: 0.182004\n",
      "[8500]\ttraining's rmse: 0.109625\tvalid_1's rmse: 0.18198\n",
      "[8600]\ttraining's rmse: 0.10909\tvalid_1's rmse: 0.18195\n",
      "[8700]\ttraining's rmse: 0.108565\tvalid_1's rmse: 0.181915\n",
      "[8800]\ttraining's rmse: 0.108036\tvalid_1's rmse: 0.181886\n",
      "[8900]\ttraining's rmse: 0.107517\tvalid_1's rmse: 0.181862\n",
      "[9000]\ttraining's rmse: 0.106994\tvalid_1's rmse: 0.181829\n",
      "[9100]\ttraining's rmse: 0.106471\tvalid_1's rmse: 0.18181\n",
      "[9200]\ttraining's rmse: 0.105967\tvalid_1's rmse: 0.181787\n",
      "[9300]\ttraining's rmse: 0.105453\tvalid_1's rmse: 0.181767\n",
      "[9400]\ttraining's rmse: 0.104954\tvalid_1's rmse: 0.181755\n",
      "[9500]\ttraining's rmse: 0.10445\tvalid_1's rmse: 0.181735\n",
      "[9600]\ttraining's rmse: 0.103962\tvalid_1's rmse: 0.181709\n",
      "[9700]\ttraining's rmse: 0.103486\tvalid_1's rmse: 0.181691\n",
      "[9800]\ttraining's rmse: 0.102991\tvalid_1's rmse: 0.181677\n",
      "[9900]\ttraining's rmse: 0.102512\tvalid_1's rmse: 0.181649\n",
      "[10000]\ttraining's rmse: 0.102021\tvalid_1's rmse: 0.181628\n",
      "[10100]\ttraining's rmse: 0.101556\tvalid_1's rmse: 0.181606\n",
      "[10200]\ttraining's rmse: 0.101079\tvalid_1's rmse: 0.181595\n",
      "[10300]\ttraining's rmse: 0.100606\tvalid_1's rmse: 0.181577\n",
      "[10400]\ttraining's rmse: 0.100134\tvalid_1's rmse: 0.18156\n",
      "[10500]\ttraining's rmse: 0.0996695\tvalid_1's rmse: 0.181544\n",
      "[10600]\ttraining's rmse: 0.0992161\tvalid_1's rmse: 0.181526\n",
      "[10700]\ttraining's rmse: 0.0987523\tvalid_1's rmse: 0.18151\n",
      "[10800]\ttraining's rmse: 0.0983061\tvalid_1's rmse: 0.181494\n",
      "[10900]\ttraining's rmse: 0.0978647\tvalid_1's rmse: 0.181484\n",
      "[11000]\ttraining's rmse: 0.0974139\tvalid_1's rmse: 0.18148\n",
      "[11100]\ttraining's rmse: 0.0969637\tvalid_1's rmse: 0.181473\n",
      "[11200]\ttraining's rmse: 0.0965173\tvalid_1's rmse: 0.181465\n",
      "[11300]\ttraining's rmse: 0.0960825\tvalid_1's rmse: 0.181454\n",
      "[11400]\ttraining's rmse: 0.0956383\tvalid_1's rmse: 0.181432\n",
      "[11500]\ttraining's rmse: 0.0952088\tvalid_1's rmse: 0.181418\n",
      "[11600]\ttraining's rmse: 0.0947708\tvalid_1's rmse: 0.181404\n",
      "[11700]\ttraining's rmse: 0.094345\tvalid_1's rmse: 0.181397\n",
      "[11800]\ttraining's rmse: 0.0939199\tvalid_1's rmse: 0.181383\n",
      "[11900]\ttraining's rmse: 0.0934964\tvalid_1's rmse: 0.181359\n",
      "[12000]\ttraining's rmse: 0.0930826\tvalid_1's rmse: 0.181343\n",
      "[12100]\ttraining's rmse: 0.0926484\tvalid_1's rmse: 0.181328\n",
      "[12200]\ttraining's rmse: 0.0922341\tvalid_1's rmse: 0.181314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12300]\ttraining's rmse: 0.0918229\tvalid_1's rmse: 0.181298\n",
      "[12400]\ttraining's rmse: 0.0914249\tvalid_1's rmse: 0.181285\n",
      "[12500]\ttraining's rmse: 0.0910178\tvalid_1's rmse: 0.181273\n",
      "[12600]\ttraining's rmse: 0.0906071\tvalid_1's rmse: 0.181259\n",
      "[12700]\ttraining's rmse: 0.0902135\tvalid_1's rmse: 0.181238\n",
      "[12800]\ttraining's rmse: 0.0898119\tvalid_1's rmse: 0.181221\n",
      "[12900]\ttraining's rmse: 0.08942\tvalid_1's rmse: 0.181213\n",
      "[13000]\ttraining's rmse: 0.0890186\tvalid_1's rmse: 0.181203\n",
      "[13100]\ttraining's rmse: 0.0886416\tvalid_1's rmse: 0.18119\n",
      "[13200]\ttraining's rmse: 0.0882393\tvalid_1's rmse: 0.181166\n",
      "[13300]\ttraining's rmse: 0.0878511\tvalid_1's rmse: 0.18115\n",
      "[13400]\ttraining's rmse: 0.0874504\tvalid_1's rmse: 0.181136\n",
      "[13500]\ttraining's rmse: 0.0870678\tvalid_1's rmse: 0.181118\n",
      "[13600]\ttraining's rmse: 0.0866832\tvalid_1's rmse: 0.181105\n",
      "[13700]\ttraining's rmse: 0.0862959\tvalid_1's rmse: 0.181086\n",
      "[13800]\ttraining's rmse: 0.0859205\tvalid_1's rmse: 0.181073\n",
      "[13900]\ttraining's rmse: 0.0855493\tvalid_1's rmse: 0.181058\n",
      "[14000]\ttraining's rmse: 0.0851762\tvalid_1's rmse: 0.181048\n",
      "[14100]\ttraining's rmse: 0.0847983\tvalid_1's rmse: 0.18104\n",
      "[14200]\ttraining's rmse: 0.0844313\tvalid_1's rmse: 0.181026\n",
      "[14300]\ttraining's rmse: 0.0840712\tvalid_1's rmse: 0.181015\n",
      "[14400]\ttraining's rmse: 0.0837017\tvalid_1's rmse: 0.180998\n",
      "[14500]\ttraining's rmse: 0.083349\tvalid_1's rmse: 0.180991\n",
      "[14600]\ttraining's rmse: 0.0829912\tvalid_1's rmse: 0.180982\n",
      "[14700]\ttraining's rmse: 0.0826388\tvalid_1's rmse: 0.180976\n",
      "[14800]\ttraining's rmse: 0.0822944\tvalid_1's rmse: 0.180961\n",
      "[14900]\ttraining's rmse: 0.081953\tvalid_1's rmse: 0.180948\n",
      "[15000]\ttraining's rmse: 0.081614\tvalid_1's rmse: 0.180938\n",
      "[15100]\ttraining's rmse: 0.0812685\tvalid_1's rmse: 0.180937\n",
      "[15200]\ttraining's rmse: 0.0809265\tvalid_1's rmse: 0.180932\n",
      "[15300]\ttraining's rmse: 0.0805749\tvalid_1's rmse: 0.180924\n",
      "[15400]\ttraining's rmse: 0.0802277\tvalid_1's rmse: 0.180918\n",
      "[15500]\ttraining's rmse: 0.0798815\tvalid_1's rmse: 0.180909\n",
      "[15600]\ttraining's rmse: 0.0795377\tvalid_1's rmse: 0.180903\n",
      "[15700]\ttraining's rmse: 0.0791979\tvalid_1's rmse: 0.180901\n",
      "[15800]\ttraining's rmse: 0.0788578\tvalid_1's rmse: 0.180897\n",
      "[15900]\ttraining's rmse: 0.0785335\tvalid_1's rmse: 0.180896\n",
      "Early stopping, best iteration is:\n",
      "[15898]\ttraining's rmse: 0.0785402\tvalid_1's rmse: 0.180895\n",
      "2 74.5009291896 181.354438443\n",
      "Iteration : 7\n",
      "60.877360886\n",
      "148.138648862\n"
     ]
    }
   ],
   "source": [
    "# reloadImagesAndPreprocess = 0\n",
    "\n",
    "numPreprocessing = 8\n",
    "ttaPredictions = np.zeros([numPreprocessing,nSplits,N-M])\n",
    "\n",
    "for curTTA in range(8):\n",
    "    Xg3f, Xg3fNames = getFeatures(curTTA)\n",
    "    models, cvtrainpreds, xis, linxis = getModels(Xg3f[:M], Y[:M])\n",
    "\n",
    "    ppreds = np.zeros([len(models),N-M])\n",
    "    for i, m in zip(range(len(models)),models):\n",
    "        mp = m.predict(Xg3f[M:])\n",
    "        ppreds[i] = mp\n",
    "\n",
    "    cvpred = ppreds.mean(axis=0)\n",
    "\n",
    "    print(\"Iteration : {}\".format(curTTA))\n",
    "    chiSq = xi2(Y[M:],cvpred,err[M:])\n",
    "    linChiSq = xi2(10**Y[M:],10**cvpred,err_lin[M:])\n",
    "    print(chiSq)\n",
    "    print(linChiSq)\n",
    "        \n",
    "    ttaPredictions[curTTA] = ppreds\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 7886)\n",
      "[[ 10.74889786  10.75988952  10.75947786]\n",
      " [ 10.68916076  10.71162126  10.69799881]\n",
      " [ 10.75648516  10.76126428  10.74767171]\n",
      " [ 10.74892393  10.69078245  10.7360299 ]\n",
      " [ 10.71231419  10.70881036  10.7239366 ]\n",
      " [ 10.72693501  10.74375724  10.74594588]\n",
      " [ 10.75396913  10.72601924  10.75285038]\n",
      " [ 10.75230014  10.74323709  10.74048101]]\n"
     ]
    }
   ],
   "source": [
    "print(ttaPredictions.shape)\n",
    "print(ttaPredictions[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 24\n",
      "57.2063131605\n",
      "150.61448157\n"
     ]
    }
   ],
   "source": [
    "cvpred = ttaPredictions.mean(axis=0).mean(axis=0)\n",
    "\n",
    "print(\"Iterations : {}\".format(nSplits*(curTTA+1)))\n",
    "chiSq = xi2(Y[M:],cvpred,err[M:])\n",
    "linChiSq = xi2(10**Y[M:],10**cvpred,err_lin[M:])\n",
    "print(chiSq)\n",
    "print(linChiSq)\n",
    "\n",
    "# ttaPredictions[curTTA] = ppreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x²:60.588125 lin x²:137.629595 [64.039406 144.898139 62.708936 141.106599 62.895182 139.109267 ]\n",
      "Iteration 1: x²:61.515723 lin x²:191.692553 [64.418611 194.725494 61.894836 191.105178 65.623192 199.953488 ]\n",
      "Iteration 2: x²:59.844921 lin x²:140.153554 [63.481772 145.833588 61.750386 152.086850 62.545139 140.719047 ]\n",
      "Iteration 3: x²:60.329488 lin x²:146.330042 [63.639371 140.982973 63.348567 159.867566 62.602334 157.054926 ]\n",
      "Iteration 4: x²:60.041728 lin x²:175.392259 [62.796371 155.328960 63.462293 227.907252 62.226022 177.527529 ]\n",
      "Iteration 5: x²:59.900297 lin x²:186.845311 [61.822557 196.103650 66.196268 176.200304 61.694322 208.033308 ]\n",
      "Iteration 6: x²:60.506375 lin x²:147.028555 [63.711979 144.312326 62.903211 167.537073 62.735615 145.420870 ]\n",
      "Iteration 7: x²:60.877361 lin x²:148.138649 [63.361428 163.313007 66.902758 150.695359 62.175337 149.908300 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(ttaPredictions.shape[0]):\n",
    "    cvpred = ttaPredictions[i].mean(axis=0)\n",
    "    chiSq = xi2(Y[M:],cvpred,err[M:])\n",
    "    linChiSq = xi2(10**Y[M:],10**cvpred,err_lin[M:])\n",
    "    print(\"Iteration {}: x²:{:2f} lin x²:{:2f} [\".format(i,chiSq,linChiSq), end='')\n",
    "    \n",
    "    for j in range(ttaPredictions.shape[1]):\n",
    "        cvpred = ttaPredictions[i,j]\n",
    "        chiSq = xi2(Y[M:],cvpred,err[M:])\n",
    "        linChiSq = xi2(10**Y[M:],10**cvpred,err_lin[M:])\n",
    "        print(\"{:2f} {:2f} \".format(chiSq, linChiSq), end='')\n",
    "        \n",
    "    print(\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values over all 24 iterations : 57.206313160518896,  150.6144815704485\n"
     ]
    }
   ],
   "source": [
    "cvpred = ttaPredictions.mean(axis=0).mean(axis=0)\n",
    "\n",
    "chiSq = xi2(Y[M:],cvpred,err[M:])\n",
    "linChiSq = xi2(10**Y[M:],10**cvpred,err_lin[M:])\n",
    "print(\"Values over all {} iterations : {},  {}\".format(nSplits*(curTTA+1), chiSq, linChiSq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(ttaPredictions.mean(0).mean(0)[3])\n",
    "# print(ttaPredictions[:,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diehere' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0df1533dee61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiehere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'diehere' is not defined"
     ]
    }
   ],
   "source": [
    "diehere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_preproc('1237662637444694216',0))\n",
    "plt.figure()\n",
    "plt.imshow(img_preproc('1237662637444694216',1))\n",
    "plt.figure()\n",
    "plt.imshow(img_preproc('1237662637444694216',2))\n",
    "plt.figure()\n",
    "plt.imshow(img_preproc('1237662637444694216',5))\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Xg3f.shape)\n",
    "print(df.shape)\n",
    "\n",
    "t1 = df.SDSS_ID.values[:N].reshape(N,1)\n",
    "t2 = Xg3f[:N,:]\n",
    "t3 = np.concatenate((t1,t2), axis=1)\n",
    "np.save(prefixThisRound+str(N), t3)\n",
    "np.save(prefixThisRound+str(N) + 'featurenames', Xg3fNames)\n",
    "del t1, t2, t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# if os.path.isfile(prefixThisRound +str(N)+'.npy'):\n",
    "#     t3 = np.load(prefixThisRound+str(N)+'.npy')\n",
    "#     Xg3fNames = np.load(prefixThisRound+str(N) + 'featurenames' + '.npy', )\n",
    "# Xg3f = t3[:,1:]\n",
    "# Xg3f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xg3f = t3[:,1:]\n",
    "# Xg3f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the train/test datasets for lgbm regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def lgb_rmsle(y_pred,y_true):\n",
    "   return 'rmsle', mean_squared_error(np.log1p(y_true.get_label()),np.log1p(y_pred)), False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Same but with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(linxis)\n",
    "cvtrainpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppreds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(Y[M:]-cvpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badID = np.argmax(Y[M:]-cvpred)\n",
    "print(Y[badID])\n",
    "print(df.loc[badID])\n",
    "# df['cvpred'] = cvpred\n",
    "# df['lincvpred'] = 10**cvpred\n",
    "# df['deltapred'] = abs(Y[M:]-cvpred)\n",
    "# df['lindeltapred'] = 10**Y[M:]-10**cvpred\n",
    "\n",
    "drawOneGalaxy(df.SDSS_ID[badID])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(prefixThisRound)\n",
    "\n",
    "# df.to_csv(prefixThisRound + '-CVResultDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='deltapred', ascending=False).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=Y, y=cvpred, kind='reg')\n",
    "plt.title('log reg')\n",
    "sns.jointplot(x=Y, y=cvpred, kind='resid')\n",
    "plt.title('log residuals')\n",
    "\n",
    "sns.jointplot(x=10**Y, y=10**cvpred, kind='reg')\n",
    "plt.title('log reg')\n",
    "sns.jointplot(x=10**Y, y=10**cvpred, kind='resid')\n",
    "plt.title('log residuals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Xg3f[:,3067])\n",
    "# plt.hist(Xg3f[:,3067],bins=100)\n",
    "np.argmax(Xg3f[:,3067])\n",
    "df.iloc[59964,:]\n",
    "\n",
    "drawOneGalaxy('1237665015776477192')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model is trained, values are obtained, saving and result analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# break here, save the stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = model.feature_importance()\n",
    "print(arr.shape)\n",
    "np.argmax(arr)\n",
    "# print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fimport = list(zip(arr, Xg3fNames))\n",
    "sorted(fimport, key=lambda x: x[0], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=Y[M:], y=pred, kind='kde')\n",
    "plt.title('log kde')\n",
    "sns.jointplot(x=Y[M:], y=pred, kind='reg')\n",
    "plt.title('log reg')\n",
    "sns.jointplot(x=Y[M:], y=pred, kind='resid')\n",
    "plt.title('log residuals')\n",
    "\n",
    "\n",
    "sns.jointplot(x=10**Y[M:], y=10**pred, kind='kde')\n",
    "plt.title('lin kde')\n",
    "sns.jointplot(x=10**Y[M:], y=10**pred, kind='reg')\n",
    "plt.title('lin joint')\n",
    "sns.jointplot(x=10**Y[M:], y=10**pred, kind='resid')\n",
    "plt.title('lin joint')\n",
    "# plt.scatter(x=10**Y[M:], y=10**pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['logMstar']>=12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(10**Y[M:]-10**pred)\n",
    "worstID = np.argmax(10**Y[M:]-10**pred)\n",
    "\n",
    "print(Y[M+worstID], pred[worstID])\n",
    "print(10**Y[M+worstID], 10**pred[worstID])\n",
    "print(df.loc[M+worstID,:]) # 1237664105244524770, 1237661851469611060 1237654626789163411\n",
    "\n",
    "# pred[worstID] = Y[M+worstID]\n",
    "\n",
    "drawOneGalaxy(df.loc[M+worstID,'SDSS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning: predictions from here on will contain data from training set: \n",
    "pred = model.predict(Xg3f[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pred'] = pred\n",
    "df['lin_pred'] = 10**pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Y[:]-pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=df, x='lin_pred', y='lin_mass', kind='reg')\n",
    "plt.title('lin kde')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:astrohack]",
   "language": "python",
   "name": "conda-env-astrohack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
