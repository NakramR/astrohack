{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.collections\n",
    "\n",
    "from matplotlib.transforms import Affine2D\n",
    "import mpl_toolkits.axisartist.floating_axes as floating_axes\n",
    "import matplotlib.collections\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from tqdm import *\n",
    "# nice progress bars otherwise\n",
    "# def tqdm(x):\n",
    "#     yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO, improvement ideas\n",
    "\n",
    "# TPOT python auto ml\n",
    "# use log(flux) as input\n",
    "# investigate highest errors (argmax(xi²))\n",
    "\n",
    "# kfold integration in place of CV\n",
    "# TTA\n",
    "# CNN segmentation cleanup \n",
    "# resnet v2 ( https://github.com/myutwo150/keras-inception-resnet-v2/blob/master/inception_resnet_v2.py )\n",
    "# custom CNN features\n",
    "# CV2 resize cubic interpolation \n",
    "\n",
    "# Serge:\n",
    "# essayer de remplacer lgb par un Deep NN keras (vu la quantité de donnée)\n",
    "\n",
    "\n",
    "#done\n",
    "# lgbm eval rmsle instead of rmse\n",
    "# add image size as feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# memory debug function\n",
    "\n",
    "import sys\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "mm = sorted([(x, sys.getsizeof(globals().get(x)),\"{:,}\".format(sys.getsizeof(globals().get(x)))) \n",
    "        for x in dir() \n",
    "           if not x.startswith('_') \n",
    "#         and x not in sys.modules\n",
    "        and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data folder set up and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFolder = 'data/mainData/'\n",
    "plt.ion()\n",
    "\n",
    "runNameParams = []\n",
    "runNameParams.append('newSource')\n",
    "# print(runNameParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(id):\n",
    "    if id[-4:] == '.npy':\n",
    "        X = np.load(dataFolder+id)\n",
    "    elif os.path.isfile(dataFolder+id+'.npy'):\n",
    "        X = np.load(dataFolder+id + '.npy')\n",
    "    elif os.path.isfile(dataFolder+id+'-g.csv'):\n",
    "        X = np.genfromtxt(dataFolder+id+'-g.csv', delimiter=\",\")\n",
    "    else:\n",
    "        X = None\n",
    "\n",
    "    X = np.float32(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80306\n"
     ]
    }
   ],
   "source": [
    "dataFileList = []\n",
    "\n",
    "directory = os.fsencode(dataFolder)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".npy\") or filename.endswith(\".py\"): \n",
    "        dataFileList.append(filename)\n",
    "        \n",
    "print(len(dataFileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check a few random images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drawOneGalaxy(galaxyID):\n",
    "    oneImageData = read_image(galaxyID)\n",
    "    print(galaxyID)\n",
    "\n",
    "    # new image\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    #set grid spec for the 4 graphs\n",
    "    gs = gridspec.GridSpec(2, 2, width_ratios=[5, 1], height_ratios=[1,5]) \n",
    "\n",
    "    #draw image\n",
    "    plt.title(\"raw\")\n",
    "    plt.subplot(gs[2])\n",
    "    plt.imshow(oneImageData)\n",
    "    \n",
    "    # horizontal (top) sum\n",
    "    plt.subplot(gs[0])\n",
    "    plt.title(galaxyID)\n",
    "    plt.plot(oneImageData.sum(axis=0))\n",
    "\n",
    "    # vertical (bottom-right) sum\n",
    "    ax = plt.subplot(gs[3])\n",
    "    ss = np.flip(oneImageData.sum(axis=1),axis=0)\n",
    "    plt.scatter(x=ss, y=list(range(oneImageData.shape[1])), s=1)\n",
    "    lines = [[(ss[i-1],i-1),(ss[i],i)] for i in range(1,len(ss))]\n",
    "    lc = matplotlib.collections.LineCollection(lines)\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    #value histogram\n",
    "    plt.subplot(gs[1])\n",
    "    plt.hist(oneImageData.reshape(-1), bins=100)\n",
    "    plt.yscale('log')    \n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #add small log of image\n",
    "    ax = fig.add_axes([0.02,0.6,.2,.2])\n",
    "    plt.imshow(np.log(oneImageData-oneImageData.min()+0.00001))\n",
    "\n",
    "for _ in range(5):\n",
    "    i = random.randint(0,len(dataFileList))\n",
    "#     oneImageData = np.load(dataFolder+'1237648704067273096.npy')\n",
    "#     drawOneGalaxy(dataFileList[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "issuesImages = ['1237658298983055529.npy','1237660634917634181.npy','1237654879654772871.npy','1237654953205170487.npy','1237651249884627014.npy','1237651754022207627.npy',\n",
    " '1237654669736018114.npy','1237655471824568727.npy','1237665530643808416.npy','1237658611444088911.npy','1237667255070490937.npy',\n",
    " '1237665531177795774.npy','1237645943975837722.npy','1237658425161220139.npy', '1237665129087435003.npy','1237657873792172224.npy',\n",
    " '1237660240313778264.npy','1237668298201432152.npy', '1237662264316264518.npy','1237657630042227294.npy','1237651754550624376.npy',\n",
    " '1237667211059986578.npy','1237655470208582145.npy']\n",
    "\n",
    "# for image in issuesImages:\n",
    "#     drawOneGalaxy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# ML part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/astrohack/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import xgboost as xgb\n",
    "from keras.applications import *\n",
    "import lightgbm as lgbm\n",
    "import scipy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xi2(true,pred,error):\n",
    "    s=np.mean((true-pred)**2/error**2)\n",
    "    return s\n",
    "\n",
    "def normalize_image(Xg):\n",
    "    Xg -= np.mean(Xg)\n",
    "    Xg /= np.std(Xg)\n",
    "    \n",
    "    return Xg\n",
    "\n",
    "def crop_image(Xg):\n",
    "    h,w = Xg.shape\n",
    "    cy, cx = h//2, w//2\n",
    "    dy, dx = int(cy*0.75), int(cx*0.75) # crop a bit around center\n",
    "    Xg = Xg[cy-dy:cy+dy,cx-dx:cx+dx]\n",
    "    \n",
    "    return Xg\n",
    "\n",
    "def img_preprocnoread(Xg, preProcNum = 0):\n",
    "#    Xg = cleanupImage(id)\n",
    "\n",
    "    if ( preProcNum != 0):\n",
    "        if preProcNum & 4: # rotate\n",
    "            Xg = np.rot90(Xg)\n",
    "            \n",
    "        if preProcNum %4 == 1: # vflip\n",
    "            Xg = np.flip(Xg,0)\n",
    "        elif preProcNum %4 == 2: # hflip\n",
    "            Xg = np.flip(Xg,1)\n",
    "        elif preProcNum %4 == 3: # hflip+vflip\n",
    "            Xg = np.flip(np.flip(Xg,1),0)\n",
    "\n",
    "    Xg = np.log1p(Xg - Xg.min())\n",
    "    Xg = normalize_image(Xg)\n",
    "    Xg = crop_image(Xg)\n",
    "\n",
    "    \n",
    "    if Xg.shape[0] >= 224:\n",
    "        Xgr = cv2.resize(Xg,(224,224), cv2.INTER_AREA)\n",
    "    else:\n",
    "        Xgr = cv2.resize(Xg,(224,224), cv2.INTER_CUBIC)\n",
    "    \n",
    "    return Xgr\n",
    "    \n",
    "def img_preproc(id, preProcNum = 0):\n",
    "    Xg = read_image(id)\n",
    "    return img_preprocnoread(Xg,preProcNum)\n",
    "\n",
    "runNameParams.append('ReadLog1pNormCrop.75')\n",
    "# preprocName = \"ReadNormCrop.5\"\n",
    "# x = img_preproc('1237662637444694216')\n",
    "x = img_preproc(dataFileList[random.randint(0,len(dataFileList))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.804691 27.1617\n",
      "[[-0.17632617 -0.12471178 -0.02148302  0.01133325 -0.02626297]\n",
      " [-0.17966296 -0.15230891 -0.0976008  -0.08636351 -0.11859703]\n",
      " [-0.18633655 -0.20750314 -0.24983639 -0.28175703 -0.30326512]\n",
      " [-0.22135624 -0.25732577 -0.32926491 -0.38014516 -0.40996665]\n",
      " [-0.28472203 -0.30177683 -0.33588639 -0.38152796 -0.43870151]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAEICAYAAACtc9bVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\novDfxeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefe2cfb160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x.min(), x.max())\n",
    "print(x[0:5,0:5])\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('histogram of values after image preprocessing')\n",
    "plt.hist(x.reshape(-1), bins=100)\n",
    "\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet',include_top=True,input_shape=(224,224,3))\n",
    "r50 = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDSS_ID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>logMst</th>\n",
       "      <th>err_l</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>D_Mpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1237662635825954925</td>\n",
       "      <td>210.95489999999998</td>\n",
       "      <td>12.64455</td>\n",
       "      <td>0.33113110693986714</td>\n",
       "      <td>0.1029</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>42.47806067869379</td>\n",
       "      <td>440.99999325616017</td>\n",
       "      <td>0.8552113203991983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1237652947452297303</td>\n",
       "      <td>0.84015</td>\n",
       "      <td>-9.98328</td>\n",
       "      <td>0.5248074948227709</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>11.312</td>\n",
       "      <td>0.016</td>\n",
       "      <td>50.181626715917524</td>\n",
       "      <td>328.7142940929958</td>\n",
       "      <td>0.6374607478101917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1237652899137912944</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>-11.17802</td>\n",
       "      <td>0.6165950323262803</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>9.708</td>\n",
       "      <td>0.071</td>\n",
       "      <td>29.440699795795908</td>\n",
       "      <td>164.1428577048438</td>\n",
       "      <td>0.3183148122868964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1237661433779716229</td>\n",
       "      <td>211.48905000000002</td>\n",
       "      <td>43.88251</td>\n",
       "      <td>0.7585775667003197</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.062</td>\n",
       "      <td>31.869792393005813</td>\n",
       "      <td>144.4285735487938</td>\n",
       "      <td>0.28008379359836033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1237652944786555077</td>\n",
       "      <td>1.48395</td>\n",
       "      <td>16.13445</td>\n",
       "      <td>0.3388441338170015</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.04</td>\n",
       "      <td>38.39840364463448</td>\n",
       "      <td>389.571413397789</td>\n",
       "      <td>0.7554782039377076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SDSS_ID                  RA        DEC                  D25  \\\n",
       "10  1237662635825954925  210.95489999999998   12.64455  0.33113110693986714   \n",
       "11  1237652947452297303             0.84015   -9.98328   0.5248074948227709   \n",
       "12  1237652899137912944              1.0026  -11.17802   0.6165950323262803   \n",
       "13  1237661433779716229  211.48905000000002   43.88251   0.7585775667003197   \n",
       "14  1237652944786555077             1.48395   16.13445   0.3388441338170015   \n",
       "\n",
       "    redshi  logMst  err_l         GalSize_kpc               D_Mpc  \\\n",
       "10  0.1029   -99.0  -99.0   42.47806067869379  440.99999325616017   \n",
       "11  0.0767  11.312  0.016  50.181626715917524   328.7142940929958   \n",
       "12  0.0383   9.708  0.071  29.440699795795908   164.1428577048438   \n",
       "13  0.0337    9.26  0.062  31.869792393005813   144.4285735487938   \n",
       "14  0.0909    10.7   0.04   38.39840364463448    389.571413397789   \n",
       "\n",
       "              d_pix_kpc  \n",
       "10   0.8552113203991983  \n",
       "11   0.6374607478101917  \n",
       "12   0.3183148122868964  \n",
       "13  0.28008379359836033  \n",
       "14   0.7554782039377076  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_fwf('metaData.dat', comment = '#')\n",
    "df.columns = df.iloc[9,:].values\n",
    "df = df[10:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "      <th>logMstar</th>\n",
       "      <th>err_logMstar</th>\n",
       "      <th>Distance</th>\n",
       "      <th>lin_mass</th>\n",
       "      <th>lin_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>187742.000000</td>\n",
       "      <td>1.877420e+05</td>\n",
       "      <td>1.877420e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>184.527190</td>\n",
       "      <td>24.898677</td>\n",
       "      <td>0.445798</td>\n",
       "      <td>0.074652</td>\n",
       "      <td>38.318105</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>9.081941</td>\n",
       "      <td>-1.313631</td>\n",
       "      <td>319.936358</td>\n",
       "      <td>7.877701e+10</td>\n",
       "      <td>4.648110e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.620064</td>\n",
       "      <td>19.374103</td>\n",
       "      <td>0.168006</td>\n",
       "      <td>0.040143</td>\n",
       "      <td>18.942158</td>\n",
       "      <td>0.333632</td>\n",
       "      <td>12.706553</td>\n",
       "      <td>11.469736</td>\n",
       "      <td>172.041273</td>\n",
       "      <td>9.461819e+10</td>\n",
       "      <td>5.529011e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.008250</td>\n",
       "      <td>-11.252830</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>4.034125</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>42.857142</td>\n",
       "      <td>1.000000e-99</td>\n",
       "      <td>-2.279559e-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>152.349938</td>\n",
       "      <td>8.662358</td>\n",
       "      <td>0.346737</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>25.157782</td>\n",
       "      <td>0.366519</td>\n",
       "      <td>10.191000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>189.000006</td>\n",
       "      <td>1.552387e+10</td>\n",
       "      <td>1.144774e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>185.824575</td>\n",
       "      <td>23.197910</td>\n",
       "      <td>0.389045</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>35.525868</td>\n",
       "      <td>0.573465</td>\n",
       "      <td>10.693000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>295.714278</td>\n",
       "      <td>4.931738e+10</td>\n",
       "      <td>2.906879e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>222.151537</td>\n",
       "      <td>39.835143</td>\n",
       "      <td>0.478630</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>48.283920</td>\n",
       "      <td>0.801189</td>\n",
       "      <td>11.032000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>413.142858</td>\n",
       "      <td>1.076465e+11</td>\n",
       "      <td>6.027530e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.994900</td>\n",
       "      <td>70.133250</td>\n",
       "      <td>10.964781</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>1373.931687</td>\n",
       "      <td>2.490003</td>\n",
       "      <td>12.326000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1284.000022</td>\n",
       "      <td>2.118361e+12</td>\n",
       "      <td>1.727792e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RA            DEC            D25         redshi  \\\n",
       "count  187742.000000  187742.000000  187742.000000  187742.000000   \n",
       "mean      184.527190      24.898677       0.445798       0.074652   \n",
       "std        61.620064      19.374103       0.168006       0.040143   \n",
       "min         0.008250     -11.252830       0.316228       0.010000   \n",
       "25%       152.349938       8.662358       0.346737       0.044100   \n",
       "50%       185.824575      23.197910       0.389045       0.069000   \n",
       "75%       222.151537      39.835143       0.478630       0.096400   \n",
       "max       359.994900      70.133250      10.964781       0.299600   \n",
       "\n",
       "         GalSize_kpc      d_pix_kpc       logMstar   err_logMstar  \\\n",
       "count  187742.000000  187742.000000  187742.000000  187742.000000   \n",
       "mean       38.318105       0.620438       9.081941      -1.313631   \n",
       "std        18.942158       0.333632      12.706553      11.469736   \n",
       "min         4.034125       0.083111     -99.000000     -99.000000   \n",
       "25%        25.157782       0.366519      10.191000       0.021000   \n",
       "50%        35.525868       0.573465      10.693000       0.029000   \n",
       "75%        48.283920       0.801189      11.032000       0.041000   \n",
       "max      1373.931687       2.490003      12.326000       0.800000   \n",
       "\n",
       "            Distance      lin_mass       lin_err  \n",
       "count  187742.000000  1.877420e+05  1.877420e+05  \n",
       "mean      319.936358  7.877701e+10  4.648110e+09  \n",
       "std       172.041273  9.461819e+10  5.529011e+09  \n",
       "min        42.857142  1.000000e-99 -2.279559e-97  \n",
       "25%       189.000006  1.552387e+10  1.144774e+09  \n",
       "50%       295.714278  4.931738e+10  2.906879e+09  \n",
       "75%       413.142858  1.076465e+11  6.027530e+09  \n",
       "max      1284.000022  2.118361e+12  1.727792e+11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RA'] = df['RA'].apply(np.float64)\n",
    "df['DEC'] = df['DEC'].apply(np.float64)\n",
    "df['D25'] = df['D25'].apply(np.float64)\n",
    "df['redshi'] = df['redshi'].apply(np.float64)\n",
    "df['logMstar'] = df['logMst'].apply(np.float64) #renamed\n",
    "df['err_logMstar'] = df['err_l'].apply(np.float64) #renamed\n",
    "df['GalSize_kpc'] = df['GalSize_kpc'].apply(np.float64)\n",
    "df['Distance'] = df['D_Mpc'].apply(np.float64) #renamed\n",
    "df['d_pix_kpc'] = df['d_pix_kpc'].apply(np.float64)\n",
    "\n",
    "df['lin_mass'] = np.power(10, df.logMstar)\n",
    "df['lin_err'] = df['lin_mass'] * np.log(10) * df.err_logMstar\n",
    "\n",
    "df = df.drop(['logMst','err_l'], axis=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file present: 80306\n",
      "data file missing: 107436\n"
     ]
    }
   ],
   "source": [
    "# df.SDSS_ID[:20].apply(lambda x: x)\n",
    "df['hasFile'] = df.SDSS_ID.apply(lambda x: os.path.isfile(dataFolder+x+'.npy'))\n",
    "\n",
    "print(\"data file present:\", len(df[df['hasFile']==True]))\n",
    "print(\"data file missing:\", len(df[df['hasFile']==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter images that have no known mass, no actual image, or with an unknown error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "      <th>logMstar</th>\n",
       "      <th>err_logMstar</th>\n",
       "      <th>Distance</th>\n",
       "      <th>lin_mass</th>\n",
       "      <th>lin_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>78851.000000</td>\n",
       "      <td>7.885100e+04</td>\n",
       "      <td>7.885100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>185.303775</td>\n",
       "      <td>25.672447</td>\n",
       "      <td>0.557644</td>\n",
       "      <td>0.058701</td>\n",
       "      <td>38.101843</td>\n",
       "      <td>0.487867</td>\n",
       "      <td>10.558197</td>\n",
       "      <td>0.031070</td>\n",
       "      <td>251.574576</td>\n",
       "      <td>7.898269e+10</td>\n",
       "      <td>4.398954e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.111612</td>\n",
       "      <td>18.944782</td>\n",
       "      <td>0.194465</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>19.838329</td>\n",
       "      <td>0.270663</td>\n",
       "      <td>0.654456</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>139.570856</td>\n",
       "      <td>9.624108e+10</td>\n",
       "      <td>5.552716e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009450</td>\n",
       "      <td>-11.238420</td>\n",
       "      <td>0.407380</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>5.248929</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>7.376000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>42.857142</td>\n",
       "      <td>2.376840e+07</td>\n",
       "      <td>4.756699e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>154.486425</td>\n",
       "      <td>9.795145</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>24.390653</td>\n",
       "      <td>0.280915</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>144.857136</td>\n",
       "      <td>1.584893e+10</td>\n",
       "      <td>1.023221e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>186.753000</td>\n",
       "      <td>24.400580</td>\n",
       "      <td>0.489779</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>35.043089</td>\n",
       "      <td>0.434670</td>\n",
       "      <td>10.692000</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>224.142852</td>\n",
       "      <td>4.920395e+10</td>\n",
       "      <td>2.693666e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>221.979375</td>\n",
       "      <td>40.093400</td>\n",
       "      <td>0.602560</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>47.500516</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>323.999992</td>\n",
       "      <td>1.071519e+11</td>\n",
       "      <td>5.603185e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>359.994900</td>\n",
       "      <td>70.133250</td>\n",
       "      <td>10.964781</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>1373.931687</td>\n",
       "      <td>2.450110</td>\n",
       "      <td>12.326000</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>1263.428628</td>\n",
       "      <td>2.118361e+12</td>\n",
       "      <td>1.414535e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RA           DEC           D25        redshi   GalSize_kpc  \\\n",
       "count  78851.000000  78851.000000  78851.000000  78851.000000  78851.000000   \n",
       "mean     185.303775     25.672447      0.557644      0.058701     38.101843   \n",
       "std       57.111612     18.944782      0.194465      0.032567     19.838329   \n",
       "min        0.009450    -11.238420      0.407380      0.010000      5.248929   \n",
       "25%      154.486425      9.795145      0.436516      0.033800     24.390653   \n",
       "50%      186.753000     24.400580      0.489779      0.052300     35.043089   \n",
       "75%      221.979375     40.093400      0.602560      0.075600     47.500516   \n",
       "max      359.994900     70.133250     10.964781      0.294800   1373.931687   \n",
       "\n",
       "          d_pix_kpc      logMstar  err_logMstar      Distance      lin_mass  \\\n",
       "count  78851.000000  78851.000000  78851.000000  78851.000000  7.885100e+04   \n",
       "mean       0.487867     10.558197      0.031070    251.574576  7.898269e+10   \n",
       "std        0.270663      0.654456      0.016953    139.570856  9.624108e+10   \n",
       "min        0.083111      7.376000      0.001000     42.857142  2.376840e+07   \n",
       "25%        0.280915     10.200000      0.019000    144.857136  1.584893e+10   \n",
       "50%        0.434670     10.692000      0.028000    224.142852  4.920395e+10   \n",
       "75%        0.628319     11.030000      0.039000    323.999992  1.071519e+11   \n",
       "max        2.450110     12.326000      0.778000   1263.428628  2.118361e+12   \n",
       "\n",
       "            lin_err  \n",
       "count  7.885100e+04  \n",
       "mean   4.398954e+09  \n",
       "std    5.552716e+09  \n",
       "min    4.756699e+05  \n",
       "25%    1.023221e+09  \n",
       "50%    2.693666e+09  \n",
       "75%    5.603185e+09  \n",
       "max    1.414535e+11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.logMstar != -99]\n",
    "df = df[df.hasFile == True]\n",
    "df = df[df['lin_err']!=0]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDSS_ID</th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>D25</th>\n",
       "      <th>redshi</th>\n",
       "      <th>GalSize_kpc</th>\n",
       "      <th>D_Mpc</th>\n",
       "      <th>d_pix_kpc</th>\n",
       "      <th>logMstar</th>\n",
       "      <th>err_logMstar</th>\n",
       "      <th>Distance</th>\n",
       "      <th>lin_mass</th>\n",
       "      <th>lin_err</th>\n",
       "      <th>hasFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237679167158747217</td>\n",
       "      <td>23.76075</td>\n",
       "      <td>15.48772</td>\n",
       "      <td>0.512861</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>46.098264</td>\n",
       "      <td>308.9999939714159</td>\n",
       "      <td>0.599230</td>\n",
       "      <td>11.351</td>\n",
       "      <td>0.037</td>\n",
       "      <td>308.999994</td>\n",
       "      <td>2.243882e+11</td>\n",
       "      <td>1.911690e+10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237661358076919942</td>\n",
       "      <td>170.32005</td>\n",
       "      <td>47.05395</td>\n",
       "      <td>0.467735</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>31.837723</td>\n",
       "      <td>234.00000163487024</td>\n",
       "      <td>0.453786</td>\n",
       "      <td>10.508</td>\n",
       "      <td>0.012</td>\n",
       "      <td>234.000002</td>\n",
       "      <td>3.221069e+10</td>\n",
       "      <td>8.900142e+08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237659119328165980</td>\n",
       "      <td>230.41650</td>\n",
       "      <td>44.79981</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>36.297368</td>\n",
       "      <td>285.85712824548995</td>\n",
       "      <td>0.554350</td>\n",
       "      <td>10.172</td>\n",
       "      <td>0.046</td>\n",
       "      <td>285.857128</td>\n",
       "      <td>1.485936e+10</td>\n",
       "      <td>1.573887e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1237661966353432773</td>\n",
       "      <td>176.04465</td>\n",
       "      <td>41.44909</td>\n",
       "      <td>0.436516</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>69.384026</td>\n",
       "      <td>546.4285612106323</td>\n",
       "      <td>1.059664</td>\n",
       "      <td>11.342</td>\n",
       "      <td>0.013</td>\n",
       "      <td>546.428561</td>\n",
       "      <td>2.197860e+11</td>\n",
       "      <td>6.578987e+09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237651736850006060</td>\n",
       "      <td>224.11650</td>\n",
       "      <td>2.20688</td>\n",
       "      <td>0.407380</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>14.677334</td>\n",
       "      <td>123.85714000889233</td>\n",
       "      <td>0.240191</td>\n",
       "      <td>10.346</td>\n",
       "      <td>0.016</td>\n",
       "      <td>123.857140</td>\n",
       "      <td>2.218196e+10</td>\n",
       "      <td>8.172138e+08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SDSS_ID         RA       DEC       D25  redshi  GalSize_kpc  \\\n",
       "0  1237679167158747217   23.76075  15.48772  0.512861  0.0721    46.098264   \n",
       "1  1237661358076919942  170.32005  47.05395  0.467735  0.0546    31.837723   \n",
       "2  1237659119328165980  230.41650  44.79981  0.436516  0.0667    36.297368   \n",
       "3  1237661966353432773  176.04465  41.44909  0.436516  0.1275    69.384026   \n",
       "4  1237651736850006060  224.11650   2.20688  0.407380  0.0289    14.677334   \n",
       "\n",
       "                D_Mpc  d_pix_kpc  logMstar  err_logMstar    Distance  \\\n",
       "0   308.9999939714159   0.599230    11.351         0.037  308.999994   \n",
       "1  234.00000163487024   0.453786    10.508         0.012  234.000002   \n",
       "2  285.85712824548995   0.554350    10.172         0.046  285.857128   \n",
       "3   546.4285612106323   1.059664    11.342         0.013  546.428561   \n",
       "4  123.85714000889233   0.240191    10.346         0.016  123.857140   \n",
       "\n",
       "       lin_mass       lin_err  hasFile  \n",
       "0  2.243882e+11  1.911690e+10     True  \n",
       "1  3.221069e+10  8.900142e+08     True  \n",
       "2  1.485936e+10  1.573887e+09     True  \n",
       "3  2.197860e+11  6.578987e+09     True  \n",
       "4  2.218196e+10  8.172138e+08     True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fefdae3bbe0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefdada0550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.logMstar.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78851\n"
     ]
    }
   ],
   "source": [
    "print(len(df.SDSS_ID.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crap instruction to make the auto execution stop here :p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call img_preproc on all images, per batches of \"chunkSize\"\n",
    "### Generate features based on the preprocessed images, pretrained networks and flux densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunkFileName(chunkSize, prefix, chunkNumber):\n",
    "    fileName = 'Xg3-'+str(chunkSize)+'-'+prefix+'-chunk-' + str(chunkNumber) + '.npy'\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'nthread': 4,\n",
    "    #'silent': True,\n",
    "    'num_leaves': 2**4,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 10,\n",
    "    'max_bin': 255,\n",
    "    #'subsample_for_bin': 50000,\n",
    "    #'subsample': 0.8,\n",
    "    #'subsample_freq': 1,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    #'reg_alpha': 1,\n",
    "    #'reg_lambda': 0,\n",
    "    #'min_split_gain': 0.5,\n",
    "    #'min_child_weight': 1,\n",
    "    #'min_child_samples': 60,\n",
    "    #'scale_pos_weight': 1,\n",
    "    'device' : 'gpu',\n",
    "    'metric' : 'rmse',\n",
    "    #'metric' : 'multi_error',\n",
    "    'verbose':0,          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postImgFeatureNames = ['norm.flux.sum', 'norm.flux.min',\n",
    "                       'norm.flux.max', 'norm.flux.mean', \n",
    "                       'norm.flux.std', 'center.flux', \n",
    "                       'aroundCenter.flux']\n",
    "preImgFeatureNames = ['pre.flux.sum', 'pre.flux.min', \n",
    "                      'pre.flux.max', 'pre.flux.mean',\n",
    "                      'pre.flux.std', 'pre.center.flux',\n",
    "                      'pre.aroundCenter.flux', 'width']\n",
    "distanceNames = ['D', '1/D', 'D**2', '1/D**2', 'D**3', '1/D**3', 'log(D)', '1/log(D)', 'log(D**2)', 'log(1/D**2)', 'log(D)**2', '1/log(D)**2' ]\n",
    "\n",
    "\n",
    "def getFeatures(preProcessingNum):\n",
    "    Xg3r50 = []\n",
    "    Xg3vgg16 = []\n",
    "    postImgFeatures = []\n",
    "    csize=2\n",
    "    preImgFeatures = []\n",
    "\n",
    "    maxChunkNumber = math.ceil(len(ids)/chunkSize)\n",
    "    chunkStart = 0\n",
    "    # for chunkStart in tqdm(range(0, 3)):\n",
    "    \n",
    "    # do the loading by chunk to avoid consuming too much memory\n",
    "    for chunkStart in tqdm(range(0, len(ids), chunkSize)):\n",
    "        curChunk = int((chunkStart//chunkSize))\n",
    "        valuesInThisChunk = min(chunkStart+chunkSize,len(ids))-chunkStart\n",
    "\n",
    "        Xg_ = []\n",
    "        pre_ex_ = []\n",
    "\n",
    "        # preprocess the image and collect some raw image stats\n",
    "        for i in range(chunkStart, chunkStart+valuesInThisChunk):\n",
    "            X = read_image(ids[i])\n",
    "            Xg_.append(img_preprocnoread(X, preProcessingNum))\n",
    "            pre_ex_.append([\n",
    "                X.sum(),\n",
    "                X.min(),\n",
    "                X.max(),\n",
    "                X.mean(),\n",
    "                X.std(),\n",
    "                X[X.shape[0]//2,X.shape[1]//2],\n",
    "                np.mean(X[X.shape[0]//2-csize:X.shape[0]//2+csize,X.shape[1]//2-csize:X.shape[1]//2+csize]), # mean center\n",
    "                X.shape[0], \n",
    "            ])\n",
    "\n",
    "        # reformat the postprocessing\n",
    "        pre_ex = np.stack(pre_ex_)\n",
    "        Xg = np.stack(Xg_)\n",
    "\n",
    "        # collect some post processing stats\n",
    "        post_ex = np.hstack([\n",
    "            np.sum(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.min(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.max(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.mean(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            np.std(Xg.reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,1),\n",
    "            Xg[:,112,112].reshape(valuesInThisChunk,1),       # center\n",
    "            np.mean(Xg[:,112-csize:112+csize,112-csize:112+csize].reshape(valuesInThisChunk,-1),axis=1).reshape(valuesInThisChunk,-1) # mean center\n",
    "            ])\n",
    "\n",
    "        # prepare correct dimension to feed to imagenet networks\n",
    "        Xg3 = np.zeros((valuesInThisChunk,224,224,3))\n",
    "        Xg3[:,:,:,:] = Xg.reshape(valuesInThisChunk,224,224,1)\n",
    "\n",
    "        # do r50 prediction\n",
    "        Xg3r50_ = r50.predict(Xg3).reshape(valuesInThisChunk, 2048)\n",
    "        Xg3vgg16_ = vgg16.predict(Xg3)\n",
    "\n",
    "\n",
    "        if chunkStart == 0:\n",
    "            Xg3r50 = Xg3r50_\n",
    "            Xg3vgg16 = Xg3vgg16_\n",
    "            preImgFeatures = pre_ex\n",
    "            postImgFeatures = post_ex\n",
    "        else:\n",
    "            Xg3r50 = np.concatenate([Xg3r50,Xg3r50_], axis=0)\n",
    "            Xg3vgg16 = np.concatenate([Xg3vgg16,Xg3vgg16_], axis=0)\n",
    "            preImgFeatures = np.concatenate([preImgFeatures,pre_ex], axis=0)\n",
    "            postImgFeatures = np.concatenate([postImgFeatures,post_ex], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    # add features from the data itself (distance)\n",
    "    Distance = df.Distance.values[:N].reshape(N,1)\n",
    "\n",
    "    Xg3f = np.hstack ( ( \n",
    "            Xg3r50, \n",
    "            Xg3vgg16, \n",
    "            Distance,\n",
    "            1/Distance,\n",
    "            Distance**2,\n",
    "            1/(Distance**2),\n",
    "            Distance**3,\n",
    "            1/(Distance**3),\n",
    "            np.log(Distance),\n",
    "            1/np.log(Distance),\n",
    "            np.log(Distance**2),\n",
    "            1/np.log(Distance**2),\n",
    "            np.log(Distance)**2,\n",
    "            1/np.log(Distance)**2,\n",
    "            preImgFeatures,\n",
    "            postImgFeatures\n",
    "            ) )\n",
    "\n",
    "\n",
    "    Xg3fNames = ( [prefixThisRound+'.r50.' + str(i) for i in range(Xg3r50.shape[1])]\n",
    "                + [prefixThisRound+'.vgg16.' + str(i) for i in range(Xg3vgg16.shape[1])] \n",
    "                + [prefixThisRound+'.'+ n for n in distanceNames]\n",
    "                + [prefixThisRound+'.'+ n for n in preImgFeatureNames]\n",
    "                + [prefixThisRound+'.'+ n for n in postImgFeatureNames])\n",
    "\n",
    "#     print(len(Xg3fNames), Xg3f.shape)\n",
    "    \n",
    "    return Xg3f, Xg3fNames\n",
    "\n",
    "numFeatures = 2048 + 1000 + len(postImgFeatureNames) + len(preImgFeatureNames) + len(distanceNames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getLGBMModelsWithCV(trainSet, YSet):\n",
    "    kf = KFold(n_splits=nSplits,shuffle=True, random_state=220477)\n",
    "\n",
    "    cvtrainpreds = np.zeros([len(Xg3f),nSplits])\n",
    "    models = []\n",
    "    xis, linxis = [],[]\n",
    "    counter = 0\n",
    "    for tix, vix in kf.split(trainSet):\n",
    "        X_train, X_test = trainSet[tix], trainSet[vix]\n",
    "        Y_train, Y_test = YSet[tix], YSet[vix]\n",
    "\n",
    "        lgb_train = lgbm.Dataset(X_train, Y_train)\n",
    "        lgb_eval = lgbm.Dataset(X_test, Y_test)\n",
    "\n",
    "        gbm = lgbm.train(lgbm_params,\n",
    "                           lgb_train,\n",
    "                           num_boost_round=20000,\n",
    "                           valid_sets=[lgb_train,lgb_eval],  # eval training data\n",
    "                           verbose_eval=100,\n",
    "                           early_stopping_rounds=100\n",
    "                        )\n",
    "        models.append(gbm)\n",
    "\n",
    "        p = gbm.predict(X_test)\n",
    "        chiSq = xi2(Y_test,p,err[vix])\n",
    "        linChiSq = xi2(10**Y_test,10**p,err_lin[vix])\n",
    "        xis.append(chiSq)\n",
    "        linxis.append(linChiSq)\n",
    "        print(counter,chiSq,linChiSq)    \n",
    "\n",
    "        cvtrainpreds[vix,counter] = p\n",
    "        counter = counter+1\n",
    "        \n",
    "    return models, cvtrainpreds, xis, linxis\n",
    "\n",
    "# models, cvtrainpreds, xis, linxis = getModels(Xg3f[:M], Y[:M])\n",
    "\n",
    "# print(models, cvtrainpreds)\n",
    "\n",
    "# print(xis, linxis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLGBMModelsNoCV(trainSet, YSet, errSet, errlinSet):\n",
    "    cvtrainpreds = np.zeros([len(trainSet),1])\n",
    "    models = []\n",
    "    xis, linxis = [],[]\n",
    "    counter = 0\n",
    "\n",
    "    tix, vix = list(range(0,int(len(trainSet)*0.9))), list(range(int(len(trainSet)*0.9),len(trainSet)))\n",
    "    \n",
    "    X_train, X_test = trainSet[tix], trainSet[vix]\n",
    "    Y_train, Y_test = YSet[tix], YSet[vix]\n",
    "\n",
    "    lgb_train = lgbm.Dataset(X_train, Y_train)\n",
    "    lgb_eval = lgbm.Dataset(X_test, Y_test)\n",
    "\n",
    "    gbm = lgbm.train(lgbm_params,\n",
    "                       lgb_train,\n",
    "                       num_boost_round=maxBoostRuns,\n",
    "                       valid_sets=[lgb_train,lgb_eval],  # eval training data\n",
    "                       verbose_eval=100,\n",
    "                       early_stopping_rounds=100\n",
    "                    )\n",
    "    models.append(gbm)\n",
    "\n",
    "    p = gbm.predict(X_test)\n",
    "    chiSq = xi2(Y_test,p,errSet[vix])\n",
    "    linChiSq = xi2(10**Y_test,10**p,errlinSet[vix])\n",
    "    xis.append(chiSq)\n",
    "    linxis.append(linChiSq)\n",
    "    print(counter,chiSq,linChiSq)    \n",
    "\n",
    "    cvtrainpreds[vix,counter] = p\n",
    "    counter = counter+1\n",
    "        \n",
    "    return models, cvtrainpreds, xis, linxis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model9d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c16e0b8abd31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel9d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget9DModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel9d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'model9d'"
     ]
    }
   ],
   "source": [
    "# from keras.models import model9d\n",
    "\n",
    "# def get9DModel(trainSet, YSet):\n",
    "#     model = model9d(trainSet.shape[1])\n",
    "#     model.fit(trainSet,YSet,verbose=1)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 0\n",
    "TEST = 4\n",
    "FEATURES = 0\n",
    "TRUTH = 1\n",
    "ERROR = 2\n",
    "LINERROR = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration parameters defined here:\n",
    "\n",
    "- N is the number of galaxies to use for this run\n",
    "- M is the number of galaxies to train set (rest is holdout)\n",
    "- chunkSize is the number of galaxies to evaluate at once\n",
    "- prefixThisRound is the model name, for serialization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = int(len(df.SDSS_ID.values))\n",
    "M = int(N*.9)\n",
    "\n",
    "prefixThisRound = 'sp'\n",
    "for i in runNameParams:\n",
    "    prefixThisRound = prefixThisRound + '-' + i\n",
    "\n",
    "prefixThisRound = prefixThisRound + '-model6'\n",
    "    \n",
    "chunkSize = 200\n",
    "nSplits = 3\n",
    "reloadImagesAndPreprocess = 1\n",
    "numPreprocessing = 2\n",
    "nSplits = 1\n",
    "\n",
    "maxBoostRuns = 20000\n",
    "# N = 3000 # number of galaxies to take into consideration\n",
    "# M = 2000 # train vs holdout\n",
    "\n",
    "\n",
    "N = int(N*0.1)\n",
    "M = int(M*0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = df.SDSS_ID.values[:N]\n",
    "Y = df.logMstar.values[:N]\n",
    "err = df.err_logMstar.values[:N]\n",
    "Y_lin = df.lin_mass.values[:N]\n",
    "err_lin = df.lin_err.values[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N)\n",
    "print(M)\n",
    "print(chunkSize)\n",
    "print(prefixThisRound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:07<00:00,  1.50s/it]\n",
      "100%|██████████| 40/40 [01:04<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "ttaPredictions = np.zeros([numPreprocessing,nSplits,N-M])\n",
    "\n",
    "data = list(range(8))\n",
    "\n",
    "data[TRAIN+FEATURES] = np.ones([0,numFeatures])\n",
    "data[TRAIN+TRUTH] = np.ones([0])\n",
    "data[TRAIN+ERROR] = np.ones([0])\n",
    "data[TRAIN+LINERROR] = np.ones([0])\n",
    "data[TEST+FEATURES] = np.ones([0,numFeatures])\n",
    "data[TEST+TRUTH] = np.ones([0])\n",
    "data[TEST+ERROR] = np.ones([0])\n",
    "data[TEST+LINERROR] = np.ones([0])\n",
    "\n",
    "fileName = prefixThisRound + 'allFeatures' + str(numPreprocessing) + '.npy'\n",
    "\n",
    "if reloadImagesAndPreprocess == 1 or not(os.path.isfile(fileName)):\n",
    "    for curTTA in range(numPreprocessing):\n",
    "        a, Xg3fNames = getFeatures(curTTA)\n",
    "\n",
    "        data[TRAIN+FEATURES] = np.vstack([data[TRAIN+FEATURES],a[:M]])\n",
    "        data[TRAIN+TRUTH] = np.hstack([data[TRAIN+TRUTH],Y[:M]])\n",
    "        data[TEST+FEATURES] = np.vstack([data[TEST+FEATURES],a[M:]])\n",
    "        data[TEST+TRUTH] = np.hstack([data[TEST+TRUTH],Y[M:]])\n",
    "        data[TRAIN+ERROR] = np.hstack([data[TRAIN+ERROR],err[:M]])\n",
    "        data[TRAIN+LINERROR] = np.hstack([data[TRAIN+LINERROR], err_lin[:M]])\n",
    "        data[TEST+ERROR] = np.hstack([data[TEST+ERROR],err[M:]])\n",
    "        data[TEST+LINERROR]  = np.hstack([data[TEST+LINERROR] , err_lin[M:]])\n",
    "\n",
    "    np.save(fileName, data)\n",
    "else:\n",
    "    data = np.load(fileName)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.346958\tvalid_1's rmse: 0.345555\n",
      "[200]\ttraining's rmse: 0.245419\tvalid_1's rmse: 0.250697\n",
      "[300]\ttraining's rmse: 0.20929\tvalid_1's rmse: 0.220103\n",
      "[400]\ttraining's rmse: 0.191007\tvalid_1's rmse: 0.206303\n",
      "[500]\ttraining's rmse: 0.178801\tvalid_1's rmse: 0.198951\n",
      "[600]\ttraining's rmse: 0.169501\tvalid_1's rmse: 0.193688\n",
      "[700]\ttraining's rmse: 0.161966\tvalid_1's rmse: 0.19013\n",
      "[800]\ttraining's rmse: 0.155694\tvalid_1's rmse: 0.187549\n",
      "[900]\ttraining's rmse: 0.150368\tvalid_1's rmse: 0.18596\n",
      "[1000]\ttraining's rmse: 0.145514\tvalid_1's rmse: 0.18442\n",
      "[1100]\ttraining's rmse: 0.141225\tvalid_1's rmse: 0.18312\n",
      "[1200]\ttraining's rmse: 0.137362\tvalid_1's rmse: 0.182378\n",
      "[1300]\ttraining's rmse: 0.133851\tvalid_1's rmse: 0.181561\n",
      "[1400]\ttraining's rmse: 0.130538\tvalid_1's rmse: 0.180724\n",
      "[1500]\ttraining's rmse: 0.127467\tvalid_1's rmse: 0.179965\n",
      "[1600]\ttraining's rmse: 0.124545\tvalid_1's rmse: 0.179437\n",
      "[1700]\ttraining's rmse: 0.121832\tvalid_1's rmse: 0.178854\n",
      "[1800]\ttraining's rmse: 0.119215\tvalid_1's rmse: 0.178401\n",
      "[1900]\ttraining's rmse: 0.11669\tvalid_1's rmse: 0.177914\n",
      "[2000]\ttraining's rmse: 0.114233\tvalid_1's rmse: 0.177462\n",
      "[2100]\ttraining's rmse: 0.111854\tvalid_1's rmse: 0.177003\n",
      "[2200]\ttraining's rmse: 0.109622\tvalid_1's rmse: 0.17653\n",
      "[2300]\ttraining's rmse: 0.107455\tvalid_1's rmse: 0.176198\n",
      "[2400]\ttraining's rmse: 0.105368\tvalid_1's rmse: 0.17575\n",
      "[2500]\ttraining's rmse: 0.103347\tvalid_1's rmse: 0.175432\n",
      "[2600]\ttraining's rmse: 0.101362\tvalid_1's rmse: 0.175046\n",
      "[2700]\ttraining's rmse: 0.0995072\tvalid_1's rmse: 0.174778\n",
      "[2800]\ttraining's rmse: 0.0977463\tvalid_1's rmse: 0.174496\n",
      "[2900]\ttraining's rmse: 0.0959504\tvalid_1's rmse: 0.174298\n",
      "[3000]\ttraining's rmse: 0.0942187\tvalid_1's rmse: 0.173959\n",
      "[3100]\ttraining's rmse: 0.092515\tvalid_1's rmse: 0.1737\n",
      "[3200]\ttraining's rmse: 0.0908883\tvalid_1's rmse: 0.173472\n",
      "[3300]\ttraining's rmse: 0.0892719\tvalid_1's rmse: 0.173274\n",
      "[3400]\ttraining's rmse: 0.0876881\tvalid_1's rmse: 0.173097\n",
      "[3500]\ttraining's rmse: 0.0862441\tvalid_1's rmse: 0.172874\n",
      "[3600]\ttraining's rmse: 0.0847814\tvalid_1's rmse: 0.172695\n",
      "[3700]\ttraining's rmse: 0.0833281\tvalid_1's rmse: 0.172542\n",
      "[3800]\ttraining's rmse: 0.0819209\tvalid_1's rmse: 0.172308\n",
      "[3900]\ttraining's rmse: 0.0805446\tvalid_1's rmse: 0.172112\n",
      "[4000]\ttraining's rmse: 0.0791888\tvalid_1's rmse: 0.171892\n",
      "[4100]\ttraining's rmse: 0.0778361\tvalid_1's rmse: 0.171758\n",
      "[4200]\ttraining's rmse: 0.076551\tvalid_1's rmse: 0.17162\n",
      "[4300]\ttraining's rmse: 0.0752711\tvalid_1's rmse: 0.171509\n",
      "[4400]\ttraining's rmse: 0.0740332\tvalid_1's rmse: 0.17139\n",
      "[4500]\ttraining's rmse: 0.0727743\tvalid_1's rmse: 0.171252\n",
      "[4600]\ttraining's rmse: 0.0716041\tvalid_1's rmse: 0.171073\n",
      "[4700]\ttraining's rmse: 0.070465\tvalid_1's rmse: 0.170982\n",
      "[4800]\ttraining's rmse: 0.0693401\tvalid_1's rmse: 0.170891\n",
      "[4900]\ttraining's rmse: 0.0682105\tvalid_1's rmse: 0.170784\n",
      "[5000]\ttraining's rmse: 0.0671299\tvalid_1's rmse: 0.170622\n",
      "[5100]\ttraining's rmse: 0.0660405\tvalid_1's rmse: 0.170531\n",
      "[5200]\ttraining's rmse: 0.06498\tvalid_1's rmse: 0.170448\n",
      "[5300]\ttraining's rmse: 0.0639836\tvalid_1's rmse: 0.170341\n",
      "[5400]\ttraining's rmse: 0.0629747\tvalid_1's rmse: 0.170274\n",
      "[5500]\ttraining's rmse: 0.0619742\tvalid_1's rmse: 0.170177\n",
      "[5600]\ttraining's rmse: 0.0609954\tvalid_1's rmse: 0.170065\n",
      "[5700]\ttraining's rmse: 0.0600414\tvalid_1's rmse: 0.169969\n",
      "[5800]\ttraining's rmse: 0.0591167\tvalid_1's rmse: 0.169882\n",
      "[5900]\ttraining's rmse: 0.0581839\tvalid_1's rmse: 0.169812\n",
      "[6000]\ttraining's rmse: 0.0572738\tvalid_1's rmse: 0.169754\n",
      "[6100]\ttraining's rmse: 0.0563959\tvalid_1's rmse: 0.169665\n",
      "[6200]\ttraining's rmse: 0.0555493\tvalid_1's rmse: 0.169605\n",
      "[6300]\ttraining's rmse: 0.0546983\tvalid_1's rmse: 0.169545\n",
      "[6400]\ttraining's rmse: 0.0538658\tvalid_1's rmse: 0.169456\n",
      "[6500]\ttraining's rmse: 0.053063\tvalid_1's rmse: 0.169375\n",
      "[6600]\ttraining's rmse: 0.0522557\tvalid_1's rmse: 0.1693\n",
      "[6700]\ttraining's rmse: 0.0514697\tvalid_1's rmse: 0.169245\n",
      "[6800]\ttraining's rmse: 0.05069\tvalid_1's rmse: 0.16917\n",
      "[6900]\ttraining's rmse: 0.0499183\tvalid_1's rmse: 0.169089\n",
      "[7000]\ttraining's rmse: 0.0491524\tvalid_1's rmse: 0.169009\n",
      "[7100]\ttraining's rmse: 0.0484255\tvalid_1's rmse: 0.16894\n",
      "[7200]\ttraining's rmse: 0.0477121\tvalid_1's rmse: 0.168904\n",
      "[7300]\ttraining's rmse: 0.0469918\tvalid_1's rmse: 0.168838\n",
      "[7400]\ttraining's rmse: 0.0462948\tvalid_1's rmse: 0.168779\n",
      "[7500]\ttraining's rmse: 0.0456394\tvalid_1's rmse: 0.168714\n",
      "[7600]\ttraining's rmse: 0.0449744\tvalid_1's rmse: 0.168672\n",
      "[7700]\ttraining's rmse: 0.0443262\tvalid_1's rmse: 0.168601\n",
      "[7800]\ttraining's rmse: 0.043682\tvalid_1's rmse: 0.168552\n",
      "[7900]\ttraining's rmse: 0.0430501\tvalid_1's rmse: 0.168505\n",
      "[8000]\ttraining's rmse: 0.0424082\tvalid_1's rmse: 0.168462\n",
      "[8100]\ttraining's rmse: 0.0417827\tvalid_1's rmse: 0.168389\n",
      "[8200]\ttraining's rmse: 0.0411943\tvalid_1's rmse: 0.168326\n",
      "[8300]\ttraining's rmse: 0.0405802\tvalid_1's rmse: 0.168281\n",
      "[8400]\ttraining's rmse: 0.040002\tvalid_1's rmse: 0.168227\n",
      "[8500]\ttraining's rmse: 0.0394369\tvalid_1's rmse: 0.168208\n",
      "[8600]\ttraining's rmse: 0.038874\tvalid_1's rmse: 0.168166\n",
      "[8700]\ttraining's rmse: 0.0383247\tvalid_1's rmse: 0.168107\n",
      "[8800]\ttraining's rmse: 0.0377679\tvalid_1's rmse: 0.168055\n",
      "[8900]\ttraining's rmse: 0.0372293\tvalid_1's rmse: 0.167997\n",
      "[9000]\ttraining's rmse: 0.0366866\tvalid_1's rmse: 0.167974\n",
      "[9100]\ttraining's rmse: 0.0361658\tvalid_1's rmse: 0.167919\n",
      "[9200]\ttraining's rmse: 0.0356489\tvalid_1's rmse: 0.167846\n",
      "[9300]\ttraining's rmse: 0.0351386\tvalid_1's rmse: 0.167813\n",
      "[9400]\ttraining's rmse: 0.0346368\tvalid_1's rmse: 0.167755\n",
      "[9500]\ttraining's rmse: 0.0341371\tvalid_1's rmse: 0.167716\n",
      "[9600]\ttraining's rmse: 0.0336365\tvalid_1's rmse: 0.16766\n",
      "[9700]\ttraining's rmse: 0.0331453\tvalid_1's rmse: 0.167599\n",
      "[9800]\ttraining's rmse: 0.032673\tvalid_1's rmse: 0.167538\n",
      "[9900]\ttraining's rmse: 0.0321958\tvalid_1's rmse: 0.167499\n",
      "[10000]\ttraining's rmse: 0.0317384\tvalid_1's rmse: 0.16745\n",
      "[10100]\ttraining's rmse: 0.0312978\tvalid_1's rmse: 0.167395\n",
      "[10200]\ttraining's rmse: 0.0308506\tvalid_1's rmse: 0.167364\n",
      "[10300]\ttraining's rmse: 0.0304226\tvalid_1's rmse: 0.167336\n",
      "[10400]\ttraining's rmse: 0.0299922\tvalid_1's rmse: 0.167298\n",
      "[10500]\ttraining's rmse: 0.0295674\tvalid_1's rmse: 0.167258\n",
      "[10600]\ttraining's rmse: 0.0291588\tvalid_1's rmse: 0.167228\n",
      "[10700]\ttraining's rmse: 0.0287458\tvalid_1's rmse: 0.167193\n",
      "[10800]\ttraining's rmse: 0.0283409\tvalid_1's rmse: 0.16716\n",
      "[10900]\ttraining's rmse: 0.027946\tvalid_1's rmse: 0.167127\n",
      "[11000]\ttraining's rmse: 0.0275559\tvalid_1's rmse: 0.167095\n",
      "[11100]\ttraining's rmse: 0.0271768\tvalid_1's rmse: 0.167068\n",
      "[11200]\ttraining's rmse: 0.0268029\tvalid_1's rmse: 0.167031\n",
      "[11300]\ttraining's rmse: 0.0264331\tvalid_1's rmse: 0.167013\n",
      "[11400]\ttraining's rmse: 0.0260633\tvalid_1's rmse: 0.166981\n",
      "[11500]\ttraining's rmse: 0.0256963\tvalid_1's rmse: 0.166942\n",
      "[11600]\ttraining's rmse: 0.0253502\tvalid_1's rmse: 0.16692\n",
      "[11700]\ttraining's rmse: 0.0249956\tvalid_1's rmse: 0.166879\n",
      "[11800]\ttraining's rmse: 0.024654\tvalid_1's rmse: 0.166852\n",
      "[11900]\ttraining's rmse: 0.0243261\tvalid_1's rmse: 0.166824\n",
      "[12000]\ttraining's rmse: 0.0239959\tvalid_1's rmse: 0.166796\n",
      "[12100]\ttraining's rmse: 0.0236731\tvalid_1's rmse: 0.166778\n",
      "[12200]\ttraining's rmse: 0.0233451\tvalid_1's rmse: 0.166757\n",
      "[12300]\ttraining's rmse: 0.0230242\tvalid_1's rmse: 0.166731\n",
      "[12400]\ttraining's rmse: 0.022716\tvalid_1's rmse: 0.16672\n",
      "[12500]\ttraining's rmse: 0.0224226\tvalid_1's rmse: 0.166701\n",
      "[12600]\ttraining's rmse: 0.0221276\tvalid_1's rmse: 0.166683\n",
      "[12700]\ttraining's rmse: 0.0218362\tvalid_1's rmse: 0.166664\n",
      "[12800]\ttraining's rmse: 0.0215434\tvalid_1's rmse: 0.166637\n",
      "[12900]\ttraining's rmse: 0.0212503\tvalid_1's rmse: 0.166612\n",
      "[13000]\ttraining's rmse: 0.0209703\tvalid_1's rmse: 0.166599\n",
      "[13100]\ttraining's rmse: 0.0206824\tvalid_1's rmse: 0.166585\n",
      "[13200]\ttraining's rmse: 0.0203942\tvalid_1's rmse: 0.166567\n",
      "[13300]\ttraining's rmse: 0.0201128\tvalid_1's rmse: 0.16655\n",
      "[13400]\ttraining's rmse: 0.019838\tvalid_1's rmse: 0.16653\n",
      "[13500]\ttraining's rmse: 0.0195674\tvalid_1's rmse: 0.166525\n",
      "[13600]\ttraining's rmse: 0.0193046\tvalid_1's rmse: 0.166497\n",
      "[13700]\ttraining's rmse: 0.0190427\tvalid_1's rmse: 0.166475\n",
      "[13800]\ttraining's rmse: 0.0187773\tvalid_1's rmse: 0.166465\n",
      "[13900]\ttraining's rmse: 0.0185214\tvalid_1's rmse: 0.166445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14000]\ttraining's rmse: 0.0182796\tvalid_1's rmse: 0.166429\n",
      "[14100]\ttraining's rmse: 0.0180274\tvalid_1's rmse: 0.16641\n",
      "[14200]\ttraining's rmse: 0.0177788\tvalid_1's rmse: 0.166401\n",
      "[14300]\ttraining's rmse: 0.0175353\tvalid_1's rmse: 0.166398\n",
      "Early stopping, best iteration is:\n",
      "[14279]\ttraining's rmse: 0.0175847\tvalid_1's rmse: 0.166395\n",
      "0 64.9465160624 64.552872269\n"
     ]
    }
   ],
   "source": [
    "models, cvtrainpreds, xis, linxis = getLGBMModelsNoCV(data[TRAIN+FEATURES], data[TRAIN+TRUTH], data[TRAIN+ERROR], data[TRAIN+LINERROR])\n",
    "\n",
    "ppreds = np.zeros([len(models),data[TEST+FEATURES].shape[0]])\n",
    "for i, m in zip(range(len(models)),models):\n",
    "    mp = m.predict(data[TEST+FEATURES])\n",
    "    ppreds[i] = mp\n",
    "\n",
    "cvpred = ppreds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 2\n",
      "67.7680028295\n",
      "77.5366504091\n"
     ]
    }
   ],
   "source": [
    "print(\"Iteration : {}\".format(numPreprocessing))\n",
    "chiSq = xi2(data[TEST+TRUTH],cvpred,data[TEST+ERROR])\n",
    "linChiSq = xi2(10**data[TEST+TRUTH],10**cvpred,data[TEST+LINERROR])\n",
    "print(chiSq)\n",
    "print(linChiSq)\n",
    "\n",
    "# ttaPredictions[curTTA] = ppreds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppreds.reshape((numPreprocessing,-1)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.3773183087\n",
      "75.3634222114\n"
     ]
    }
   ],
   "source": [
    "# print(M)\n",
    "# print(trainXg3fStacked.shape)\n",
    "# testXg3fStacked.shape\n",
    "# ttaPredictions.shape\n",
    "# ppreds.shape\n",
    "\n",
    "mpred = ppreds.reshape((numPreprocessing,-1)).mean(axis=0)\n",
    "chiSq = xi2(data[TEST+TRUTH][:len(mpred)],mpred,data[TEST+ERROR][:len(mpred)])\n",
    "linChiSq = xi2(10**data[TEST+TRUTH][:len(mpred)],10**mpred,data[TEST+LINERROR][:len(mpred)])\n",
    "print(chiSq)\n",
    "print(linChiSq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12772 samples, validate on 1420 samples\n",
      "Epoch 1/500\n",
      "12772/12772 [==============================] - 1s - loss: 23.6014 - acc: 2.3489e-04 - val_loss: 10.3412 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "12772/12772 [==============================] - 1s - loss: 3.7427 - acc: 5.4807e-04 - val_loss: 5.6842 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "12772/12772 [==============================] - 1s - loss: 2.2477 - acc: 3.1319e-04 - val_loss: 18.8492 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "12772/12772 [==============================] - 1s - loss: 1.5662 - acc: 3.1319e-04 - val_loss: 52.3977 - val_acc: 7.0423e-04\n",
      "Epoch 5/500\n",
      "12772/12772 [==============================] - 1s - loss: 1.1236 - acc: 3.9148e-04 - val_loss: 3.3844 - val_acc: 7.0423e-04\n",
      "Epoch 6/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.9046 - acc: 7.0467e-04 - val_loss: 10.0795 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.7425 - acc: 9.3956e-04 - val_loss: 25.5780 - val_acc: 7.0423e-04\n",
      "Epoch 8/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.5999 - acc: 5.4807e-04 - val_loss: 1.3232 - val_acc: 7.0423e-04\n",
      "Epoch 9/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.5497 - acc: 6.2637e-04 - val_loss: 25.6945 - val_acc: 7.0423e-04\n",
      "Epoch 10/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.4769 - acc: 6.2637e-04 - val_loss: 55.3098 - val_acc: 7.0423e-04\n",
      "Epoch 11/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.4519 - acc: 6.2637e-04 - val_loss: 48.2717 - val_acc: 7.0423e-04\n",
      "Epoch 12/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.4102 - acc: 9.3956e-04 - val_loss: 80.3789 - val_acc: 7.0423e-04\n",
      "Epoch 13/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3727 - acc: 8.6126e-04 - val_loss: 75.9997 - val_acc: 0.0014\n",
      "Epoch 14/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3693 - acc: 0.0010 - val_loss: 79.1769 - val_acc: 7.0423e-04\n",
      "Epoch 15/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3666 - acc: 8.6126e-04 - val_loss: 30.9706 - val_acc: 7.0423e-04\n",
      "Epoch 16/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3377 - acc: 7.0467e-04 - val_loss: 77.8475 - val_acc: 7.0423e-04\n",
      "Epoch 17/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3523 - acc: 7.0467e-04 - val_loss: 8.1318 - val_acc: 7.0423e-04\n",
      "Epoch 18/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3275 - acc: 7.0467e-04 - val_loss: 0.7979 - val_acc: 7.0423e-04\n",
      "Epoch 19/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3302 - acc: 9.3956e-04 - val_loss: 0.9398 - val_acc: 7.0423e-04\n",
      "Epoch 20/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3033 - acc: 8.6126e-04 - val_loss: 8.7025 - val_acc: 7.0423e-04\n",
      "Epoch 21/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2982 - acc: 7.8296e-04 - val_loss: 37.8616 - val_acc: 0.0014\n",
      "Epoch 22/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.3030 - acc: 7.8296e-04 - val_loss: 1.3119 - val_acc: 7.0423e-04\n",
      "Epoch 23/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2824 - acc: 4.6978e-04 - val_loss: 3.9070 - val_acc: 7.0423e-04\n",
      "Epoch 24/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2801 - acc: 7.8296e-04 - val_loss: 16.8481 - val_acc: 7.0423e-04\n",
      "Epoch 25/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2623 - acc: 8.6126e-04 - val_loss: 8840.7655 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2650 - acc: 8.6126e-04 - val_loss: 2.6826 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2648 - acc: 9.3956e-04 - val_loss: 1.4306 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2603 - acc: 9.3956e-04 - val_loss: 8.4944 - val_acc: 7.0423e-04\n",
      "Epoch 29/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2443 - acc: 9.3956e-04 - val_loss: 11.1949 - val_acc: 7.0423e-04\n",
      "Epoch 30/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2413 - acc: 6.2637e-04 - val_loss: 1.1768 - val_acc: 7.0423e-04\n",
      "Epoch 31/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2436 - acc: 7.8296e-04 - val_loss: 2.4604 - val_acc: 7.0423e-04\n",
      "Epoch 32/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2379 - acc: 8.6126e-04 - val_loss: 1.0960 - val_acc: 7.0423e-04\n",
      "Epoch 33/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2509 - acc: 7.0467e-04 - val_loss: 260.6949 - val_acc: 7.0423e-04\n",
      "Epoch 34/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2345 - acc: 0.0010 - val_loss: 2.7963 - val_acc: 7.0423e-04\n",
      "Epoch 35/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2379 - acc: 9.3956e-04 - val_loss: 6.7067 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2359 - acc: 9.3956e-04 - val_loss: 1.0190 - val_acc: 0.0014\n",
      "Epoch 37/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2319 - acc: 7.8296e-04 - val_loss: 5.4974 - val_acc: 7.0423e-04\n",
      "Epoch 38/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2225 - acc: 9.3956e-04 - val_loss: 5.1617 - val_acc: 7.0423e-04\n",
      "Epoch 39/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2296 - acc: 9.3956e-04 - val_loss: 3.0575 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2273 - acc: 0.0010 - val_loss: 4.1910 - val_acc: 0.0014\n",
      "Epoch 41/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2278 - acc: 9.3956e-04 - val_loss: 4.6396 - val_acc: 0.0014\n",
      "Epoch 42/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2204 - acc: 7.8296e-04 - val_loss: 4.0681 - val_acc: 0.0014\n",
      "Epoch 43/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2210 - acc: 7.8296e-04 - val_loss: 6.0999 - val_acc: 7.0423e-04\n",
      "Epoch 44/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2199 - acc: 7.8296e-04 - val_loss: 7.8463 - val_acc: 7.0423e-04\n",
      "Epoch 45/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2173 - acc: 9.3956e-04 - val_loss: 1.9238 - val_acc: 0.0014\n",
      "Epoch 46/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2142 - acc: 9.3956e-04 - val_loss: 2.7915 - val_acc: 0.0014\n",
      "Epoch 47/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2284 - acc: 9.3956e-04 - val_loss: 4.4463 - val_acc: 0.0014\n",
      "Epoch 48/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2241 - acc: 8.6126e-04 - val_loss: 5.8056 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2207 - acc: 8.6126e-04 - val_loss: 4.3470 - val_acc: 0.0014\n",
      "Epoch 50/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2245 - acc: 8.6126e-04 - val_loss: 6.2661 - val_acc: 0.0014\n",
      "Epoch 51/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2143 - acc: 7.8296e-04 - val_loss: 3.9553 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2169 - acc: 0.0010 - val_loss: 5.8854 - val_acc: 7.0423e-04\n",
      "Epoch 53/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2116 - acc: 9.3956e-04 - val_loss: 2.3578 - val_acc: 0.0014\n",
      "Epoch 54/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2228 - acc: 9.3956e-04 - val_loss: 7.1124 - val_acc: 0.0014\n",
      "Epoch 55/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2124 - acc: 9.3956e-04 - val_loss: 3.6685 - val_acc: 7.0423e-04\n",
      "Epoch 56/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2002 - acc: 0.0010 - val_loss: 4.9051 - val_acc: 7.0423e-04\n",
      "Epoch 57/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2146 - acc: 0.0010 - val_loss: 6.5918 - val_acc: 7.0423e-04\n",
      "Epoch 58/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2121 - acc: 0.0011 - val_loss: 8.9781 - val_acc: 0.0014\n",
      "Epoch 59/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2090 - acc: 9.3956e-04 - val_loss: 3.3270 - val_acc: 7.0423e-04\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.2057 - acc: 9.3956e-04 - val_loss: 12.0433 - val_acc: 0.0014\n",
      "Epoch 61/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2094 - acc: 7.8296e-04 - val_loss: 5.0013 - val_acc: 7.0423e-04\n",
      "Epoch 62/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2056 - acc: 9.3956e-04 - val_loss: 5.3820 - val_acc: 7.0423e-04\n",
      "Epoch 63/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2044 - acc: 0.0010 - val_loss: 2.0358 - val_acc: 0.0014\n",
      "Epoch 64/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2058 - acc: 0.0010 - val_loss: 6.3783 - val_acc: 0.0014\n",
      "Epoch 65/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2059 - acc: 9.3956e-04 - val_loss: 2.2950 - val_acc: 0.0014\n",
      "Epoch 66/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1999 - acc: 9.3956e-04 - val_loss: 4.6459 - val_acc: 7.0423e-04\n",
      "Epoch 67/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2027 - acc: 0.0011 - val_loss: 1.9994 - val_acc: 7.0423e-04\n",
      "Epoch 68/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1987 - acc: 0.0010 - val_loss: 4.8089 - val_acc: 0.0014\n",
      "Epoch 69/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.2068 - acc: 0.0011 - val_loss: 6.4600 - val_acc: 0.0014\n",
      "Epoch 70/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1928 - acc: 7.8296e-04 - val_loss: 5.8263 - val_acc: 0.0014\n",
      "Epoch 71/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1902 - acc: 9.3956e-04 - val_loss: 2.5038 - val_acc: 7.0423e-04\n",
      "Epoch 72/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1942 - acc: 0.0010 - val_loss: 7.5093 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1944 - acc: 0.0010 - val_loss: 3.5038 - val_acc: 7.0423e-04\n",
      "Epoch 74/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1885 - acc: 7.8296e-04 - val_loss: 6.5262 - val_acc: 7.0423e-04\n",
      "Epoch 75/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1890 - acc: 7.8296e-04 - val_loss: 4.4069 - val_acc: 7.0423e-04\n",
      "Epoch 76/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1861 - acc: 0.0010 - val_loss: 5.7534 - val_acc: 0.0014\n",
      "Epoch 77/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1912 - acc: 0.0010 - val_loss: 4.6971 - val_acc: 7.0423e-04\n",
      "Epoch 78/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1868 - acc: 8.6126e-04 - val_loss: 7.5235 - val_acc: 0.0014\n",
      "Epoch 79/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1938 - acc: 7.8296e-04 - val_loss: 4.2404 - val_acc: 0.0014\n",
      "Epoch 80/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1885 - acc: 8.6126e-04 - val_loss: 8.1000 - val_acc: 0.0014\n",
      "Epoch 81/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1858 - acc: 8.6126e-04 - val_loss: 3.4796 - val_acc: 0.0014\n",
      "Epoch 82/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1855 - acc: 0.0010 - val_loss: 7.9668 - val_acc: 0.0014\n",
      "Epoch 83/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1925 - acc: 0.0010 - val_loss: 2.1684 - val_acc: 0.0014\n",
      "Epoch 84/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1878 - acc: 0.0011 - val_loss: 7.0726 - val_acc: 0.0014\n",
      "Epoch 85/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1817 - acc: 0.0010 - val_loss: 4.3114 - val_acc: 0.0014\n",
      "Epoch 86/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1818 - acc: 9.3956e-04 - val_loss: 9.4583 - val_acc: 7.0423e-04\n",
      "Epoch 87/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1821 - acc: 8.6126e-04 - val_loss: 3.2278 - val_acc: 0.0014\n",
      "Epoch 88/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1778 - acc: 8.6126e-04 - val_loss: 9.1452 - val_acc: 7.0423e-04\n",
      "Epoch 89/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1761 - acc: 8.6126e-04 - val_loss: 5.1371 - val_acc: 0.0014\n",
      "Epoch 90/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1806 - acc: 9.3956e-04 - val_loss: 11.8341 - val_acc: 0.0014\n",
      "Epoch 91/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1827 - acc: 0.0011 - val_loss: 7.6051 - val_acc: 7.0423e-04\n",
      "Epoch 92/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1752 - acc: 0.0010 - val_loss: 4.7899 - val_acc: 0.0014\n",
      "Epoch 93/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1793 - acc: 0.0010 - val_loss: 9.6858 - val_acc: 0.0014\n",
      "Epoch 94/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1804 - acc: 0.0011 - val_loss: 3.6736 - val_acc: 7.0423e-04\n",
      "Epoch 95/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1836 - acc: 9.3956e-04 - val_loss: 3.2891 - val_acc: 0.0014\n",
      "Epoch 96/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1789 - acc: 8.6126e-04 - val_loss: 5.4814 - val_acc: 7.0423e-04\n",
      "Epoch 97/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1742 - acc: 8.6126e-04 - val_loss: 9.9200 - val_acc: 0.0014\n",
      "Epoch 98/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1880 - acc: 7.8296e-04 - val_loss: 5.1292 - val_acc: 7.0423e-04\n",
      "Epoch 99/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1834 - acc: 8.6126e-04 - val_loss: 11.2184 - val_acc: 0.0014\n",
      "Epoch 100/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1741 - acc: 9.3956e-04 - val_loss: 6.3331 - val_acc: 7.0423e-04\n",
      "Epoch 101/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1731 - acc: 8.6126e-04 - val_loss: 2.6069 - val_acc: 0.0014\n",
      "Epoch 102/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1743 - acc: 8.6126e-04 - val_loss: 7.2394 - val_acc: 0.0014\n",
      "Epoch 103/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1768 - acc: 8.6126e-04 - val_loss: 3.0502 - val_acc: 0.0014\n",
      "Epoch 104/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1707 - acc: 9.3956e-04 - val_loss: 7.3389 - val_acc: 0.0014\n",
      "Epoch 105/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1714 - acc: 0.0011 - val_loss: 4.1483 - val_acc: 0.0014\n",
      "Epoch 106/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1661 - acc: 9.3956e-04 - val_loss: 4.5359 - val_acc: 0.0014\n",
      "Epoch 107/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1765 - acc: 9.3956e-04 - val_loss: 7.5472 - val_acc: 7.0423e-04\n",
      "Epoch 108/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1721 - acc: 0.0010 - val_loss: 5.7572 - val_acc: 0.0014\n",
      "Epoch 109/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1695 - acc: 9.3956e-04 - val_loss: 8.8352 - val_acc: 0.0014\n",
      "Epoch 110/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1667 - acc: 9.3956e-04 - val_loss: 4.8180 - val_acc: 0.0014\n",
      "Epoch 111/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1691 - acc: 0.0010 - val_loss: 8.2640 - val_acc: 0.0014\n",
      "Epoch 112/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1723 - acc: 9.3956e-04 - val_loss: 4.1868 - val_acc: 0.0014\n",
      "Epoch 113/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1804 - acc: 9.3956e-04 - val_loss: 9.3548 - val_acc: 0.0014\n",
      "Epoch 114/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1632 - acc: 0.0010 - val_loss: 3.9395 - val_acc: 0.0014\n",
      "Epoch 115/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1674 - acc: 9.3956e-04 - val_loss: 6.5985 - val_acc: 0.0000e+00\n",
      "Epoch 116/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1628 - acc: 7.8296e-04 - val_loss: 2.0329 - val_acc: 0.0014\n",
      "Epoch 117/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1629 - acc: 0.0010 - val_loss: 5.7100 - val_acc: 0.0014\n",
      "Epoch 118/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1658 - acc: 7.8296e-04 - val_loss: 6.2011 - val_acc: 0.0014\n",
      "Epoch 119/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1687 - acc: 0.0010 - val_loss: 5.5958 - val_acc: 7.0423e-04\n",
      "Epoch 120/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1691 - acc: 0.0010 - val_loss: 12.0731 - val_acc: 0.0014\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1627 - acc: 9.3956e-04 - val_loss: 6.6840 - val_acc: 0.0014\n",
      "Epoch 122/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1689 - acc: 0.0011 - val_loss: 4.0219 - val_acc: 0.0014\n",
      "Epoch 123/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1650 - acc: 9.3956e-04 - val_loss: 6.8545 - val_acc: 0.0014\n",
      "Epoch 124/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1642 - acc: 0.0010 - val_loss: 3.9769 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1640 - acc: 9.3956e-04 - val_loss: 11.0797 - val_acc: 0.0014\n",
      "Epoch 126/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1628 - acc: 9.3956e-04 - val_loss: 3.3331 - val_acc: 0.0014\n",
      "Epoch 127/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1607 - acc: 0.0010 - val_loss: 6.8452 - val_acc: 0.0014\n",
      "Epoch 128/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1662 - acc: 9.3956e-04 - val_loss: 3.9597 - val_acc: 0.0014\n",
      "Epoch 129/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1645 - acc: 9.3956e-04 - val_loss: 5.6237 - val_acc: 0.0014\n",
      "Epoch 130/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1622 - acc: 0.0010 - val_loss: 3.3673 - val_acc: 7.0423e-04\n",
      "Epoch 131/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1623 - acc: 0.0010 - val_loss: 6.0156 - val_acc: 7.0423e-04\n",
      "Epoch 132/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1624 - acc: 0.0010 - val_loss: 5.6258 - val_acc: 0.0014\n",
      "Epoch 133/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1624 - acc: 0.0010 - val_loss: 4.4892 - val_acc: 0.0014\n",
      "Epoch 134/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1641 - acc: 0.0010 - val_loss: 13.7540 - val_acc: 7.0423e-04\n",
      "Epoch 135/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1550 - acc: 0.0010 - val_loss: 3.7117 - val_acc: 7.0423e-04\n",
      "Epoch 136/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1606 - acc: 0.0010 - val_loss: 10.6888 - val_acc: 7.0423e-04\n",
      "Epoch 137/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1576 - acc: 0.0010 - val_loss: 4.1969 - val_acc: 0.0014\n",
      "Epoch 138/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1537 - acc: 0.0011 - val_loss: 5.5583 - val_acc: 0.0014\n",
      "Epoch 139/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1508 - acc: 9.3956e-04 - val_loss: 4.1230 - val_acc: 0.0014\n",
      "Epoch 140/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1606 - acc: 0.0010 - val_loss: 9.3932 - val_acc: 7.0423e-04\n",
      "Epoch 141/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1581 - acc: 9.3956e-04 - val_loss: 3.2483 - val_acc: 0.0014\n",
      "Epoch 142/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1572 - acc: 9.3956e-04 - val_loss: 7.8124 - val_acc: 0.0014\n",
      "Epoch 143/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1614 - acc: 8.6126e-04 - val_loss: 3.8132 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1575 - acc: 0.0010 - val_loss: 8.3741 - val_acc: 0.0014\n",
      "Epoch 145/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1596 - acc: 0.0011 - val_loss: 4.0155 - val_acc: 0.0014\n",
      "Epoch 146/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1542 - acc: 9.3956e-04 - val_loss: 4.8120 - val_acc: 0.0014\n",
      "Epoch 147/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1552 - acc: 0.0010 - val_loss: 4.4590 - val_acc: 7.0423e-04\n",
      "Epoch 148/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1540 - acc: 8.6126e-04 - val_loss: 7.5021 - val_acc: 0.0014\n",
      "Epoch 149/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1562 - acc: 0.0010 - val_loss: 5.5419 - val_acc: 7.0423e-04\n",
      "Epoch 150/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1526 - acc: 9.3956e-04 - val_loss: 5.4553 - val_acc: 0.0014\n",
      "Epoch 151/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1576 - acc: 0.0011 - val_loss: 11.0132 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1551 - acc: 0.0010 - val_loss: 2.4930 - val_acc: 7.0423e-04\n",
      "Epoch 153/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1562 - acc: 9.3956e-04 - val_loss: 6.5257 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1510 - acc: 9.3956e-04 - val_loss: 4.2540 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1547 - acc: 9.3956e-04 - val_loss: 11.5939 - val_acc: 7.0423e-04\n",
      "Epoch 156/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1550 - acc: 0.0010 - val_loss: 6.1854 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1524 - acc: 7.8296e-04 - val_loss: 12.8284 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1558 - acc: 0.0010 - val_loss: 4.9729 - val_acc: 0.0014\n",
      "Epoch 159/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1553 - acc: 0.0010 - val_loss: 10.1844 - val_acc: 7.0423e-04\n",
      "Epoch 160/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1562 - acc: 0.0010 - val_loss: 5.0728 - val_acc: 7.0423e-04\n",
      "Epoch 161/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1560 - acc: 0.0010 - val_loss: 8.0458 - val_acc: 0.0014\n",
      "Epoch 162/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1510 - acc: 9.3956e-04 - val_loss: 2.6114 - val_acc: 0.0014\n",
      "Epoch 163/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1498 - acc: 9.3956e-04 - val_loss: 5.2758 - val_acc: 0.0014\n",
      "Epoch 164/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1603 - acc: 0.0011 - val_loss: 3.4675 - val_acc: 7.0423e-04\n",
      "Epoch 165/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1522 - acc: 8.6126e-04 - val_loss: 13.0959 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1483 - acc: 0.0010 - val_loss: 4.6749 - val_acc: 7.0423e-04\n",
      "Epoch 167/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1528 - acc: 0.0010 - val_loss: 10.4073 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1519 - acc: 8.6126e-04 - val_loss: 2.8596 - val_acc: 7.0423e-04\n",
      "Epoch 169/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1543 - acc: 8.6126e-04 - val_loss: 5.9720 - val_acc: 0.0014\n",
      "Epoch 170/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1486 - acc: 0.0011 - val_loss: 8.0468 - val_acc: 0.0014\n",
      "Epoch 171/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1487 - acc: 0.0011 - val_loss: 5.5598 - val_acc: 0.0014\n",
      "Epoch 172/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1462 - acc: 0.0010 - val_loss: 16.3679 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1504 - acc: 0.0010 - val_loss: 4.1991 - val_acc: 7.0423e-04\n",
      "Epoch 174/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1445 - acc: 0.0011 - val_loss: 5.3438 - val_acc: 0.0014\n",
      "Epoch 175/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1436 - acc: 0.0010 - val_loss: 2.9206 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1443 - acc: 0.0010 - val_loss: 6.9889 - val_acc: 7.0423e-04\n",
      "Epoch 177/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1453 - acc: 0.0010 - val_loss: 3.3784 - val_acc: 7.0423e-04\n",
      "Epoch 178/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1504 - acc: 0.0010 - val_loss: 7.5182 - val_acc: 7.0423e-04\n",
      "Epoch 179/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1526 - acc: 0.0010 - val_loss: 6.3194 - val_acc: 0.0014\n",
      "Epoch 180/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1472 - acc: 0.0011 - val_loss: 8.2755 - val_acc: 7.0423e-04\n",
      "Epoch 181/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1417 - acc: 9.3956e-04 - val_loss: 4.4334 - val_acc: 0.0014\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1430 - acc: 0.0011 - val_loss: 12.5171 - val_acc: 0.0014\n",
      "Epoch 183/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1436 - acc: 0.0011 - val_loss: 3.3541 - val_acc: 7.0423e-04\n",
      "Epoch 184/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1480 - acc: 0.0010 - val_loss: 12.2506 - val_acc: 7.0423e-04\n",
      "Epoch 185/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1409 - acc: 0.0010 - val_loss: 3.6726 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1483 - acc: 0.0010 - val_loss: 7.7970 - val_acc: 7.0423e-04\n",
      "Epoch 187/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1381 - acc: 0.0011 - val_loss: 5.6663 - val_acc: 7.0423e-04\n",
      "Epoch 188/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1400 - acc: 0.0010 - val_loss: 12.2277 - val_acc: 0.0014\n",
      "Epoch 189/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1409 - acc: 9.3956e-04 - val_loss: 3.9967 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1375 - acc: 0.0010 - val_loss: 2.2930 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1405 - acc: 0.0011 - val_loss: 5.6069 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1374 - acc: 0.0010 - val_loss: 2.2513 - val_acc: 0.0014\n",
      "Epoch 193/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1386 - acc: 9.3956e-04 - val_loss: 6.3348 - val_acc: 7.0423e-04\n",
      "Epoch 194/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1422 - acc: 0.0010 - val_loss: 3.0701 - val_acc: 7.0423e-04\n",
      "Epoch 195/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1412 - acc: 0.0011 - val_loss: 13.8372 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1440 - acc: 0.0011 - val_loss: 4.0726 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1405 - acc: 9.3956e-04 - val_loss: 8.1393 - val_acc: 7.0423e-04\n",
      "Epoch 198/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1383 - acc: 0.0011 - val_loss: 5.9517 - val_acc: 0.0014\n",
      "Epoch 199/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1402 - acc: 9.3956e-04 - val_loss: 14.3339 - val_acc: 0.0014\n",
      "Epoch 200/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1417 - acc: 7.8296e-04 - val_loss: 3.3130 - val_acc: 0.0014\n",
      "Epoch 201/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1401 - acc: 8.6126e-04 - val_loss: 9.7998 - val_acc: 7.0423e-04\n",
      "Epoch 202/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1373 - acc: 9.3956e-04 - val_loss: 7.3787 - val_acc: 7.0423e-04\n",
      "Epoch 203/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1358 - acc: 0.0011 - val_loss: 3.6651 - val_acc: 0.0014\n",
      "Epoch 204/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1387 - acc: 0.0010 - val_loss: 10.8621 - val_acc: 7.0423e-04\n",
      "Epoch 205/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1399 - acc: 9.3956e-04 - val_loss: 15.5799 - val_acc: 0.0014\n",
      "Epoch 206/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1415 - acc: 0.0010 - val_loss: 8.9019 - val_acc: 7.0423e-04\n",
      "Epoch 207/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1387 - acc: 0.0010 - val_loss: 16.2775 - val_acc: 0.0014\n",
      "Epoch 208/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1373 - acc: 0.0010 - val_loss: 7.2114 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1369 - acc: 0.0010 - val_loss: 10.1668 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1375 - acc: 8.6126e-04 - val_loss: 14.6885 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1364 - acc: 0.0011 - val_loss: 6.4412 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1322 - acc: 0.0010 - val_loss: 7.1556 - val_acc: 0.0014\n",
      "Epoch 213/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1338 - acc: 9.3956e-04 - val_loss: 6.3557 - val_acc: 0.0014\n",
      "Epoch 214/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1435 - acc: 0.0011 - val_loss: 7.9067 - val_acc: 7.0423e-04\n",
      "Epoch 215/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1353 - acc: 0.0011 - val_loss: 3.6499 - val_acc: 0.0014\n",
      "Epoch 216/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1343 - acc: 0.0011 - val_loss: 12.4952 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1342 - acc: 9.3956e-04 - val_loss: 4.8532 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1364 - acc: 0.0011 - val_loss: 9.3037 - val_acc: 7.0423e-04\n",
      "Epoch 219/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1381 - acc: 0.0011 - val_loss: 3.8647 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1375 - acc: 0.0010 - val_loss: 10.6068 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1326 - acc: 0.0011 - val_loss: 4.0877 - val_acc: 7.0423e-04\n",
      "Epoch 222/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1333 - acc: 0.0011 - val_loss: 11.8822 - val_acc: 0.0014\n",
      "Epoch 223/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1337 - acc: 0.0011 - val_loss: 5.6017 - val_acc: 0.0014\n",
      "Epoch 224/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1331 - acc: 8.6126e-04 - val_loss: 11.5396 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1355 - acc: 0.0011 - val_loss: 2.6241 - val_acc: 0.0014\n",
      "Epoch 226/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1316 - acc: 0.0011 - val_loss: 5.4875 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1311 - acc: 0.0010 - val_loss: 3.9627 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1340 - acc: 8.6126e-04 - val_loss: 6.1167 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1306 - acc: 9.3956e-04 - val_loss: 4.4836 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1314 - acc: 9.3956e-04 - val_loss: 13.3163 - val_acc: 0.0014\n",
      "Epoch 231/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1321 - acc: 0.0011 - val_loss: 6.4352 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1329 - acc: 0.0010 - val_loss: 12.9330 - val_acc: 0.0014\n",
      "Epoch 233/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1295 - acc: 0.0010 - val_loss: 4.3955 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1339 - acc: 0.0010 - val_loss: 11.9083 - val_acc: 0.0014\n",
      "Epoch 235/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1334 - acc: 0.0011 - val_loss: 4.6850 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1274 - acc: 0.0010 - val_loss: 8.3084 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1278 - acc: 0.0010 - val_loss: 6.5435 - val_acc: 0.0014\n",
      "Epoch 238/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1318 - acc: 0.0010 - val_loss: 11.1403 - val_acc: 7.0423e-04\n",
      "Epoch 239/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1351 - acc: 9.3956e-04 - val_loss: 4.7928 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1327 - acc: 9.3956e-04 - val_loss: 8.9387 - val_acc: 0.0014\n",
      "Epoch 241/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1294 - acc: 0.0010 - val_loss: 6.8764 - val_acc: 0.0014\n",
      "Epoch 242/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1330 - acc: 0.0011 - val_loss: 8.0678 - val_acc: 7.0423e-04\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1288 - acc: 0.0011 - val_loss: 4.0515 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1303 - acc: 0.0011 - val_loss: 11.7252 - val_acc: 0.0014\n",
      "Epoch 245/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1302 - acc: 9.3956e-04 - val_loss: 5.7061 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1253 - acc: 0.0010 - val_loss: 11.2382 - val_acc: 0.0014\n",
      "Epoch 247/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1329 - acc: 0.0010 - val_loss: 4.5782 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1281 - acc: 0.0010 - val_loss: 4.6484 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1288 - acc: 0.0010 - val_loss: 6.8121 - val_acc: 7.0423e-04\n",
      "Epoch 250/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1281 - acc: 0.0011 - val_loss: 7.2871 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1330 - acc: 0.0011 - val_loss: 16.1141 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1293 - acc: 8.6126e-04 - val_loss: 8.6726 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1309 - acc: 0.0010 - val_loss: 14.6487 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1283 - acc: 9.3956e-04 - val_loss: 7.8093 - val_acc: 7.0423e-04\n",
      "Epoch 255/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1287 - acc: 0.0010 - val_loss: 11.3756 - val_acc: 0.0014\n",
      "Epoch 256/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1250 - acc: 0.0011 - val_loss: 5.6430 - val_acc: 0.0014\n",
      "Epoch 257/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1241 - acc: 0.0010 - val_loss: 4.0948 - val_acc: 0.0014\n",
      "Epoch 258/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1245 - acc: 0.0011 - val_loss: 4.6638 - val_acc: 7.0423e-04\n",
      "Epoch 259/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1226 - acc: 0.0010 - val_loss: 9.2115 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1295 - acc: 0.0011 - val_loss: 6.1325 - val_acc: 0.0014\n",
      "Epoch 261/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1243 - acc: 0.0010 - val_loss: 8.9484 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1278 - acc: 0.0011 - val_loss: 3.5064 - val_acc: 7.0423e-04\n",
      "Epoch 263/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1264 - acc: 9.3956e-04 - val_loss: 10.6044 - val_acc: 7.0423e-04\n",
      "Epoch 264/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1283 - acc: 0.0011 - val_loss: 4.7422 - val_acc: 7.0423e-04\n",
      "Epoch 265/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1260 - acc: 0.0011 - val_loss: 10.4957 - val_acc: 7.0423e-04\n",
      "Epoch 266/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1241 - acc: 0.0010 - val_loss: 9.4995 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1223 - acc: 0.0010 - val_loss: 18.3788 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1262 - acc: 0.0010 - val_loss: 3.4352 - val_acc: 0.0014\n",
      "Epoch 269/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1289 - acc: 0.0010 - val_loss: 11.1319 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1271 - acc: 0.0011 - val_loss: 4.2637 - val_acc: 0.0014\n",
      "Epoch 271/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1252 - acc: 0.0010 - val_loss: 10.0575 - val_acc: 0.0014\n",
      "Epoch 272/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1221 - acc: 0.0010 - val_loss: 4.4333 - val_acc: 0.0014\n",
      "Epoch 273/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1240 - acc: 0.0010 - val_loss: 9.4926 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1185 - acc: 0.0010 - val_loss: 3.0975 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1214 - acc: 0.0011 - val_loss: 7.7759 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1292 - acc: 0.0010 - val_loss: 3.7609 - val_acc: 0.0014\n",
      "Epoch 277/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1212 - acc: 9.3956e-04 - val_loss: 7.7479 - val_acc: 7.0423e-04\n",
      "Epoch 278/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1236 - acc: 8.6126e-04 - val_loss: 3.5144 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1225 - acc: 0.0011 - val_loss: 10.2446 - val_acc: 0.0014\n",
      "Epoch 280/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1232 - acc: 0.0010 - val_loss: 4.9870 - val_acc: 0.0014\n",
      "Epoch 281/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1225 - acc: 0.0010 - val_loss: 4.0963 - val_acc: 7.0423e-04\n",
      "Epoch 282/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1236 - acc: 0.0010 - val_loss: 10.4359 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1190 - acc: 9.3956e-04 - val_loss: 3.7786 - val_acc: 0.0014\n",
      "Epoch 284/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1233 - acc: 0.0010 - val_loss: 11.1422 - val_acc: 0.0014\n",
      "Epoch 285/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1251 - acc: 0.0010 - val_loss: 7.4389 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1256 - acc: 9.3956e-04 - val_loss: 12.5281 - val_acc: 0.0014\n",
      "Epoch 287/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1195 - acc: 9.3956e-04 - val_loss: 8.9347 - val_acc: 0.0014\n",
      "Epoch 288/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1241 - acc: 0.0010 - val_loss: 5.7721 - val_acc: 0.0014\n",
      "Epoch 289/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1214 - acc: 0.0011 - val_loss: 6.4456 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1214 - acc: 0.0010 - val_loss: 4.8014 - val_acc: 0.0014\n",
      "Epoch 291/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1214 - acc: 9.3956e-04 - val_loss: 6.0664 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1199 - acc: 8.6126e-04 - val_loss: 5.5327 - val_acc: 0.0014\n",
      "Epoch 293/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1262 - acc: 0.0010 - val_loss: 8.5201 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1176 - acc: 0.0010 - val_loss: 5.7524 - val_acc: 0.0014\n",
      "Epoch 295/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1194 - acc: 0.0010 - val_loss: 12.4126 - val_acc: 7.0423e-04\n",
      "Epoch 296/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1215 - acc: 0.0010 - val_loss: 4.4479 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1199 - acc: 8.6126e-04 - val_loss: 6.5398 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1243 - acc: 0.0011 - val_loss: 4.2747 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1194 - acc: 0.0010 - val_loss: 12.3858 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1281 - acc: 0.0011 - val_loss: 5.5265 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1231 - acc: 0.0010 - val_loss: 13.8518 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1205 - acc: 0.0011 - val_loss: 7.0483 - val_acc: 7.0423e-04\n",
      "Epoch 303/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1185 - acc: 0.0011 - val_loss: 11.5239 - val_acc: 7.0423e-04\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1271 - acc: 0.0010 - val_loss: 4.8441 - val_acc: 0.0014\n",
      "Epoch 305/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1179 - acc: 0.0010 - val_loss: 9.3103 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1204 - acc: 0.0011 - val_loss: 5.9725 - val_acc: 7.0423e-04\n",
      "Epoch 307/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1229 - acc: 0.0011 - val_loss: 8.0035 - val_acc: 7.0423e-04\n",
      "Epoch 308/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1197 - acc: 0.0010 - val_loss: 5.3002 - val_acc: 7.0423e-04\n",
      "Epoch 309/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1157 - acc: 9.3956e-04 - val_loss: 10.7951 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1187 - acc: 0.0010 - val_loss: 6.4108 - val_acc: 7.0423e-04\n",
      "Epoch 311/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1170 - acc: 9.3956e-04 - val_loss: 10.2567 - val_acc: 0.0014\n",
      "Epoch 312/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1193 - acc: 0.0010 - val_loss: 7.3842 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1187 - acc: 0.0010 - val_loss: 10.5194 - val_acc: 7.0423e-04\n",
      "Epoch 314/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1174 - acc: 0.0010 - val_loss: 4.5754 - val_acc: 0.0014\n",
      "Epoch 315/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1157 - acc: 0.0010 - val_loss: 9.5052 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1195 - acc: 0.0011 - val_loss: 9.0426 - val_acc: 7.0423e-04\n",
      "Epoch 317/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1190 - acc: 9.3956e-04 - val_loss: 14.2675 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1187 - acc: 0.0010 - val_loss: 8.0921 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1205 - acc: 7.8296e-04 - val_loss: 7.0516 - val_acc: 0.0014\n",
      "Epoch 320/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1143 - acc: 0.0010 - val_loss: 6.5276 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1172 - acc: 0.0011 - val_loss: 8.9534 - val_acc: 0.0014\n",
      "Epoch 322/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1144 - acc: 8.6126e-04 - val_loss: 8.2707 - val_acc: 0.0014\n",
      "Epoch 323/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1150 - acc: 0.0010 - val_loss: 4.2391 - val_acc: 0.0014\n",
      "Epoch 324/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1133 - acc: 0.0010 - val_loss: 13.5117 - val_acc: 0.0014\n",
      "Epoch 325/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1173 - acc: 9.3956e-04 - val_loss: 5.6811 - val_acc: 0.0014\n",
      "Epoch 326/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1148 - acc: 0.0011 - val_loss: 8.2638 - val_acc: 0.0014\n",
      "Epoch 327/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1145 - acc: 0.0011 - val_loss: 4.0402 - val_acc: 0.0014\n",
      "Epoch 328/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1177 - acc: 0.0010 - val_loss: 10.2843 - val_acc: 7.0423e-04\n",
      "Epoch 329/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1168 - acc: 8.6126e-04 - val_loss: 5.5535 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1149 - acc: 0.0010 - val_loss: 9.8118 - val_acc: 0.0014\n",
      "Epoch 331/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1135 - acc: 0.0011 - val_loss: 3.3135 - val_acc: 0.0014\n",
      "Epoch 332/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1171 - acc: 7.8296e-04 - val_loss: 7.0168 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1196 - acc: 0.0011 - val_loss: 2.9199 - val_acc: 7.0423e-04\n",
      "Epoch 334/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1170 - acc: 0.0011 - val_loss: 9.1761 - val_acc: 7.0423e-04\n",
      "Epoch 335/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1134 - acc: 0.0011 - val_loss: 4.4291 - val_acc: 0.0014\n",
      "Epoch 336/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1098 - acc: 8.6126e-04 - val_loss: 12.8390 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1145 - acc: 0.0010 - val_loss: 3.1832 - val_acc: 0.0014\n",
      "Epoch 338/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1118 - acc: 0.0011 - val_loss: 7.1355 - val_acc: 7.0423e-04\n",
      "Epoch 339/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1186 - acc: 0.0010 - val_loss: 4.0500 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1172 - acc: 0.0010 - val_loss: 10.2748 - val_acc: 0.0014\n",
      "Epoch 341/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1153 - acc: 0.0010 - val_loss: 2.6483 - val_acc: 7.0423e-04\n",
      "Epoch 342/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1189 - acc: 9.3956e-04 - val_loss: 5.9849 - val_acc: 0.0014\n",
      "Epoch 343/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1129 - acc: 0.0010 - val_loss: 4.0741 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1178 - acc: 8.6126e-04 - val_loss: 10.2563 - val_acc: 0.0014\n",
      "Epoch 345/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1171 - acc: 0.0010 - val_loss: 5.9308 - val_acc: 0.0014\n",
      "Epoch 346/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1147 - acc: 9.3956e-04 - val_loss: 6.8713 - val_acc: 0.0014\n",
      "Epoch 347/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1110 - acc: 0.0010 - val_loss: 4.3210 - val_acc: 0.0014\n",
      "Epoch 348/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1118 - acc: 9.3956e-04 - val_loss: 9.7650 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1225 - acc: 0.0010 - val_loss: 3.0779 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1430 - acc: 0.0010 - val_loss: 4.5046 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1330 - acc: 0.0010 - val_loss: 3.8145 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1267 - acc: 0.0010 - val_loss: 2.6495 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1232 - acc: 0.0011 - val_loss: 5.8080 - val_acc: 7.0423e-04\n",
      "Epoch 354/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1293 - acc: 0.0011 - val_loss: 3.3135 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1322 - acc: 8.6126e-04 - val_loss: 5.6489 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1316 - acc: 9.3956e-04 - val_loss: 2.6430 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1247 - acc: 9.3956e-04 - val_loss: 6.4118 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1242 - acc: 0.0011 - val_loss: 5.0696 - val_acc: 7.0423e-04\n",
      "Epoch 359/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1139 - acc: 0.0010 - val_loss: 7.7103 - val_acc: 0.0014\n",
      "Epoch 360/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1205 - acc: 0.0011 - val_loss: 2.7511 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1142 - acc: 0.0011 - val_loss: 4.8713 - val_acc: 0.0014\n",
      "Epoch 362/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1134 - acc: 0.0011 - val_loss: 3.5209 - val_acc: 7.0423e-04\n",
      "Epoch 363/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1112 - acc: 8.6126e-04 - val_loss: 6.7984 - val_acc: 7.0423e-04\n",
      "Epoch 364/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1128 - acc: 0.0011 - val_loss: 5.3309 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1166 - acc: 9.3956e-04 - val_loss: 9.9512 - val_acc: 7.0423e-04\n",
      "Epoch 366/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1140 - acc: 0.0011 - val_loss: 4.7435 - val_acc: 0.0014\n",
      "Epoch 367/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1109 - acc: 0.0011 - val_loss: 9.0925 - val_acc: 0.0014\n",
      "Epoch 368/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1114 - acc: 0.0010 - val_loss: 4.6087 - val_acc: 7.0423e-04\n",
      "Epoch 369/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1126 - acc: 0.0010 - val_loss: 10.5974 - val_acc: 0.0014\n",
      "Epoch 370/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1144 - acc: 8.6126e-04 - val_loss: 7.3386 - val_acc: 7.0423e-04\n",
      "Epoch 371/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1097 - acc: 0.0010 - val_loss: 14.4762 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1143 - acc: 0.0011 - val_loss: 3.0922 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1123 - acc: 0.0011 - val_loss: 5.4988 - val_acc: 7.0423e-04\n",
      "Epoch 374/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1117 - acc: 0.0010 - val_loss: 5.0818 - val_acc: 7.0423e-04\n",
      "Epoch 375/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1097 - acc: 9.3956e-04 - val_loss: 11.4433 - val_acc: 0.0014\n",
      "Epoch 376/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1131 - acc: 0.0011 - val_loss: 3.6303 - val_acc: 0.0014\n",
      "Epoch 377/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1125 - acc: 8.6126e-04 - val_loss: 4.7350 - val_acc: 0.0014\n",
      "Epoch 378/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1129 - acc: 9.3956e-04 - val_loss: 4.6099 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1120 - acc: 0.0011 - val_loss: 12.6261 - val_acc: 0.0014\n",
      "Epoch 380/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1075 - acc: 9.3956e-04 - val_loss: 7.8321 - val_acc: 0.0014\n",
      "Epoch 381/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1091 - acc: 9.3956e-04 - val_loss: 13.5422 - val_acc: 0.0014\n",
      "Epoch 382/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1101 - acc: 0.0011 - val_loss: 5.4298 - val_acc: 0.0014\n",
      "Epoch 383/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1109 - acc: 0.0010 - val_loss: 14.4371 - val_acc: 0.0014\n",
      "Epoch 384/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1096 - acc: 8.6126e-04 - val_loss: 5.0845 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1068 - acc: 0.0010 - val_loss: 8.0073 - val_acc: 0.0014\n",
      "Epoch 386/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1101 - acc: 0.0010 - val_loss: 2.7404 - val_acc: 0.0014\n",
      "Epoch 387/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1078 - acc: 9.3956e-04 - val_loss: 5.4326 - val_acc: 0.0014\n",
      "Epoch 388/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1100 - acc: 0.0010 - val_loss: 2.9816 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1068 - acc: 0.0011 - val_loss: 7.8620 - val_acc: 0.0014\n",
      "Epoch 390/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1061 - acc: 0.0010 - val_loss: 5.2977 - val_acc: 0.0014\n",
      "Epoch 391/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1088 - acc: 0.0011 - val_loss: 14.1040 - val_acc: 7.0423e-04\n",
      "Epoch 392/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1091 - acc: 0.0010 - val_loss: 3.7381 - val_acc: 7.0423e-04\n",
      "Epoch 393/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1084 - acc: 0.0010 - val_loss: 7.7117 - val_acc: 7.0423e-04\n",
      "Epoch 394/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1060 - acc: 9.3956e-04 - val_loss: 3.6907 - val_acc: 0.0014\n",
      "Epoch 395/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1081 - acc: 0.0010 - val_loss: 8.1381 - val_acc: 0.0014\n",
      "Epoch 396/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1075 - acc: 0.0010 - val_loss: 6.1772 - val_acc: 7.0423e-04\n",
      "Epoch 397/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1073 - acc: 0.0010 - val_loss: 5.9061 - val_acc: 0.0014\n",
      "Epoch 398/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1072 - acc: 9.3956e-04 - val_loss: 3.8253 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1107 - acc: 8.6126e-04 - val_loss: 11.9324 - val_acc: 0.0014\n",
      "Epoch 400/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1055 - acc: 0.0010 - val_loss: 5.0086 - val_acc: 0.0014\n",
      "Epoch 401/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1090 - acc: 0.0010 - val_loss: 9.5126 - val_acc: 0.0014\n",
      "Epoch 402/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1100 - acc: 7.8296e-04 - val_loss: 6.4432 - val_acc: 7.0423e-04\n",
      "Epoch 403/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1066 - acc: 9.3956e-04 - val_loss: 8.0735 - val_acc: 7.0423e-04\n",
      "Epoch 404/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1103 - acc: 0.0010 - val_loss: 3.3029 - val_acc: 7.0423e-04\n",
      "Epoch 405/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1063 - acc: 0.0010 - val_loss: 6.8758 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1082 - acc: 0.0011 - val_loss: 5.9749 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1062 - acc: 9.3956e-04 - val_loss: 15.6032 - val_acc: 0.0014\n",
      "Epoch 408/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1055 - acc: 0.0010 - val_loss: 4.0072 - val_acc: 0.0014\n",
      "Epoch 409/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1064 - acc: 0.0010 - val_loss: 13.2606 - val_acc: 0.0014\n",
      "Epoch 410/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1053 - acc: 0.0011 - val_loss: 8.7415 - val_acc: 7.0423e-04\n",
      "Epoch 411/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1039 - acc: 0.0010 - val_loss: 8.1876 - val_acc: 0.0014\n",
      "Epoch 412/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1049 - acc: 8.6126e-04 - val_loss: 5.5317 - val_acc: 0.0014\n",
      "Epoch 413/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1067 - acc: 0.0010 - val_loss: 13.7537 - val_acc: 0.0014\n",
      "Epoch 414/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1020 - acc: 0.0011 - val_loss: 3.3845 - val_acc: 0.0014\n",
      "Epoch 415/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1035 - acc: 0.0011 - val_loss: 8.7734 - val_acc: 7.0423e-04\n",
      "Epoch 416/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1057 - acc: 9.3956e-04 - val_loss: 6.4972 - val_acc: 0.0014\n",
      "Epoch 417/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1065 - acc: 0.0010 - val_loss: 11.3828 - val_acc: 0.0014\n",
      "Epoch 418/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1021 - acc: 0.0011 - val_loss: 6.5451 - val_acc: 7.0423e-04\n",
      "Epoch 419/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1013 - acc: 0.0011 - val_loss: 6.7488 - val_acc: 0.0014\n",
      "Epoch 420/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1010 - acc: 0.0010 - val_loss: 4.4753 - val_acc: 0.0014\n",
      "Epoch 421/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1069 - acc: 0.0011 - val_loss: 7.1185 - val_acc: 0.0014\n",
      "Epoch 422/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1037 - acc: 0.0011 - val_loss: 4.3227 - val_acc: 0.0014\n",
      "Epoch 423/500\n",
      "12772/12772 [==============================] - ETA: 0s - loss: 0.1035 - acc: 0.0010    - 1s - loss: 0.1033 - acc: 0.0010 - val_loss: 8.9491 - val_acc: 0.0014\n",
      "Epoch 424/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1041 - acc: 9.3956e-04 - val_loss: 2.9362 - val_acc: 7.0423e-04\n",
      "Epoch 425/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1055 - acc: 0.0011 - val_loss: 9.1643 - val_acc: 0.0014\n",
      "Epoch 426/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1016 - acc: 0.0010 - val_loss: 4.4235 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1062 - acc: 0.0010 - val_loss: 11.6633 - val_acc: 0.0014\n",
      "Epoch 428/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1011 - acc: 0.0011 - val_loss: 6.5928 - val_acc: 0.0014\n",
      "Epoch 429/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1026 - acc: 0.0011 - val_loss: 7.0653 - val_acc: 0.0014\n",
      "Epoch 430/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1023 - acc: 0.0010 - val_loss: 6.4585 - val_acc: 0.0014\n",
      "Epoch 431/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1002 - acc: 0.0011 - val_loss: 6.5111 - val_acc: 0.0014\n",
      "Epoch 432/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1085 - acc: 9.3956e-04 - val_loss: 6.7100 - val_acc: 0.0014\n",
      "Epoch 433/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1040 - acc: 0.0010 - val_loss: 13.4073 - val_acc: 0.0014\n",
      "Epoch 434/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1018 - acc: 0.0010 - val_loss: 3.2684 - val_acc: 0.0014\n",
      "Epoch 435/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1059 - acc: 0.0010 - val_loss: 7.2922 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1034 - acc: 0.0010 - val_loss: 4.3213 - val_acc: 0.0014\n",
      "Epoch 437/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1005 - acc: 9.3956e-04 - val_loss: 5.8746 - val_acc: 7.0423e-04\n",
      "Epoch 438/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1002 - acc: 0.0010 - val_loss: 2.8479 - val_acc: 0.0014\n",
      "Epoch 439/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1004 - acc: 9.3956e-04 - val_loss: 5.8600 - val_acc: 7.0423e-04\n",
      "Epoch 440/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1048 - acc: 0.0011 - val_loss: 4.9762 - val_acc: 0.0014\n",
      "Epoch 441/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1018 - acc: 8.6126e-04 - val_loss: 7.5558 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1070 - acc: 0.0011 - val_loss: 2.7306 - val_acc: 0.0014\n",
      "Epoch 443/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1040 - acc: 0.0010 - val_loss: 9.4772 - val_acc: 0.0014\n",
      "Epoch 444/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1017 - acc: 0.0011 - val_loss: 4.5098 - val_acc: 0.0014\n",
      "Epoch 445/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1019 - acc: 0.0010 - val_loss: 6.0866 - val_acc: 0.0014\n",
      "Epoch 446/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1017 - acc: 0.0011 - val_loss: 5.1540 - val_acc: 7.0423e-04\n",
      "Epoch 447/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1154 - acc: 0.0010 - val_loss: 6.8407 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1129 - acc: 0.0010 - val_loss: 5.4546 - val_acc: 7.0423e-04\n",
      "Epoch 449/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1090 - acc: 0.0010 - val_loss: 11.0556 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1124 - acc: 0.0011 - val_loss: 3.9332 - val_acc: 0.0014\n",
      "Epoch 451/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1128 - acc: 0.0010 - val_loss: 7.3646 - val_acc: 0.0014\n",
      "Epoch 452/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1092 - acc: 9.3956e-04 - val_loss: 2.4508 - val_acc: 0.0014\n",
      "Epoch 453/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1105 - acc: 0.0010 - val_loss: 9.2639 - val_acc: 0.0014\n",
      "Epoch 454/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1043 - acc: 9.3956e-04 - val_loss: 3.6349 - val_acc: 0.0014\n",
      "Epoch 455/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1043 - acc: 0.0011 - val_loss: 7.2705 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1021 - acc: 0.0010 - val_loss: 3.6659 - val_acc: 7.0423e-04\n",
      "Epoch 457/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1023 - acc: 0.0010 - val_loss: 12.5802 - val_acc: 7.0423e-04\n",
      "Epoch 458/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.0999 - acc: 9.3956e-04 - val_loss: 3.7915 - val_acc: 0.0014\n",
      "Epoch 459/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1095 - acc: 0.0010 - val_loss: 9.3370 - val_acc: 7.0423e-04\n",
      "Epoch 460/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1049 - acc: 0.0010 - val_loss: 4.1387 - val_acc: 7.0423e-04\n",
      "Epoch 461/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1021 - acc: 9.3956e-04 - val_loss: 8.3198 - val_acc: 0.0014\n",
      "Epoch 462/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.0999 - acc: 0.0011 - val_loss: 4.6250 - val_acc: 0.0014\n",
      "Epoch 463/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1101 - acc: 0.0011 - val_loss: 9.0566 - val_acc: 0.0014\n",
      "Epoch 464/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1092 - acc: 0.0011 - val_loss: 2.6830 - val_acc: 0.0014\n",
      "Epoch 465/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1118 - acc: 0.0010 - val_loss: 7.8962 - val_acc: 7.0423e-04\n",
      "Epoch 466/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1096 - acc: 0.0011 - val_loss: 4.0121 - val_acc: 7.0423e-04\n",
      "Epoch 467/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1089 - acc: 0.0010 - val_loss: 7.2582 - val_acc: 7.0423e-04\n",
      "Epoch 468/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1097 - acc: 0.0011 - val_loss: 3.6437 - val_acc: 7.0423e-04\n",
      "Epoch 469/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1067 - acc: 0.0010 - val_loss: 6.9702 - val_acc: 7.0423e-04\n",
      "Epoch 470/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1035 - acc: 9.3956e-04 - val_loss: 7.5827 - val_acc: 7.0423e-04\n",
      "Epoch 471/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1035 - acc: 0.0010 - val_loss: 15.4994 - val_acc: 0.0014\n",
      "Epoch 472/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1099 - acc: 0.0010 - val_loss: 8.0946 - val_acc: 7.0423e-04\n",
      "Epoch 473/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1074 - acc: 0.0011 - val_loss: 11.1537 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1073 - acc: 9.3956e-04 - val_loss: 6.9464 - val_acc: 0.0014\n",
      "Epoch 475/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1060 - acc: 0.0010 - val_loss: 14.7965 - val_acc: 0.0014\n",
      "Epoch 476/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1032 - acc: 0.0011 - val_loss: 2.7301 - val_acc: 0.0014\n",
      "Epoch 477/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1079 - acc: 0.0011 - val_loss: 7.2157 - val_acc: 7.0423e-04\n",
      "Epoch 478/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1087 - acc: 0.0010 - val_loss: 3.7971 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1052 - acc: 0.0011 - val_loss: 10.7896 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1085 - acc: 9.3956e-04 - val_loss: 4.1758 - val_acc: 0.0014\n",
      "Epoch 481/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1138 - acc: 8.6126e-04 - val_loss: 12.2526 - val_acc: 0.0014\n",
      "Epoch 482/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1065 - acc: 0.0011 - val_loss: 3.5375 - val_acc: 0.0014\n",
      "Epoch 483/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1071 - acc: 0.0011 - val_loss: 6.9301 - val_acc: 0.0014\n",
      "Epoch 484/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1079 - acc: 0.0011 - val_loss: 2.8666 - val_acc: 0.0014\n",
      "Epoch 485/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1050 - acc: 0.0010 - val_loss: 7.5401 - val_acc: 0.0014\n",
      "Epoch 486/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1047 - acc: 0.0011 - val_loss: 2.6463 - val_acc: 7.0423e-04\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12772/12772 [==============================] - 1s - loss: 0.1047 - acc: 9.3956e-04 - val_loss: 5.7477 - val_acc: 0.0014\n",
      "Epoch 488/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1064 - acc: 0.0010 - val_loss: 4.4318 - val_acc: 7.0423e-04\n",
      "Epoch 489/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1026 - acc: 0.0011 - val_loss: 10.3072 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1011 - acc: 9.3956e-04 - val_loss: 5.8064 - val_acc: 0.0014\n",
      "Epoch 491/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1051 - acc: 0.0010 - val_loss: 10.3842 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1027 - acc: 0.0011 - val_loss: 4.1537 - val_acc: 0.0014\n",
      "Epoch 493/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1063 - acc: 0.0010 - val_loss: 7.4535 - val_acc: 7.0423e-04\n",
      "Epoch 494/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1031 - acc: 0.0011 - val_loss: 4.8340 - val_acc: 0.0014\n",
      "Epoch 495/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1023 - acc: 9.3956e-04 - val_loss: 14.5003 - val_acc: 0.0014\n",
      "Epoch 496/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1049 - acc: 0.0011 - val_loss: 3.6847 - val_acc: 0.0014\n",
      "Epoch 497/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1019 - acc: 0.0010 - val_loss: 7.6229 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1040 - acc: 0.0011 - val_loss: 4.4345 - val_acc: 0.0014\n",
      "Epoch 499/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1054 - acc: 0.0010 - val_loss: 3.3024 - val_acc: 0.0014\n",
      "Epoch 500/500\n",
      "12772/12772 [==============================] - 1s - loss: 0.1047 - acc: 0.0011 - val_loss: 11.3681 - val_acc: 0.0014\n",
      "[[ 10.94796085]\n",
      " [ 10.91129589]\n",
      " [ 10.4806633 ]\n",
      " ..., \n",
      " [  9.94560051]\n",
      " [ 10.86862564]\n",
      " [  9.57504749]]\n"
     ]
    }
   ],
   "source": [
    "# test keras model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3000, input_shape=(data[TRAIN+FEATURES].shape[1],), activation = 'relu',))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1500, activation='relu'))\n",
    "model.add(Dense(750, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0),\n",
    "      loss='mse',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(data[TRAIN+FEATURES], data[TRAIN+TRUTH], batch_size=100, epochs=500, validation_split = 0.1)\n",
    "# model.compile(optimizer='adam',      loss='mse', metrics=['accuracy'])\n",
    "\n",
    "x = model.predict(data[TEST+FEATURES])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28093135092e+56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fefd1796da0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAGoCAYAAADxbmq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvWKYs7BAdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefd199ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linChiSq = xi2(10**data[TEST+TRUTH],10**x,data[TEST+LINERROR])\n",
    "print(linChiSq)\n",
    "\n",
    "g = sns.jointplot(x=cvpred, y=data[TEST+TRUTH], alpha=.3)\n",
    "g.x = x[:,0].clip(0,13)\n",
    "g.y = data[TEST+TRUTH]\n",
    "g.plot_joint(plt.scatter, alpha=.3, c='r')\n",
    "\n",
    "plt.legend(['lgbm', 'keras-rmsprop'])\n",
    "# sns.jointplot(x=x[:,0], y=cvpred)\n",
    "\n",
    "# sns.jointplot(x=cvpred, y=data[TEST+TRUTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    }
   ],
   "source": [
    "qsd =x\n",
    "\n",
    "print(qsd.clip(0,15).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[TEST+FEATURES][:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:astrohack]",
   "language": "python",
   "name": "conda-env-astrohack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
